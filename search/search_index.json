{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A-Profiles","text":"<p>Welcome to A-Profiles documentation!</p> <p></p> <p>A-Profiles is a python library dedicated to the analysis of atmospheric profilers measurements.</p> <p>Using elastic measurements performed by Lidars and/or ceilometers, A-Profiles includes several modules such as clouds detection, tracking of the planetary boundary layer height or the retrieval of aerosol properties (extinction, mass concentration) using some a priori.</p> <p>At present time, A-Profiles supports E-PROFILE data reading. This library is used by V-Profiles.</p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li> Installation</li> <li> Examples</li> <li> API</li> <li> Command Line Interface (CLI)</li> <li> Changelog</li> </ul>"},{"location":"api/","title":"Overview","text":"<p>Documentation of the core API of aprofiles.</p> <ul> <li> Reading</li> <li> Data Classes</li> <li> Detection</li> <li> Retrieval</li> <li> Simulation</li> <li> Plotting</li> <li> Writing</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#0142","title":"0.14.2","text":"<p>Jun 12, 2025</p> <ul> <li>Create daily climatology files.</li> </ul>"},{"location":"changelog/#0141","title":"0.14.1","text":"<p>May 22, 2025</p> <ul> <li>Sort files per time and aer_type to ensure monotonicity.</li> </ul>"},{"location":"changelog/#0140","title":"0.14.0","text":"<p>May 21, 2025</p> <ul> <li>Add aprofiles version in output files metadata and as a general option of the CLI.</li> </ul>"},{"location":"changelog/#0133","title":"0.13.3","text":"<p>May 20, 2025</p> <ul> <li>Make sure files with dimensions in the the order (altitude, time) are computed, and not just lazy processed with dask, which made the lowest layers extrapolation not working.</li> </ul>"},{"location":"changelog/#0132","title":"0.13.2","text":"<p>Mar 24, 2025</p> <ul> <li>Fix map processing by using new attributes name (<code>station_altitude_t0</code>, <code>station_latitude_t0</code> and <code>station_longitude_t0</code>)</li> </ul>"},{"location":"changelog/#0131","title":"0.13.1","text":"<p>Mar 24, 2025</p> <ul> <li>In CLI, return PBL under clouds per default</li> </ul>"},{"location":"changelog/#0130","title":"0.13.0","text":"<p>Mar 24, 2025</p> <p>This update intends to support the processing of moving stations.</p> <ul> <li>update <code>profiles</code> Object data format</li> <li>the reference altitude is set above ground level (instead of above sea level)</li> <li>add time dimension to <code>station_altitude</code>, <code>station_latitude</code> and <code>station_longitude</code></li> <li>update <code>AP</code> files formatting to reflect new <code>profiles</code> format</li> <li>add <code>station_altitude_t0</code>, <code>station_latitude_t0</code> and <code>station_longitude_t0</code> attributes for convenience</li> </ul>"},{"location":"changelog/#0125","title":"0.12.5","text":"<p>Feb 12, 2025</p> <ul> <li>adjust some parameters in cli workflow</li> </ul>"},{"location":"changelog/#0124","title":"0.12.4","text":"<p>Feb 11, 2025</p> <ul> <li>fix pip extras dependencies installation</li> </ul>"},{"location":"changelog/#0123","title":"0.12.3","text":"<p>Feb 11, 2025</p> <ul> <li>goes from groups to extras for dependencies support with pip</li> </ul>"},{"location":"changelog/#0122","title":"0.12.2","text":"<p>Feb 11, 2025</p> <ul> <li>CLI updates:</li> <li>skip corrupted files in calendar and map files making</li> <li>fix some conflicts in climatology due to file format changes</li> </ul>"},{"location":"changelog/#0121","title":"0.12.1","text":"<p>Feb 10, 2025</p> <ul> <li>write cloud_base_height variable provided in original files</li> <li>update documentation</li> </ul>"},{"location":"changelog/#0120","title":"0.12.0","text":"<p>Feb 10, 2025</p> <ul> <li>add AI-Profiles Deep Embedded Clustering (DEC) cloud detection method in addition to the vertical gradient (VG). The two methods are available into the cloud detection function. DEC is the default selected method.</li> <li>revisit documentation accordingly</li> <li>use snr method as a fallback to detect fog or condensation if the method is called before the cloud detection</li> </ul> <p>[!WARNING] breaking change: the cloud detection output is now defined into a single cloud boolean variable instead of the combination of bases, peaks, and tops, so both cloud detection methods (DEC)</p>"},{"location":"changelog/#0112","title":"0.11.2","text":"<p>Feb 4, 2025</p> <ul> <li>use groups instead of extras for dependencies installation</li> </ul>"},{"location":"changelog/#0111","title":"0.11.1","text":"<p>Oct 29, 2024</p> <ul> <li>replace emc (Extinction to Mass Coefficient) to mec (Mass to Extinction Coefficient)</li> </ul>"},{"location":"changelog/#0110","title":"0.11.0","text":"<p>Oct 29, 2024</p> <ul> <li>add ifs emc to netcdf files and emc for different aerosol types and ifs to map json files</li> </ul>"},{"location":"changelog/#0106","title":"0.10.6","text":"<p>Oct 25, 2024</p> <ul> <li>fix CI</li> </ul>"},{"location":"changelog/#0105","title":"0.10.5","text":"<p>Oct 25, 2024</p> <ul> <li>change <code>aer_ifs.json</code> structure</li> <li>move config logic to workflow part</li> </ul>"},{"location":"changelog/#0104","title":"0.10.4","text":"<p>Oct 19, 2024</p> <ul> <li>change <code>lr_ifs.json</code> to <code>aer_ifs.json</code></li> </ul>"},{"location":"changelog/#0103","title":"0.10.3","text":"<p>Oct 18, 2024</p> <ul> <li>use time_steps option (6 by default, for working with 30 minutes batch files)</li> </ul>"},{"location":"changelog/#0102","title":"0.10.2","text":"<p>Oct 18, 2024</p> <ul> <li>make 30 minutes batch L2b files</li> </ul>"},{"location":"changelog/#0101","title":"0.10.1","text":"<p>Oct 10, 2024</p> <ul> <li>preserve time dimension in L2B files</li> </ul>"},{"location":"changelog/#0100","title":"0.10.0","text":"<p>Oct 10, 2024</p> <ul> <li>revisit CLI: two commands<ul> <li><code>apro run</code> (formerly <code>aprocess</code>: run standard workflow)</li> <li><code>apro l2b</code> (creates L2B files out of AP files)</li> </ul> </li> </ul>"},{"location":"changelog/#097","title":"0.9.7","text":"<p>Oct 3, 2024</p> <ul> <li>round up values in climatology files</li> </ul>"},{"location":"changelog/#096","title":"0.9.6","text":"<p>Oct 2, 2024</p> <ul> <li>fix time unit in climatology files</li> <li>fix typo in documentation</li> </ul>"},{"location":"changelog/#095","title":"0.9.5","text":"<p>Oct 2, 2024</p> <ul> <li>write time as int in climatology files</li> </ul>"},{"location":"changelog/#094","title":"0.9.4","text":"<p>Oct 2, 2024</p> <ul> <li>fix typo</li> </ul>"},{"location":"changelog/#093","title":"0.9.3","text":"<p>Oct 2, 2024</p> <ul> <li>add Z as suffix to time in climatology json files</li> </ul>"},{"location":"changelog/#092","title":"0.9.2","text":"<p>Oct 1, 2024</p> <ul> <li>change snr calculation</li> <li>fix build</li> <li>sort climatology by time</li> </ul>"},{"location":"changelog/#091","title":"0.9.1","text":"<p>Sep 30, 2024</p> <ul> <li>fix pip version number</li> </ul>"},{"location":"changelog/#090","title":"0.9.0","text":"<p>Sep 30, 2024</p> <ul> <li>Add <code>aod</code> and <code>lidar_ratio</code> to climatology files</li> </ul>"},{"location":"changelog/#084","title":"0.8.4","text":"<p>Sep 27, 2024</p> <ul> <li>Add <code>lidar_ratio</code> to maps.json</li> </ul>"},{"location":"changelog/#083","title":"0.8.3","text":"<p>Sep 26, 2024</p> <ul> <li>Fix time precision (double instead of float)</li> </ul>"},{"location":"changelog/#082","title":"0.8.2","text":"<p>Sep 25, 2024</p> <ul> <li>Fix time precision (double instead of float)</li> </ul>"},{"location":"changelog/#081","title":"0.8.1","text":"<p>Sep 24, 2024</p> <ul> <li>Fix progress bar visibility in CLI climatology</li> <li>Only read relevant variables in CLI maps and calendar</li> <li>Fix some links in documentation</li> </ul>"},{"location":"changelog/#080","title":"0.8.0","text":"<p>Sep 23, 2024</p> <ul> <li>Use mkdocs for documentation</li> <li>Compress all variables when writing AP files</li> <li>New logo</li> <li>Update README.md</li> </ul>"},{"location":"changelog/#072","title":"0.7.2","text":"<p>Sep 21, 2024</p> <ul> <li>Update quality flags attrs type for CF compliance.</li> </ul>"},{"location":"changelog/#071","title":"0.7.1","text":"<p>Sep 21, 2024</p> <ul> <li>Update dependencies</li> <li>Fix documentation</li> <li>Makes climatology much faster by using dask</li> </ul>"},{"location":"changelog/#070","title":"0.7.0","text":"<p>Sep 20, 2024</p> <ul> <li>Support Python 3.12.</li> <li>Replace tqdm with rich</li> </ul>"},{"location":"changelog/#065","title":"0.6.5","text":"<p>Sep 20, 2024</p> <ul> <li>Work on CF compliance (write time as days).</li> </ul>"},{"location":"changelog/#064","title":"0.6.4","text":"<p>Sep 16, 2024</p> <ul> <li>Work on CF compliance (missing altitude direction and time units).</li> </ul>"},{"location":"changelog/#063","title":"0.6.3","text":"<p>Nov 10, 2023</p> <ul> <li>Fix time conversion warnings in the map processing.</li> </ul>"},{"location":"changelog/#062","title":"0.6.2","text":"<p>Nov 9, 2023</p> <ul> <li>Enable multiprocessing for climatology computation.</li> <li>Fix bug in map processing due to the removal of time conversion warnings (0.6.1).</li> </ul>"},{"location":"changelog/#061","title":"0.6.1","text":"<p>Nov 9, 2023</p> <p>CLI improvements: - Remove time conversion warnings in map computation. - Add indicator in progress-bar when using multiprocessing.</p>"},{"location":"changelog/#060","title":"0.6.0","text":"<p>Nov 3, 2023</p> <ul> <li>Support python3.11.</li> <li>Fix relative paths issues occurring when the CLI is triggered without a local copy of the repository (via module load on ecFlow).</li> </ul>"},{"location":"changelog/#0515","title":"0.5.15","text":"<p>Nov 3, 2023</p> <ul> <li>Fix resampling issue [TypeError: Grouper.__init__() got an unexpected keyword argument 'base'] obtained with pandas v2.0.0. See xarray issue #8282.</li> <li>Add workers option in the CLI.</li> </ul>"},{"location":"changelog/#0514","title":"0.5.14","text":"<p>Mar 24, 2022</p> <ul> <li>Explicitly add numba to the list of required dependencies for solving some installation issues.</li> </ul>"},{"location":"changelog/#0513","title":"0.5.13","text":"<p>Dec 2, 2022</p> <ul> <li>Create a DOI and add citation file in the Git repository.</li> </ul>"},{"location":"changelog/#0512","title":"0.5.12","text":"<p>Nov 16, 2022</p> <ul> <li>Fix relative path of the config file read in the CLI to make the command work properly anywhere.</li> </ul>"},{"location":"changelog/#0511","title":"0.5.11","text":"<p>Nov 15, 2022</p> <ul> <li>Move CLI within the package directory to make aprocess available everywhere.</li> <li>Add pipx installation instructions in documentation.</li> </ul>"},{"location":"changelog/#0510","title":"0.5.10","text":"<p>Nov 10, 2022</p> <ul> <li>Create a aprocess command (calling <code>cli/aprocess.py</code>).</li> <li>Update Typer (from 0.4.0 to 0.7.0).</li> <li>Use Path library.</li> <li>Clean up imports.</li> </ul>"},{"location":"changelog/#059","title":"0.5.9","text":"<p>Oct 27, 2022</p> <ul> <li>Support Python 3.10.</li> </ul>"},{"location":"changelog/#058","title":"0.5.8","text":"<p>Jul 15, 2022</p> <ul> <li>Fix climatology computation bug, which was returning only a single profile instead of seasonal profiles.</li> <li>New configuration file <code>cfg.json</code> with a new exclude_stations_id_from_climatology key for removing some stations with changing altitude.</li> <li>Add a try/except block in the climatology computation for excluding stations with non-monotonic global indexes.</li> </ul>"},{"location":"changelog/#057","title":"0.5.7","text":"<p>Jul 14, 2022</p> <ul> <li>Remove time duplicates if they exist in the L2 file (e.g., <code>L2_0-380-61_A20220708.nc</code>) that were causing conflicts when trying to read multiple files for computing the climatology with <code>xarray.open_mfdataset</code>.</li> </ul>"},{"location":"changelog/#056","title":"0.5.6","text":"<p>Jul 13, 2022</p> <ul> <li>Fix a bug in the PBL detection that was triggering an IndexError when no valid point was found in a profile (e.g., <code>L2_0-20000-003590_A20220701.nc</code>).</li> <li>Improve the previous clouds detection fix, by checking if any valid point was found in the processed profile.</li> </ul>"},{"location":"changelog/#055","title":"0.5.5","text":"<p>Jul 13, 2022</p> <ul> <li>Fix a bug in the clouds detection that was triggering an IndexError when no valid point was found in a profile (e.g., <code>L2_0-20000-003590_A20220701.nc</code>).</li> </ul>"},{"location":"changelog/#054","title":"0.5.4","text":"<p>Jul 12, 2022</p> <ul> <li>Fix a bug in the clouds detection that was triggering an IndexError when data presented consecutive equal values vertically (e.g., <code>L2_0-20000-006432_A20220701.nc</code> where large squares in the altitude are filled with NaN values).</li> </ul>"},{"location":"changelog/#053","title":"0.5.3","text":"<p>Jun 20, 2022</p> <ul> <li>Update pydata-sphinx-theme minimum required version from 0.7.2 to 0.9.0 for supporting dark mode \ud83c\udf18.</li> <li>Update black minimum required version from 21.12b0 to 22.3.0.</li> </ul>"},{"location":"changelog/#052","title":"0.5.2","text":"<p>Apr 13, 2022</p> <ul> <li>Change max valid AOD value used to define outliers from 0.5 to 2.0.</li> </ul>"},{"location":"changelog/#051","title":"0.5.1","text":"<p>Apr 13, 2022</p> <ul> <li>Add compat='override' option to the <code>update_climatology()</code> function to resolve potential merging issues.</li> </ul>"},{"location":"changelog/#050","title":"0.5.0","text":"<p>Apr 12, 2022</p> <ul> <li>Add --update-climatology option in the CLI. This option creates seasonal extinction profiles in one climatology JSON file per station after reading all available AP files.</li> </ul>"},{"location":"changelog/#042","title":"0.4.2","text":"<p>Apr 12, 2022</p> <ul> <li>Fix --from option in CLI.</li> </ul>"},{"location":"changelog/#041","title":"0.4.1","text":"<p>Jan 31, 2022</p> <ul> <li>Add alc_parameters.json file in CLI config directory for overwriting dataflow parameters for different ALC types.</li> <li>Add --no-progress-bar option in CLI.</li> </ul>"},{"location":"changelog/#040","title":"0.4.0","text":"<p>Jan 27, 2022</p> <ul> <li>Add test suite using pytest and pytest-cov.</li> </ul>"},{"location":"changelog/#035","title":"0.3.5","text":"<p>Jan 18, 2022</p> <ul> <li>Enables reading of original CEDA archive files with variables having dimensions as (altitude, time) instead of (time, altitude).</li> </ul>"},{"location":"changelog/#034","title":"0.3.4","text":"<p>Dec 14, 2021</p> <ul> <li>Exit forward inversion loop as soon as a np.nan value is found in the profile.</li> <li>Work on documentation.</li> </ul>"},{"location":"changelog/#033","title":"0.3.3","text":"<p>Dec 13, 2021</p> <ul> <li>Fix poetry warning when publishing to pip.</li> </ul> <p>Note</p> <p>After further investigation, the reported issue with the installation of aprofiles with pip was due to the use of the -e option:</p> <ul> <li><code>pip install .</code> works</li> <li><code>pip install . -e</code> fails</li> </ul>"},{"location":"changelog/#032","title":"0.3.2","text":"<p>Dec 13, 2021</p> <ul> <li>Use multiprocessing instead of multithreading.</li> </ul>"},{"location":"changelog/#031","title":"0.3.1","text":"<p>Dec 9, 2021</p> <ul> <li>Use max altitude as reference altitude when using the forward inversion method.</li> </ul>"},{"location":"changelog/#030","title":"0.3.0","text":"<p>Dec 9, 2021</p> <p>Note</p> <p>This version has been removed from pypi. Use 0.3.1 instead.</p> <ul> <li>Fix major bug in the forward inversion method (use of molecular transmission instead of aerosol transmission).</li> <li>Use max altitude as reference altitude when using the forward inversion method.</li> <li>Add a simulator module for computing attenuated backscatter profiles from a given extinction profile model.</li> <li>Remove outliers in the standard workflow called by the CLI.</li> </ul>"},{"location":"changelog/#026","title":"0.2.6","text":"<p>Dec 8, 2021</p> <ul> <li>Fix Attenuated Backscatter units from \u00b5m\u207b\u00b9.sr\u207b\u00b9 to Mm\u207b\u00b9.sr\u207b\u00b9. This bug only impacted figure legends.</li> </ul>"},{"location":"changelog/#025","title":"0.2.5","text":"<p>Dec 7, 2021</p> <ul> <li>Move Typer from development dependencies to default dependencies.</li> </ul>"},{"location":"changelog/#024","title":"0.2.4","text":"<p>Dec 6, 2021</p> <ul> <li>Remove email address from scripts.</li> <li>Change CLI option (instrument-types to instruments-type).</li> <li>Add show_fig and save_fig options to the plotting function.</li> <li>Replace E-6 m\u207b\u00b9 by \u00b5m\u207b\u00b9 in figures.</li> <li>Update README and documentation figures.</li> </ul>"},{"location":"changelog/#023","title":"0.2.3","text":"<p>Dec 3, 2021</p> <ul> <li>Rename run directory to cli.</li> <li>Rename aprorun.py to aprocess.py.</li> <li>Add CLI documentation.</li> </ul>"},{"location":"changelog/#022","title":"0.2.2","text":"<p>Nov 30, 2021</p> <ul> <li>Work on CLI:<ul> <li>Use Typer instead of argparse.</li> <li>Use pathlib instead of os.path.</li> </ul> </li> </ul>"},{"location":"changelog/#021","title":"0.2.1","text":"<p>Nov 29, 2021</p> <ul> <li> <p>Add CLI for facilitating deployment on ecFlow.</p> <p>Examples: <pre><code>./run/aprorun.py --date 2021-09-09\n./run/aprorun.py --from 2021-09-09 --to 2021-09-10\n./run/aprorun.py --today\n./run/aprorun.py --today --yesterday\n</code></pre></p> </li> </ul>"},{"location":"changelog/#020","title":"0.2.0","text":"<p>Nov 19, 2021</p> <ul> <li>Initial release</li> </ul>"},{"location":"changelog/#010","title":"0.1.0","text":"<p>Sep 20, 2021</p> <ul> <li>Test release</li> </ul>"},{"location":"cli/","title":"CLI","text":"<p>For facilitating the processing of the measurements in routine, a Command Line Interface (CLI) has been developed: cli/apro.py</p> <p>In the current version, the CLI has 3 possible actions:</p> <ol> <li>process data for all stations via the usual A-Profiles cli/utils/workflow.py</li> <li>create a JSON calendar file (used by V-Profiles)</li> <li>create a JSON map file (used by V-Profiles)</li> </ol>"},{"location":"cli/#installation","title":"Installation","text":"<p>In order to use the CLI, A-Profiles needs to be installed with the required extras:</p> <p> via pip/pipx</p> <pre><code>pip install .[cli]\n</code></pre> <p> via poetry</p> <pre><code>poetry install -E cli\n</code></pre>"},{"location":"cli/#documentation","title":"Documentation","text":"<p><code>apro</code> commands can be listed with <code>apro --help</code></p> <pre><code>apro --help\n\n Usage: apro [OPTIONS] COMMAND [ARGS]...                                                                                             \n\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --version             -v        Show the application version and exit                                                             \u2502\n\u2502 --install-completion            Install completion for the current shell.                                                         \u2502\n\u2502 --show-completion               Show completion for the current shell, to copy it or customize the installation.                  \u2502\n\u2502 --help                          Show this message and exit.                                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 l2b   make E-PROFILE L2b files out of AP files                                                                                    \u2502\n\u2502 run   run aprofiles standard workflow for given dates and specific instruments types                                              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"cli/#run-command","title":"<code>run</code> command","text":"<pre><code>apro run --help\n\n Usage: apro run [OPTIONS]                                                                                                           \n\n run aprofiles standard workflow for given dates and specific instruments types                                                      \n see some examples [here](https://augustinmortier.github.io/a-profiles/cli/)                                                         \n\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --date                                             [%Y-%m-%d]              \ud83d\udcc5 Processing date.                                    \u2502\n\u2502 --from                                             [%Y-%m-%d]              \ud83d\udcc5 Initial date. [default: None]                       \u2502\n\u2502 --to                                               [%Y-%m-%d]              \ud83d\udcc5 Ending date. [default: (Today's date)]              \u2502\n\u2502 --today                 --no-today                                         \ud83d\udd51 Process today's data. [default: no-today]           \u2502\n\u2502 --yesterday             --no-yesterday                                     \ud83d\udd59 Process yesterday's data. [default: no-yesterday]   \u2502\n\u2502 --instruments-type                                 [CHM15k|Mini-MPL|CL61]  \ud83d\udcd7 List of specific instruments to be processed.       \u2502\n\u2502                                                                            [default: CHM15k, Mini-MPL]                            \u2502\n\u2502 --multiprocessing       --no-multiprocessing                               \ud83d\ude80 Use multiprocessing mode.                           \u2502\n\u2502                                                                            [default: no-multiprocessing]                          \u2502\n\u2502 --workers                                          INTEGER RANGE [x&gt;=1]    \ud83d\udc77 Number of workers (NSLOTS, if multiprocessing mode  \u2502\n\u2502                                                                            is enabled).                                           \u2502\n\u2502                                                                            [env var: NSLOTS]                                      \u2502\n\u2502                                                                            [default: 2]                                           \u2502\n\u2502 --path-in                                          PATH                    \ud83d\udcc2 Base path for input data. [default: data/e-profile] \u2502\n\u2502 --path-out                                         PATH                    \ud83d\udcc2 Base path for output data.                          \u2502\n\u2502                                                                            [default: data/v-profiles]                             \u2502\n\u2502 --apriori-cfg                                      PATH                    \ud83d\udcc2 Base path for a priori config file.                 \u2502\n\u2502                                                                            [default: config]                                      \u2502\n\u2502 --update-data           --no-update-data                                   \ud83d\udcc8 Update data. [default: update-data]                 \u2502\n\u2502 --update-calendar       --no-update-calendar                               \ud83d\uddd3\ufe0f Update calendar. [default: update-calendar]          \u2502\n\u2502 --update-map            --no-update-map                                    \ud83d\uddfa\ufe0f Update map. [default: update-map]                    \u2502\n\u2502 --update-climatology    --no-update-climatology                            \u21aa\ufe0f Update climatology. [default: update-climatology]    \u2502\n\u2502 --progress-bar          --no-progress-bar                                  \u231b Show progress bar. [default: progress-bar]          \u2502\n\u2502 --help                                                                     Show this message and exit.                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"cli/#examples","title":"Examples","text":""},{"location":"cli/#run-a-specific-date","title":"run a specific date","text":"<pre><code>apro run --date 2021-09-09\n</code></pre>"},{"location":"cli/#run-todays-files","title":"run today\\'s files","text":"<pre><code>apro run --today\n</code></pre>"},{"location":"cli/#run-yesterdays-files","title":"run yesterday\\'s files","text":"<pre><code>apro run --yesterday\n</code></pre> <p>It is possible to combine different options.</p>"},{"location":"cli/#run-todays-and-yesterdays-files-for-chm15k-only","title":"run today\\'s and yesterday\\'s files for CHM15k only","text":"<pre><code>apro run --today --yesterday --instruments-type CHM15k\n</code></pre>"},{"location":"cli/#update-only-calendar-files-for-2021","title":"update only calendar files for 2021","text":"<pre><code>apro run --from 2021-01-01 --to 2021-12-31 --no-update-data --no-update-map\n</code></pre>"},{"location":"cli/#use-multiprocessing","title":"use multiprocessing","text":"<p>The data processing can be run in parallel by using the [<code>multiprocessing</code>] option : <pre><code>apro run --today --yesterday --multiprocessing\n</code></pre></p>"},{"location":"cli/#l2b-command","title":"<code>l2b</code> command","text":"<pre><code>apro l2b --help\n\n Usage: apro l2b [OPTIONS]                                                                                                           \n\n make E-PROFILE L2b files out of AP files                                                                                            \n\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --path-in                              PATH     \ud83d\udcc2 Base path for input data. [default: data/v-profiles]                           \u2502\n\u2502 --path-out                             PATH     \ud83d\udcc2 Base path for output data. [default: data/l2b]                                 \u2502\n\u2502 --time-steps                           INTEGER  \ud83d\udd02 Number of most recent time steps to be processed. [default: 12]                \u2502\n\u2502 --progress-bar    --no-progress-bar             \u231b Show progress bar. [default: progress-bar]                                     \u2502\n\u2502 --help                                          Show this message and exit.                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"cli/#examples_1","title":"Examples","text":""},{"location":"cli/#make-l2b-files-out-of-todays-ap-files-in-default-directory","title":"make L2b files out of today's AP files in default directory","text":"<pre><code>apro l2b \n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>Some basic examples for getting you started using aprofiles. For more information, check out the <code>API</code>.</p>"},{"location":"examples/#data-reading","title":"Data reading","text":"<p>For reading ceilometers and lidars data, the <code>ReadProfiles</code> class must be instantiated with the path of the NetCDF file to be read. The <code>read()</code> method applied to this instance returns a <code>ProfilesData</code> object whose <code>data</code> attribute contains the NetCDF file content as a <code>xarray.Dataset</code>.</p> <pre><code>import aprofiles as apro\n\n# path of the NetCDF file to be read\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n# instantiate the ReadProfiles class with the file path\napro_reader = apro.reader.ReadProfiles(path)\n# call the read method of the instance\nprofiles = apro_reader.read()\n\n# plot the attenuated backscatter profile\nprofiles.plot(\n    var=\"attenuated_backscatter_0\", zref=\"agl\", log=True, vmin=1e-2, vmax=1e1,\n    save_fig=\"examples/images/attenuated_backscatter.png\"\n)\n</code></pre> <p></p>"},{"location":"examples/#basic-corrections","title":"Basic corrections","text":"<p>Here is a non exhaustive list of basic corrections available to correct profile measurements.</p>"},{"location":"examples/#extrapolation-lowest-layers","title":"Extrapolation lowest layers","text":"<p>It is frequent to observe negative values in the lowest layers of the profiles due to instrumental artifacts. It is recommended to eliminate those outliers prior to detecting parameters such as the planetary boundary layer height or before retrieving the aerosol profiles. The <code>extrapolate_below()</code> method of the <code>ProfilesData</code> class allows you to extrapolate values of the selected variable of a <code>ProfilesData</code> object.</p> <p></p> <pre><code>import aprofiles as apro\n\n# path of the NetCDF file to be read\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nprofiles = apro.reader.ReadProfiles(path).read()\n\n# extrapolate lowest layers\nprofiles.extrapolate_below(z=150.0, inplace=True)\n\n# plot the attenuated backscatter profile up to 1000m of altitude\nprofiles.plot(\n    zref=\"agl\", zmax=1000.0, log=True, vmin=1e-2, vmax=1e1,\n    save_fig=\"examples/images/lowest_extrap.png\"\n)\n</code></pre> <p></p>"},{"location":"examples/#gaussian-filtering","title":"Gaussian Filtering","text":"<p>The application of a Gaussian filter can help increase the SNR (which can be determined with the <code>snr()</code> method).</p> <p></p> <pre><code>import aprofiles as apro\n\n# path of the NetCDF file to be read\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nprofiles = apro.reader.ReadProfiles(path).read()\n\n# gaussian filtering\nprofiles.gaussian_filter(sigma=0.5, inplace=True)\n\n# plot the attenuated backscatter profile\nprofiles.plot(\n    log=True, vmin=1e-2, vmax=1e1,\n    save_fig=\"examples/images/gaussian_filter.png\"\n)\n</code></pre> <p></p>"},{"location":"examples/#more-advanced-detection","title":"More advanced detection","text":""},{"location":"examples/#fog-or-condensation-detection","title":"Fog or condensation detection","text":"<p>Fog or condensation prevents the laser beam from propagating into the atmosphere. It is important to detect these cases to filter the data when trying to quantify the aerosol content. Two methods are available:</p> <ul> <li>cloud_base (default): uses the minimum cloud base height.</li> <li>snr (fallback if no clouds are available): identifies areas under a certain altitude for which snr values lower than the prescribed threshold.</li> </ul> <pre><code>import aprofiles as apro\n\n# read some data\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nprofiles = apro.reader.ReadProfiles(path).read()\n\n# basic corrections\nprofiles.extrapolate_below(z=150., inplace=True)\n\n# foc detection\nprofiles.foc(zmin_cloud=200.)\n\n# plot image below 6000m with a highlight on foc\nprofiles.plot(\n    show_foc=True, zmax=6000., vmin=1e-2, vmax=1e1, log=True,\n    save_fig=\"examples/images/foc.png\"\n)\n</code></pre> <p></p>"},{"location":"examples/#clouds-detection","title":"Clouds detection","text":"<p>The clouds module aims to detect the clouds from the aerosols. Two methods are available: </p> <ul> <li>dec (default): Deep Embedded Clustering (see AI-Profiles).</li> <li>vg: Vertical Gradient.</li> </ul> <pre><code>import aprofiles as apro\n\n# read some data\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nprofiles = apro.reader.ReadProfiles(path).read()\n\n# basic corrections\nprofiles.extrapolate_below(z=150., inplace=True)\n\n# clouds detection\nprofiles.clouds()\n\n# plot image with clouds\nprofiles.plot(\n    show_clouds=True, log=True, vmin=1e-2, vmax=1e1,\n    save_fig=\"examples/images/clouds_dec.png\"\n)\n</code></pre> <p></p>"},{"location":"examples/#planetary-boundary-layer-tracking","title":"Planetary Boundary Layer tracking","text":"<p>The Planetary Boundary Layer module identifies the PBL heigh as the strongest vertical gradient of the attenuated backscatter profiles.</p> <pre><code>import aprofiles as apro\n\n# read some data\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nprofiles = apro.reader.ReadProfiles(path).read()\n\n# basic corrections\nprofiles.extrapolate_below(z=150., inplace=True)\n\n# planetary boundary layer detection\nprofiles.pbl(zmin=200., zmax=3000., under_clouds=False, min_snr=2., verbose=True)\n\n# plot image with pbl tracking\nprofiles.plot(\n    zmax=6000., show_pbl=True, log=True, vmin=1e-2, vmax=1e1,\n    save_fig=\"examples/images/pbl.png\"\n)\n</code></pre> <p></p>"},{"location":"examples/#aerosol-retrieval","title":"Aerosol retrieval","text":""},{"location":"examples/#extinction","title":"Extinction","text":"<p>The aerosol extinction module retrieves extinction profiles by using a prescribed a priori (Lidar ratio, or AOD). Both backward and forward methods have been implemented and can be used in this module.</p> <pre><code>import aprofiles as apro\n\n# read some data\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nprofiles = apro.reader.ReadProfiles(path).read()\n\n# basic corrections\nprofiles.extrapolate_below(z=150., inplace=True)\n\n# aerosol retrievals - forward inversion\nprofiles.inversion(\n    zmin=4000., zmax=6000., remove_outliers=False, method=\"forward\", verbose=True\n)\n\n# plot extinction profiles\nprofiles.plot(\n    var=\"extinction\", zmax=6000., vmin=0., vmax=5e-2,\n    save_fig=\"examples/images/forward.png\"\n)\n</code></pre> <p></p>"},{"location":"examples/#concentration","title":"Concentration","text":"<p>Aerosol mass concentration is calculated by <code>inversion()</code>, if <code>mass_conc=True</code> (default), for different aerosol types when calculating the extinction profiles. Together with <code>extinction</code>, other variables are added to the instance of the <code>ProfilesData</code> class: <code>mass_concentration:[aer_type]</code>.</p> <pre><code>import aprofiles as apro\n\n# read some data\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nprofiles = apro.reader.ReadProfiles(path).read()\n\n# basic corrections\nprofiles.extrapolate_below(z=150., inplace=True)\n\n# aerosol retrievals - forward inversion\nprofiles.inversion(\n    zmin=4000., zmax=6000., remove_outliers=True, method=\"forward\", verbose=True\n)\n\n# plot mass concentration profiles im the case of desert dust\nprofiles.plot(\n    'mass_concentration:dust', zmax=6000., vmin=0., vmax=100., cmap='Oranges',\n    save_fig=\"examples/images/mass_conc-dust.png\"\n)\n</code></pre> <p></p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#via-pippipx","title":"via pip/pipx","text":"<p>aprofiles is directly available on pip. This will install the latest released version of aprofiles and its depencencies.</p> <pre><code>pip install aprofiles\n</code></pre>"},{"location":"installation/#via-github","title":"via Github","text":"<ol> <li> <p>clone aprofiles repository</p> <pre><code>git clone https://github.com/AugustinMortier/A-Profiles.git\n</code></pre> </li> <li> <p>installation</p> <p> with pip/pipx (&gt;21.3):</p> <pre><code>pip install .\n</code></pre> <p> with poetry:</p> <pre><code>poetry install\n</code></pre> </li> </ol>"},{"location":"api/data_classes/","title":"Data Classes","text":""},{"location":"api/data_classes/#profilesdata","title":"ProfilesData","text":"<p>The <code>ProfilesData</code> class contains profile data information. Most of the information can be found in the <code>data</code> attribute, which is an <code>xarray.Dataset</code>. Detection and retrieval methods might add information as additional <code>xarray.DataArray</code>.</p>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData","title":"<code>ProfilesData</code>","text":"<p>Base class representing profiles data returned by (aprofiles.reader.ReadProfiles):.</p> Source code in <code>aprofiles/profiles.py</code> <pre><code>class ProfilesData:\n    \"\"\"\n    Base class representing profiles data returned by (aprofiles.reader.ReadProfiles):.\n    \"\"\"\n\n    def __init__(self, data):\n        self.data = data\n\n    @property\n    def data(self):\n        \"\"\"\n        Data attribute (instance of (xarray.Dataset):)\n        \"\"\"\n        return self._data\n\n    @data.setter\n    def data(self, data):\n        if not isinstance(data, xr.Dataset):\n            raise ValueError(\"Wrong data type: an xarray Dataset is expected.\")\n        self._data = data\n\n    def _get_index_from_altitude_AGL(self, altitude):\n        \"\"\"\n        Returns the closest index of the ProfilesData vertical dimension to a given AGL altitude\n\n        Args:\n            altitude (float): in m, altitude AGL to look for\n\n        Returns:\n            (int): Closest index of the vertical dimension to the given altitude AGL\n        \"\"\"\n        return int(np.argmin(abs(self.data.altitude.data - altitude)))\n\n    def _get_indices_from_altitude_AGL(self, altitude):\n        \"\"\"\n        Returns an array of the closest indexes of the ProfilesData vertical dimension to given AGL altitudes\n\n        Args:\n            altitudes (array-like): in m, altitudes AGL to look for\n\n        Returns:\n            (np.ndarray): Array of closest indices of the vertical dimension to the given altitudes AGL\n        \"\"\"\n        altitudes = np.full_like(self.data.station_altitude.data, altitude)\n        closest_indices = [\n            int(np.argmin(abs(self.data.altitude.data - alt))) for alt in altitudes\n        ]\n        return closest_indices\n\n    def _get_resolution(self, which):\n        \"\"\"\n        Returns the resolution of a given dimension. Supports 'altitude' and 'time'.\n        The altitude resolution is given in meters, while the time resolution is given in seconds.\n\n        Args:\n            which (str): Dimension: must be ['altitude', 'time'].\n\n        Returns:\n            (float): resolution, in m (if which=='altitude') or in s (if which=='time')\n        \"\"\"\n        if which == \"altitude\":\n            return min(np.diff(self.data.altitude.data))\n        elif which == \"time\":\n            return (\n                min(np.diff(self.data.time.data)).astype(\"timedelta64[s]\").astype(int)\n            )\n\n    def _get_lowest_clouds(self):\n        # returns an array of the altitude (in m, ASL) of the lowest cloud for each timestamp\n        lowest_clouds = np.full(np.shape(self.data.time.data), np.nan)\n        for i, _ in enumerate(self.data.time.data):\n            clouds_profile = self.data.clouds[i, :]\n            i_clouds = np.squeeze(np.where(clouds_profile))\n            if len(i_clouds) &gt; 0:\n                lowest_clouds[i] = self.data.altitude.data[i_clouds[0]]\n        return lowest_clouds\n\n    def _get_itime(self, datetime):\n        \"\"\"\n        Returns the index of closest datetime available of the ProfilesData object.\n        \"\"\"\n        time = self.data.time.data\n        i_time = np.argmin(abs(time - datetime))\n        return i_time\n\n    def snr(self, var=\"attenuated_backscatter_0\", step=4, verbose=False):\n        \"\"\"\n        Method that calculates the Signal to Noise Ratio.\n\n        Args:\n            var (str, optional): Variable of the DataArray to calculate the SNR from.\n            step (int, optional): Number of steps around we calculate the SNR for a given altitude.\n            verbose (bool, optional): Verbose mode.\n\n        Returns:\n            (ProfilesData): object with additional (xarray.DataArray): `snr`.\n\n        Example:\n            ```python\n            import aprofiles as apro\n            # read example file\n            path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n            reader = apro.reader.ReadProfiles(path)\n            profiles = reader.read()\n            # snr calculation\n            profiles.snr()\n            # snr image\n            profiles.plot(var='snr',vmin=0, vmax=3, cmap='Greys_r')\n            ```\n        \"\"\"\n\n        # Get the dimensions of the data array\n        time_len, altitude_len = self.data[var].shape\n\n        # Preallocate the SNR array with zeros\n        snr_array = np.zeros((time_len, altitude_len))\n\n        # Loop over each time step\n        for t in track(range(time_len), description=\"snr   \", disable=not verbose):\n            # Extract 1D slice for current time step\n            array = self.data[var].data[t, :]\n\n            # Create a sliding window view for the rolling calculation\n            sliding_windows = np.lib.stride_tricks.sliding_window_view(\n                array, window_shape=2 * step + 1, axis=0\n            )\n\n            # Calculate mean and std across the window axis\n            means = np.nanmean(sliding_windows, axis=1)\n            stds = np.nanstd(sliding_windows, axis=1)\n\n            # Handle the edges (where sliding window can't be applied due to boundary)\n            means = np.pad(\n                means, pad_width=(step,), mode=\"constant\", constant_values=np.nan\n            )\n            stds = np.pad(\n                stds, pad_width=(step,), mode=\"constant\", constant_values=np.nan\n            )\n\n            # Avoid division by zero\n            stds = np.where(stds == 0, np.nan, stds)\n\n            # Compute SNR\n            snr_array[t, :] = np.divide(means, stds, where=(stds != 0))\n\n        # Add the SNR DataArray to the object's data attribute\n        self.data[\"snr\"] = ((\"time\", \"altitude\"), snr_array)\n        self.data[\"snr\"] = self.data.snr.assign_attrs(\n            {\"long_name\": \"Signal to Noise Ratio\", \"units\": \"\", \"step\": step}\n        )\n\n        return self\n\n    def gaussian_filter(\n        self, sigma=0.25, var=\"attenuated_backscatter_0\", inplace=False\n    ):\n        \"\"\"\n        Applies a 2D gaussian filter in order to reduce high frequency noise.\n\n        Args:\n            sigma (scalar or sequence of scalars, optional): Standard deviation for Gaussian kernel. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.\n            var (str, optional): variable name of the Dataset to be processed.\n            inplace (bool, optional): if True, replace the instance of the (ProfilesData): class.\n\n        Returns:\n            (ProfilesData): object with additional attributes `gaussian_filter` for the processed (xarray.DataArray):.\n\n        Example:\n            ```python\n            import aprofiles as apro\n            # read example file\n            path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n            reader = apro.reader.ReadProfiles(path)\n            profiles = reader.read()\n            # apply gaussian filtering\n            profiles.gaussian_filter(sigma=0.5, inplace=True)\n            profiles.data.attenuated_backscatter_0.attrs.gaussian_filter\n            0.50\n            ```\n\n            ![Before gaussian filtering](../../assets/images/attenuated_backscatter.png)\n            ![After gaussian filtering (sigma=0.5)](../../assets/images/gaussian_filter.png)\n        \"\"\"\n        import copy\n\n        from scipy.ndimage import gaussian_filter\n\n        # apply gaussian filter\n        filtered_data = gaussian_filter(self.data[var].data, sigma=sigma)\n\n        if inplace:\n            self.data[var].data = filtered_data\n            new_dataset = self\n        else:\n            copied_dataset = copy.deepcopy(self)\n            copied_dataset.data[var].data = filtered_data\n            new_dataset = copied_dataset\n        # add attribute\n        new_dataset.data[var].attrs[\"gaussian_filter\"] = sigma\n        return new_dataset\n\n    def time_avg(self, minutes, var=\"attenuated_backscatter_0\", inplace=False):\n        \"\"\"\n        Rolling median in the time dimension.\n\n        Args:\n            minutes (float): Number of minutes to average over.\n            var (str, optional): variable of the Dataset to be processed.\n            inplace (bool, optional): if True, replace the instance of the (ProfilesData): class.\n\n        Returns:\n            (ProfilesData):\n        \"\"\"\n        rcs = self.data[var].copy()\n        # time conversion from minutes to seconds\n        t_avg = minutes * 60\n        # time resolution in profiles data in seconds\n        dt_s = self._get_resolution(\"time\")\n        # number of timestamps to be to averaged\n        nt_avg = max([1, round(t_avg / dt_s)])\n        # rolling median\n        filtered_data = (\n            rcs.rolling(time=nt_avg, min_periods=1, center=True).median().data\n        )\n\n        if inplace:\n            self.data[var].data = filtered_data\n            new_dataset = self\n        else:\n            copied_dataset = copy.deepcopy(self)\n            copied_dataset.data[var].data = filtered_data\n            new_dataset = copied_dataset\n        # add attribute\n        new_dataset.data[var].attrs[\"time averaged (minutes)\"] = minutes\n        return new_dataset\n\n    def extrapolate_below(\n        self, var=\"attenuated_backscatter_0\", z=150, method=\"cst\", inplace=False\n    ):\n        \"\"\"\n        Method for extrapolating lowest layers below a certain altitude. This is of particular intrest for instruments subject to After Pulse effect, with saturated signal in the lowest layers.\n        We recommend to use a value of zmin=150m due to random values often found below that altitude which perturbs the clouds detection.\n\n        Args:\n            var (str, optional): variable of the :class:`xarray.Dataset` to be processed.\n            z (float, optional): Altitude (in m, AGL) below which the signal is extrapolated.\n            method ({'cst', 'lin'}, optional): Method to be used for extrapolation of lowest layers.\n            inplace (bool, optional): if True, replace the instance of the (ProfilesData): class.\n\n        Returns:\n            (ProfilesData): object with additional attributes:\n\n                - `extrapolation_low_layers_altitude_agl`\n                - `extrapolation_low_layers_method` for the processed (xarray.DataArray):.\n\n        Example:\n            ```python\n            import aprofiles as apro\n            # read example file\n            path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n            reader = apro.reader.ReadProfiles(path)\n            profiles = reader.read()\n            # desaturation below 4000m\n            profiles.extrapolate_below(z=150., inplace=True)\n            profiles.data.attenuated_backscatter_0.extrapolation_low_layers_altitude_agl\n            150\n            ```\n\n            ![Before extrapolation](../../assets/images/lowest.png)\n            ![After extrapolation](../../assets/images/lowest_extrap.png)\n        \"\"\"\n\n        # get index of z\n        imax = self._get_indices_from_altitude_AGL(z)\n        nt = np.shape(self.data[var].data)[0]\n\n        if method == \"cst\":\n            # get values at imax indices\n            data_zmax = np.array([self.data[var].data[t, imax[t]] for t in range(nt)])\n\n            # replace values\n            filling_matrice = np.array(\n                [np.full(max(imax), data_zmax[t]) for t in range(nt)]\n            )\n        elif method == \"lin\":\n            raise NotImplementedError(\"Linear extrapolation is not implemented yet\")\n        else:\n            raise ValueError(\"Expected string: lin or cst\")\n\n        if inplace:\n            for t in range(nt):\n                self.data[var].data[t, : imax[t]] = filling_matrice[t, : imax[t]]\n            new_profiles_data = self\n            filling_matrice[t, : imax[t]]\n        else:\n            copied_dataset = copy.deepcopy(self)\n            for t in range(nt):\n                copied_dataset.data[var].data[t, : imax[t]] = filling_matrice[\n                    t, : imax[t]\n                ]\n            new_profiles_data = copied_dataset\n\n        # add attributes\n        new_profiles_data.data[var].attrs[\"extrapolation_low_layers_altitude_agl\"] = z\n        new_profiles_data.data[var].attrs[\"extrapolation_low_layers_method\"] = method\n\n        return new_profiles_data\n\n    def range_correction(self, var=\"attenuated_backscatter_0\", inplace=False):\n        \"\"\"\n        Method that corrects the solid angle effect (1/z2) which makes that the backscatter beam is more unlikely to be detected with the square of the altitude.\n\n        Args:\n            var (str, optional): variable of the Dataset to be processed.\n            inplace (bool, optional): if True, replace the instance of the (ProfilesData): class.\n\n        Returns:\n            (ProfilesData):\n\n        .. warning::\n            Make sure that the range correction is not already applied to the selected variable.\n        \"\"\"\n\n        range_corrected_data = []\n\n        for i in range(len(self.data.time.data)):\n            # for the altitude correction, must one use the altitude above the ground level\n            z_agl = self.data.altitude.data - self.data.station_altitude.data[i]\n\n            data = self.data[var].data[i, :]\n            range_corrected_data.append(np.multiply(data, z_agl))\n\n        if inplace:\n            self.data[var].data = range_corrected_data\n            new_profiles_data = self\n        else:\n            copied_dataset = copy.deepcopy(self)\n            copied_dataset.data[var].data = range_corrected_data\n            new_profiles_data = copied_dataset\n\n        # add attribute\n        new_profiles_data.data[var].attrs[\"range correction\"] = True\n        # remove units\n        new_profiles_data.data[var].attrs[\"units\"] = None\n        return new_profiles_data\n\n    def desaturate_below(self, var=\"attenuated_backscatter_0\", z=4000.0, inplace=False):\n        \"\"\"\n        Remove saturation caused by clouds at low altitude which results in negative values above the maximum.\n        The absolute value of the signal is returned below the prescribed altitude.\n\n        Args:\n            var (str, optional): variable of the :class:`xarray.Dataset` to be processed.\n            z (float, optional): Altitude (in m, AGL) below which the signal is unsaturated.\n            inplace (bool, optional): if True, replace the instance of the (ProfilesData):.\n\n        Todo:\n            Refine method to desaturate only saturated areas.\n\n        Returns:\n            (ProfilesData): object with additional attribute `desaturate` for the processed (xarray.DataArray):.\n\n        .. warning::\n            For now, absolute values are returned everywhere below the prescribed altitude.\n\n        Example:\n            ```python\n            import aprofiles as apro\n            # read example file\n            path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n            reader = apro.reader.ReadProfiles(path)\n            profiles = reader.read()\n            # desaturation below 4000m\n            profiles.desaturate_below(z=4000., inplace=True)\n            profiles.data.attenuated_backscatter_0.desaturated\n            True\n            ```\n\n            ![Before desaturation](../../assets/images/saturated.png)\n            ![After desaturation](../../assets/images/desaturated.png)\n        \"\"\"\n\n        imax = self._get_indices_from_altitude_AGL(z)\n        unsaturated_data = copy.deepcopy(self.data[var].data)\n        for i in range(len(self.data.time.data)):\n            unsaturated_data[i, : imax[i]] = abs(unsaturated_data[i, : imax[i]])\n\n        if inplace:\n            self.data[var].data = unsaturated_data\n            new_profiles_data = self\n        else:\n            copied_dataset = copy.deepcopy(self)\n            copied_dataset.data[var].data = unsaturated_data\n            new_profiles_data = copied_dataset\n\n        # add attribute\n        new_profiles_data.data[var].attrs[\"desaturated\"] = str(True)\n        return new_profiles_data\n\n    def foc(\n        self,\n        method=\"cloud_base\",\n        var=\"attenuated_backscatter_0\",\n        z_snr=2000.0,\n        min_snr=2.0,\n        zmin_cloud=200.0,\n    ):\n        \"\"\"\n        Calls :meth:`aprofiles.detection.foc.detect_foc()`.\n        \"\"\"\n        return apro.detection.foc.detect_foc(\n            self, method, var, z_snr, min_snr, zmin_cloud\n        )\n\n    def clouds(\n        self,\n        method: Literal[\"dec\", \"vg\"] = \"dec\",\n        time_avg=1,\n        zmin=0,\n        thr_noise=5.0,\n        thr_clouds=4.0,\n        min_snr=0.0,\n        verbose=False,\n    ):\n        \"\"\"\n        Calls :meth:`aprofiles.detection.clouds.detect_clouds()`.\n        \"\"\"\n        return apro.detection.clouds.detect_clouds(\n            self, method, time_avg, zmin, thr_noise, thr_clouds, min_snr, verbose\n        )\n\n    def pbl(\n        self,\n        time_avg=1,\n        zmin=100.0,\n        zmax=3000.0,\n        wav_width=200.0,\n        under_clouds=True,\n        min_snr=2.0,\n        verbose=False,\n    ):\n        \"\"\"\n        Calls :meth:`aprofiles.detection.pbl.detect_pbl()`.\n        \"\"\"\n        return apro.detection.pbl.detect_pbl(\n            self, time_avg, zmin, zmax, wav_width, under_clouds, min_snr, verbose\n        )\n\n    def inversion(\n        self,\n        time_avg=1,\n        zmin=4000.0,\n        zmax=6000.0,\n        min_snr=0.0,\n        under_clouds=False,\n        method=\"forward\",\n        apriori={\"lr\": 50.0, \"mec\": False, \"use_cfg\": False},\n        remove_outliers=False,\n        mass_conc=True,\n        mass_conc_method=\"mortier_2013\",\n        verbose=False,\n    ):\n        \"\"\"\n        Calls :meth:`aprofiles.retrieval.extinction.inversion()` to calculate extinction profiles.\n        Calls :meth:`aprofiles.retrieval.mass_conc.mec()` to calculate Mass to Extinction coefficients if `mass_conc` is true (Default).\n        \"\"\"\n        apro.retrieval.extinction.inversion(\n            self,\n            time_avg,\n            zmin,\n            zmax,\n            min_snr,\n            under_clouds,\n            method,\n            apriori,\n            remove_outliers,\n            verbose,\n        )\n        if mass_conc:\n            apro.retrieval.mass_conc.concentration_profiles(\n                self, mass_conc_method, apriori\n            )\n        return apro\n\n    def plot(\n        self,\n        var=\"attenuated_backscatter_0\",\n        datetime=None,\n        zref=\"agl\",\n        zmin=None,\n        zmax=None,\n        vmin=None,\n        vmax=None,\n        log=False,\n        show_foc=False,\n        show_pbl=False,\n        show_clouds=False,\n        cmap=\"coolwarm\",\n        show_fig=True,\n        save_fig=None,\n        **kwargs\n    ):\n        \"\"\"\n        Plotting method.\n        Depending on the variable selected, this method will plot an image, a single profile or a time series of the requested variable.\n        See also :ref:`Plotting`.\n\n        Args:\n            var (str, optional): Variable to be plotted.\n            datetime (:class:`numpy.datetime64`, optional): if provided, plot the profile for closest time. If not, plot an image constructed on all profiles.\n            zref ({'agl', 'asl'}, optional): Base reference for the altitude axis.\n            zmin (float, optional): Minimum altitude AGL (m).\n            zmax (float, optional): Maximum altitude AGL (m).\n            vmin (float, optional): Minimum value.\n            vmax (float, optional): Maximum value.\n            log (bool, optional): Use logarithmic scale.\n            show_foc (bool, optional): Show fog or condensation retrievals.\n            show_pbl (bool, optional): Show PBL height retrievals.\n            show_clouds (bool, optional): Show clouds retrievals.\n            cmap (str, optional): Matplotlib colormap.\n            show_fig (bool, optional): Show Figure.\n            save_fig (str, optional): Path of the saved figure.\n        \"\"\"\n\n        # check if var is available\n        if var not in list(self.data.data_vars):\n            raise ValueError(\n                \"{} is not a valid variable. \\n List of available variables: {}\".format(\n                    var, list(self.data.data_vars)\n                )\n            )\n\n        # here, check the dimension. If the variable has only the time dimension, calls timeseries method\n        if datetime is None:\n            # check dimension of var\n            if len(list(self.data[var].dims)) == 2:\n                apro.plot.image.plot(\n                    self.data,\n                    var,\n                    zref,\n                    zmin,\n                    zmax,\n                    vmin,\n                    vmax,\n                    log,\n                    show_foc,\n                    show_pbl,\n                    show_clouds,\n                    cmap,\n                    show_fig,\n                    save_fig,\n                )\n            else:\n                apro.plot.timeseries.plot(self.data, var, show_fig, save_fig, **kwargs)\n        else:\n            apro.plot.profile.plot(\n                self.data,\n                datetime,\n                var,\n                zref,\n                zmin,\n                zmax,\n                vmin,\n                vmax,\n                log,\n                show_foc,\n                show_pbl,\n                show_clouds,\n                show_fig,\n                save_fig,\n            )\n\n    def write(self, base_dir=Path(\"examples\", \"data\", \"V-Profiles\"), verbose=False):\n        \"\"\"\n        Calls :meth:`aprofiles.io.write_profiles.write()`.\n        \"\"\"\n        apro.io.write_profiles.write(self, base_dir, verbose=verbose)\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.data","title":"<code>data</code>  <code>property</code> <code>writable</code>","text":"<p>Data attribute (instance of (xarray.Dataset):)</p>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.clouds","title":"<code>clouds(method='dec', time_avg=1, zmin=0, thr_noise=5.0, thr_clouds=4.0, min_snr=0.0, verbose=False)</code>","text":"<p>Calls :meth:<code>aprofiles.detection.clouds.detect_clouds()</code>.</p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def clouds(\n    self,\n    method: Literal[\"dec\", \"vg\"] = \"dec\",\n    time_avg=1,\n    zmin=0,\n    thr_noise=5.0,\n    thr_clouds=4.0,\n    min_snr=0.0,\n    verbose=False,\n):\n    \"\"\"\n    Calls :meth:`aprofiles.detection.clouds.detect_clouds()`.\n    \"\"\"\n    return apro.detection.clouds.detect_clouds(\n        self, method, time_avg, zmin, thr_noise, thr_clouds, min_snr, verbose\n    )\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.desaturate_below","title":"<code>desaturate_below(var='attenuated_backscatter_0', z=4000.0, inplace=False)</code>","text":"<p>Remove saturation caused by clouds at low altitude which results in negative values above the maximum. The absolute value of the signal is returned below the prescribed altitude.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>variable of the :class:<code>xarray.Dataset</code> to be processed.</p> <code>'attenuated_backscatter_0'</code> <code>z</code> <code>float</code> <p>Altitude (in m, AGL) below which the signal is unsaturated.</p> <code>4000.0</code> <code>inplace</code> <code>bool</code> <p>if True, replace the instance of the (ProfilesData):.</p> <code>False</code> Todo <p>Refine method to desaturate only saturated areas.</p> <p>Returns:</p> Type Description <code>ProfilesData): object with additional attribute `desaturate` for the processed (xarray.DataArray</code> <p>.</p> <p>.. warning::     For now, absolute values are returned everywhere below the prescribed altitude.</p> Example <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# desaturation below 4000m\nprofiles.desaturate_below(z=4000., inplace=True)\nprofiles.data.attenuated_backscatter_0.desaturated\nTrue\n</code></pre> <p> </p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def desaturate_below(self, var=\"attenuated_backscatter_0\", z=4000.0, inplace=False):\n    \"\"\"\n    Remove saturation caused by clouds at low altitude which results in negative values above the maximum.\n    The absolute value of the signal is returned below the prescribed altitude.\n\n    Args:\n        var (str, optional): variable of the :class:`xarray.Dataset` to be processed.\n        z (float, optional): Altitude (in m, AGL) below which the signal is unsaturated.\n        inplace (bool, optional): if True, replace the instance of the (ProfilesData):.\n\n    Todo:\n        Refine method to desaturate only saturated areas.\n\n    Returns:\n        (ProfilesData): object with additional attribute `desaturate` for the processed (xarray.DataArray):.\n\n    .. warning::\n        For now, absolute values are returned everywhere below the prescribed altitude.\n\n    Example:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # desaturation below 4000m\n        profiles.desaturate_below(z=4000., inplace=True)\n        profiles.data.attenuated_backscatter_0.desaturated\n        True\n        ```\n\n        ![Before desaturation](../../assets/images/saturated.png)\n        ![After desaturation](../../assets/images/desaturated.png)\n    \"\"\"\n\n    imax = self._get_indices_from_altitude_AGL(z)\n    unsaturated_data = copy.deepcopy(self.data[var].data)\n    for i in range(len(self.data.time.data)):\n        unsaturated_data[i, : imax[i]] = abs(unsaturated_data[i, : imax[i]])\n\n    if inplace:\n        self.data[var].data = unsaturated_data\n        new_profiles_data = self\n    else:\n        copied_dataset = copy.deepcopy(self)\n        copied_dataset.data[var].data = unsaturated_data\n        new_profiles_data = copied_dataset\n\n    # add attribute\n    new_profiles_data.data[var].attrs[\"desaturated\"] = str(True)\n    return new_profiles_data\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.extrapolate_below","title":"<code>extrapolate_below(var='attenuated_backscatter_0', z=150, method='cst', inplace=False)</code>","text":"<p>Method for extrapolating lowest layers below a certain altitude. This is of particular intrest for instruments subject to After Pulse effect, with saturated signal in the lowest layers. We recommend to use a value of zmin=150m due to random values often found below that altitude which perturbs the clouds detection.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>variable of the :class:<code>xarray.Dataset</code> to be processed.</p> <code>'attenuated_backscatter_0'</code> <code>z</code> <code>float</code> <p>Altitude (in m, AGL) below which the signal is extrapolated.</p> <code>150</code> <code>method</code> <code>{cst, lin}</code> <p>Method to be used for extrapolation of lowest layers.</p> <code>'cst'</code> <code>inplace</code> <code>bool</code> <p>if True, replace the instance of the (ProfilesData): class.</p> <code>False</code> <p>Returns:</p> Type Description <code>ProfilesData</code> <p>object with additional attributes:</p> <ul> <li><code>extrapolation_low_layers_altitude_agl</code></li> <li><code>extrapolation_low_layers_method</code> for the processed (xarray.DataArray):.</li> </ul> Example <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# desaturation below 4000m\nprofiles.extrapolate_below(z=150., inplace=True)\nprofiles.data.attenuated_backscatter_0.extrapolation_low_layers_altitude_agl\n150\n</code></pre> <p> </p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def extrapolate_below(\n    self, var=\"attenuated_backscatter_0\", z=150, method=\"cst\", inplace=False\n):\n    \"\"\"\n    Method for extrapolating lowest layers below a certain altitude. This is of particular intrest for instruments subject to After Pulse effect, with saturated signal in the lowest layers.\n    We recommend to use a value of zmin=150m due to random values often found below that altitude which perturbs the clouds detection.\n\n    Args:\n        var (str, optional): variable of the :class:`xarray.Dataset` to be processed.\n        z (float, optional): Altitude (in m, AGL) below which the signal is extrapolated.\n        method ({'cst', 'lin'}, optional): Method to be used for extrapolation of lowest layers.\n        inplace (bool, optional): if True, replace the instance of the (ProfilesData): class.\n\n    Returns:\n        (ProfilesData): object with additional attributes:\n\n            - `extrapolation_low_layers_altitude_agl`\n            - `extrapolation_low_layers_method` for the processed (xarray.DataArray):.\n\n    Example:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # desaturation below 4000m\n        profiles.extrapolate_below(z=150., inplace=True)\n        profiles.data.attenuated_backscatter_0.extrapolation_low_layers_altitude_agl\n        150\n        ```\n\n        ![Before extrapolation](../../assets/images/lowest.png)\n        ![After extrapolation](../../assets/images/lowest_extrap.png)\n    \"\"\"\n\n    # get index of z\n    imax = self._get_indices_from_altitude_AGL(z)\n    nt = np.shape(self.data[var].data)[0]\n\n    if method == \"cst\":\n        # get values at imax indices\n        data_zmax = np.array([self.data[var].data[t, imax[t]] for t in range(nt)])\n\n        # replace values\n        filling_matrice = np.array(\n            [np.full(max(imax), data_zmax[t]) for t in range(nt)]\n        )\n    elif method == \"lin\":\n        raise NotImplementedError(\"Linear extrapolation is not implemented yet\")\n    else:\n        raise ValueError(\"Expected string: lin or cst\")\n\n    if inplace:\n        for t in range(nt):\n            self.data[var].data[t, : imax[t]] = filling_matrice[t, : imax[t]]\n        new_profiles_data = self\n        filling_matrice[t, : imax[t]]\n    else:\n        copied_dataset = copy.deepcopy(self)\n        for t in range(nt):\n            copied_dataset.data[var].data[t, : imax[t]] = filling_matrice[\n                t, : imax[t]\n            ]\n        new_profiles_data = copied_dataset\n\n    # add attributes\n    new_profiles_data.data[var].attrs[\"extrapolation_low_layers_altitude_agl\"] = z\n    new_profiles_data.data[var].attrs[\"extrapolation_low_layers_method\"] = method\n\n    return new_profiles_data\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.foc","title":"<code>foc(method='cloud_base', var='attenuated_backscatter_0', z_snr=2000.0, min_snr=2.0, zmin_cloud=200.0)</code>","text":"<p>Calls :meth:<code>aprofiles.detection.foc.detect_foc()</code>.</p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def foc(\n    self,\n    method=\"cloud_base\",\n    var=\"attenuated_backscatter_0\",\n    z_snr=2000.0,\n    min_snr=2.0,\n    zmin_cloud=200.0,\n):\n    \"\"\"\n    Calls :meth:`aprofiles.detection.foc.detect_foc()`.\n    \"\"\"\n    return apro.detection.foc.detect_foc(\n        self, method, var, z_snr, min_snr, zmin_cloud\n    )\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.gaussian_filter","title":"<code>gaussian_filter(sigma=0.25, var='attenuated_backscatter_0', inplace=False)</code>","text":"<p>Applies a 2D gaussian filter in order to reduce high frequency noise.</p> <p>Parameters:</p> Name Type Description Default <code>sigma</code> <code>scalar or sequence of scalars</code> <p>Standard deviation for Gaussian kernel. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.</p> <code>0.25</code> <code>var</code> <code>str</code> <p>variable name of the Dataset to be processed.</p> <code>'attenuated_backscatter_0'</code> <code>inplace</code> <code>bool</code> <p>if True, replace the instance of the (ProfilesData): class.</p> <code>False</code> <p>Returns:</p> Type Description <code>ProfilesData): object with additional attributes `gaussian_filter` for the processed (xarray.DataArray</code> <p>.</p> Example <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# apply gaussian filtering\nprofiles.gaussian_filter(sigma=0.5, inplace=True)\nprofiles.data.attenuated_backscatter_0.attrs.gaussian_filter\n0.50\n</code></pre> <p> </p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def gaussian_filter(\n    self, sigma=0.25, var=\"attenuated_backscatter_0\", inplace=False\n):\n    \"\"\"\n    Applies a 2D gaussian filter in order to reduce high frequency noise.\n\n    Args:\n        sigma (scalar or sequence of scalars, optional): Standard deviation for Gaussian kernel. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.\n        var (str, optional): variable name of the Dataset to be processed.\n        inplace (bool, optional): if True, replace the instance of the (ProfilesData): class.\n\n    Returns:\n        (ProfilesData): object with additional attributes `gaussian_filter` for the processed (xarray.DataArray):.\n\n    Example:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # apply gaussian filtering\n        profiles.gaussian_filter(sigma=0.5, inplace=True)\n        profiles.data.attenuated_backscatter_0.attrs.gaussian_filter\n        0.50\n        ```\n\n        ![Before gaussian filtering](../../assets/images/attenuated_backscatter.png)\n        ![After gaussian filtering (sigma=0.5)](../../assets/images/gaussian_filter.png)\n    \"\"\"\n    import copy\n\n    from scipy.ndimage import gaussian_filter\n\n    # apply gaussian filter\n    filtered_data = gaussian_filter(self.data[var].data, sigma=sigma)\n\n    if inplace:\n        self.data[var].data = filtered_data\n        new_dataset = self\n    else:\n        copied_dataset = copy.deepcopy(self)\n        copied_dataset.data[var].data = filtered_data\n        new_dataset = copied_dataset\n    # add attribute\n    new_dataset.data[var].attrs[\"gaussian_filter\"] = sigma\n    return new_dataset\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.inversion","title":"<code>inversion(time_avg=1, zmin=4000.0, zmax=6000.0, min_snr=0.0, under_clouds=False, method='forward', apriori={'lr': 50.0, 'mec': False, 'use_cfg': False}, remove_outliers=False, mass_conc=True, mass_conc_method='mortier_2013', verbose=False)</code>","text":"<p>Calls :meth:<code>aprofiles.retrieval.extinction.inversion()</code> to calculate extinction profiles. Calls :meth:<code>aprofiles.retrieval.mass_conc.mec()</code> to calculate Mass to Extinction coefficients if <code>mass_conc</code> is true (Default).</p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def inversion(\n    self,\n    time_avg=1,\n    zmin=4000.0,\n    zmax=6000.0,\n    min_snr=0.0,\n    under_clouds=False,\n    method=\"forward\",\n    apriori={\"lr\": 50.0, \"mec\": False, \"use_cfg\": False},\n    remove_outliers=False,\n    mass_conc=True,\n    mass_conc_method=\"mortier_2013\",\n    verbose=False,\n):\n    \"\"\"\n    Calls :meth:`aprofiles.retrieval.extinction.inversion()` to calculate extinction profiles.\n    Calls :meth:`aprofiles.retrieval.mass_conc.mec()` to calculate Mass to Extinction coefficients if `mass_conc` is true (Default).\n    \"\"\"\n    apro.retrieval.extinction.inversion(\n        self,\n        time_avg,\n        zmin,\n        zmax,\n        min_snr,\n        under_clouds,\n        method,\n        apriori,\n        remove_outliers,\n        verbose,\n    )\n    if mass_conc:\n        apro.retrieval.mass_conc.concentration_profiles(\n            self, mass_conc_method, apriori\n        )\n    return apro\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.pbl","title":"<code>pbl(time_avg=1, zmin=100.0, zmax=3000.0, wav_width=200.0, under_clouds=True, min_snr=2.0, verbose=False)</code>","text":"<p>Calls :meth:<code>aprofiles.detection.pbl.detect_pbl()</code>.</p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def pbl(\n    self,\n    time_avg=1,\n    zmin=100.0,\n    zmax=3000.0,\n    wav_width=200.0,\n    under_clouds=True,\n    min_snr=2.0,\n    verbose=False,\n):\n    \"\"\"\n    Calls :meth:`aprofiles.detection.pbl.detect_pbl()`.\n    \"\"\"\n    return apro.detection.pbl.detect_pbl(\n        self, time_avg, zmin, zmax, wav_width, under_clouds, min_snr, verbose\n    )\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.plot","title":"<code>plot(var='attenuated_backscatter_0', datetime=None, zref='agl', zmin=None, zmax=None, vmin=None, vmax=None, log=False, show_foc=False, show_pbl=False, show_clouds=False, cmap='coolwarm', show_fig=True, save_fig=None, **kwargs)</code>","text":"<p>Plotting method. Depending on the variable selected, this method will plot an image, a single profile or a time series of the requested variable. See also :ref:<code>Plotting</code>.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>Variable to be plotted.</p> <code>'attenuated_backscatter_0'</code> <code>datetime</code> <p>class:<code>numpy.datetime64</code>, optional): if provided, plot the profile for closest time. If not, plot an image constructed on all profiles.</p> <code>None</code> <code>zref</code> <code>{agl, asl}</code> <p>Base reference for the altitude axis.</p> <code>'agl'</code> <code>zmin</code> <code>float</code> <p>Minimum altitude AGL (m).</p> <code>None</code> <code>zmax</code> <code>float</code> <p>Maximum altitude AGL (m).</p> <code>None</code> <code>vmin</code> <code>float</code> <p>Minimum value.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>Maximum value.</p> <code>None</code> <code>log</code> <code>bool</code> <p>Use logarithmic scale.</p> <code>False</code> <code>show_foc</code> <code>bool</code> <p>Show fog or condensation retrievals.</p> <code>False</code> <code>show_pbl</code> <code>bool</code> <p>Show PBL height retrievals.</p> <code>False</code> <code>show_clouds</code> <code>bool</code> <p>Show clouds retrievals.</p> <code>False</code> <code>cmap</code> <code>str</code> <p>Matplotlib colormap.</p> <code>'coolwarm'</code> <code>show_fig</code> <code>bool</code> <p>Show Figure.</p> <code>True</code> <code>save_fig</code> <code>str</code> <p>Path of the saved figure.</p> <code>None</code> Source code in <code>aprofiles/profiles.py</code> <pre><code>def plot(\n    self,\n    var=\"attenuated_backscatter_0\",\n    datetime=None,\n    zref=\"agl\",\n    zmin=None,\n    zmax=None,\n    vmin=None,\n    vmax=None,\n    log=False,\n    show_foc=False,\n    show_pbl=False,\n    show_clouds=False,\n    cmap=\"coolwarm\",\n    show_fig=True,\n    save_fig=None,\n    **kwargs\n):\n    \"\"\"\n    Plotting method.\n    Depending on the variable selected, this method will plot an image, a single profile or a time series of the requested variable.\n    See also :ref:`Plotting`.\n\n    Args:\n        var (str, optional): Variable to be plotted.\n        datetime (:class:`numpy.datetime64`, optional): if provided, plot the profile for closest time. If not, plot an image constructed on all profiles.\n        zref ({'agl', 'asl'}, optional): Base reference for the altitude axis.\n        zmin (float, optional): Minimum altitude AGL (m).\n        zmax (float, optional): Maximum altitude AGL (m).\n        vmin (float, optional): Minimum value.\n        vmax (float, optional): Maximum value.\n        log (bool, optional): Use logarithmic scale.\n        show_foc (bool, optional): Show fog or condensation retrievals.\n        show_pbl (bool, optional): Show PBL height retrievals.\n        show_clouds (bool, optional): Show clouds retrievals.\n        cmap (str, optional): Matplotlib colormap.\n        show_fig (bool, optional): Show Figure.\n        save_fig (str, optional): Path of the saved figure.\n    \"\"\"\n\n    # check if var is available\n    if var not in list(self.data.data_vars):\n        raise ValueError(\n            \"{} is not a valid variable. \\n List of available variables: {}\".format(\n                var, list(self.data.data_vars)\n            )\n        )\n\n    # here, check the dimension. If the variable has only the time dimension, calls timeseries method\n    if datetime is None:\n        # check dimension of var\n        if len(list(self.data[var].dims)) == 2:\n            apro.plot.image.plot(\n                self.data,\n                var,\n                zref,\n                zmin,\n                zmax,\n                vmin,\n                vmax,\n                log,\n                show_foc,\n                show_pbl,\n                show_clouds,\n                cmap,\n                show_fig,\n                save_fig,\n            )\n        else:\n            apro.plot.timeseries.plot(self.data, var, show_fig, save_fig, **kwargs)\n    else:\n        apro.plot.profile.plot(\n            self.data,\n            datetime,\n            var,\n            zref,\n            zmin,\n            zmax,\n            vmin,\n            vmax,\n            log,\n            show_foc,\n            show_pbl,\n            show_clouds,\n            show_fig,\n            save_fig,\n        )\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.range_correction","title":"<code>range_correction(var='attenuated_backscatter_0', inplace=False)</code>","text":"<p>Method that corrects the solid angle effect (1/z2) which makes that the backscatter beam is more unlikely to be detected with the square of the altitude.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>variable of the Dataset to be processed.</p> <code>'attenuated_backscatter_0'</code> <code>inplace</code> <code>bool</code> <p>if True, replace the instance of the (ProfilesData): class.</p> <code>False</code> <p>Returns:</p> Type Description <code>ProfilesData</code> <p>.. warning::     Make sure that the range correction is not already applied to the selected variable.</p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def range_correction(self, var=\"attenuated_backscatter_0\", inplace=False):\n    \"\"\"\n    Method that corrects the solid angle effect (1/z2) which makes that the backscatter beam is more unlikely to be detected with the square of the altitude.\n\n    Args:\n        var (str, optional): variable of the Dataset to be processed.\n        inplace (bool, optional): if True, replace the instance of the (ProfilesData): class.\n\n    Returns:\n        (ProfilesData):\n\n    .. warning::\n        Make sure that the range correction is not already applied to the selected variable.\n    \"\"\"\n\n    range_corrected_data = []\n\n    for i in range(len(self.data.time.data)):\n        # for the altitude correction, must one use the altitude above the ground level\n        z_agl = self.data.altitude.data - self.data.station_altitude.data[i]\n\n        data = self.data[var].data[i, :]\n        range_corrected_data.append(np.multiply(data, z_agl))\n\n    if inplace:\n        self.data[var].data = range_corrected_data\n        new_profiles_data = self\n    else:\n        copied_dataset = copy.deepcopy(self)\n        copied_dataset.data[var].data = range_corrected_data\n        new_profiles_data = copied_dataset\n\n    # add attribute\n    new_profiles_data.data[var].attrs[\"range correction\"] = True\n    # remove units\n    new_profiles_data.data[var].attrs[\"units\"] = None\n    return new_profiles_data\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.snr","title":"<code>snr(var='attenuated_backscatter_0', step=4, verbose=False)</code>","text":"<p>Method that calculates the Signal to Noise Ratio.</p> <p>Parameters:</p> Name Type Description Default <code>var</code> <code>str</code> <p>Variable of the DataArray to calculate the SNR from.</p> <code>'attenuated_backscatter_0'</code> <code>step</code> <code>int</code> <p>Number of steps around we calculate the SNR for a given altitude.</p> <code>4</code> <code>verbose</code> <code>bool</code> <p>Verbose mode.</p> <code>False</code> <p>Returns:</p> Type Description <code>ProfilesData): object with additional (xarray.DataArray</code> <p><code>snr</code>.</p> Example <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# snr calculation\nprofiles.snr()\n# snr image\nprofiles.plot(var='snr',vmin=0, vmax=3, cmap='Greys_r')\n</code></pre> Source code in <code>aprofiles/profiles.py</code> <pre><code>def snr(self, var=\"attenuated_backscatter_0\", step=4, verbose=False):\n    \"\"\"\n    Method that calculates the Signal to Noise Ratio.\n\n    Args:\n        var (str, optional): Variable of the DataArray to calculate the SNR from.\n        step (int, optional): Number of steps around we calculate the SNR for a given altitude.\n        verbose (bool, optional): Verbose mode.\n\n    Returns:\n        (ProfilesData): object with additional (xarray.DataArray): `snr`.\n\n    Example:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # snr calculation\n        profiles.snr()\n        # snr image\n        profiles.plot(var='snr',vmin=0, vmax=3, cmap='Greys_r')\n        ```\n    \"\"\"\n\n    # Get the dimensions of the data array\n    time_len, altitude_len = self.data[var].shape\n\n    # Preallocate the SNR array with zeros\n    snr_array = np.zeros((time_len, altitude_len))\n\n    # Loop over each time step\n    for t in track(range(time_len), description=\"snr   \", disable=not verbose):\n        # Extract 1D slice for current time step\n        array = self.data[var].data[t, :]\n\n        # Create a sliding window view for the rolling calculation\n        sliding_windows = np.lib.stride_tricks.sliding_window_view(\n            array, window_shape=2 * step + 1, axis=0\n        )\n\n        # Calculate mean and std across the window axis\n        means = np.nanmean(sliding_windows, axis=1)\n        stds = np.nanstd(sliding_windows, axis=1)\n\n        # Handle the edges (where sliding window can't be applied due to boundary)\n        means = np.pad(\n            means, pad_width=(step,), mode=\"constant\", constant_values=np.nan\n        )\n        stds = np.pad(\n            stds, pad_width=(step,), mode=\"constant\", constant_values=np.nan\n        )\n\n        # Avoid division by zero\n        stds = np.where(stds == 0, np.nan, stds)\n\n        # Compute SNR\n        snr_array[t, :] = np.divide(means, stds, where=(stds != 0))\n\n    # Add the SNR DataArray to the object's data attribute\n    self.data[\"snr\"] = ((\"time\", \"altitude\"), snr_array)\n    self.data[\"snr\"] = self.data.snr.assign_attrs(\n        {\"long_name\": \"Signal to Noise Ratio\", \"units\": \"\", \"step\": step}\n    )\n\n    return self\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.time_avg","title":"<code>time_avg(minutes, var='attenuated_backscatter_0', inplace=False)</code>","text":"<p>Rolling median in the time dimension.</p> <p>Parameters:</p> Name Type Description Default <code>minutes</code> <code>float</code> <p>Number of minutes to average over.</p> required <code>var</code> <code>str</code> <p>variable of the Dataset to be processed.</p> <code>'attenuated_backscatter_0'</code> <code>inplace</code> <code>bool</code> <p>if True, replace the instance of the (ProfilesData): class.</p> <code>False</code> <p>Returns:</p> Type Description <code>ProfilesData</code> Source code in <code>aprofiles/profiles.py</code> <pre><code>def time_avg(self, minutes, var=\"attenuated_backscatter_0\", inplace=False):\n    \"\"\"\n    Rolling median in the time dimension.\n\n    Args:\n        minutes (float): Number of minutes to average over.\n        var (str, optional): variable of the Dataset to be processed.\n        inplace (bool, optional): if True, replace the instance of the (ProfilesData): class.\n\n    Returns:\n        (ProfilesData):\n    \"\"\"\n    rcs = self.data[var].copy()\n    # time conversion from minutes to seconds\n    t_avg = minutes * 60\n    # time resolution in profiles data in seconds\n    dt_s = self._get_resolution(\"time\")\n    # number of timestamps to be to averaged\n    nt_avg = max([1, round(t_avg / dt_s)])\n    # rolling median\n    filtered_data = (\n        rcs.rolling(time=nt_avg, min_periods=1, center=True).median().data\n    )\n\n    if inplace:\n        self.data[var].data = filtered_data\n        new_dataset = self\n    else:\n        copied_dataset = copy.deepcopy(self)\n        copied_dataset.data[var].data = filtered_data\n        new_dataset = copied_dataset\n    # add attribute\n    new_dataset.data[var].attrs[\"time averaged (minutes)\"] = minutes\n    return new_dataset\n</code></pre>"},{"location":"api/data_classes/#aprofiles.profiles.ProfilesData.write","title":"<code>write(base_dir=Path('examples', 'data', 'V-Profiles'), verbose=False)</code>","text":"<p>Calls :meth:<code>aprofiles.io.write_profiles.write()</code>.</p> Source code in <code>aprofiles/profiles.py</code> <pre><code>def write(self, base_dir=Path(\"examples\", \"data\", \"V-Profiles\"), verbose=False):\n    \"\"\"\n    Calls :meth:`aprofiles.io.write_profiles.write()`.\n    \"\"\"\n    apro.io.write_profiles.write(self, base_dir, verbose=verbose)\n</code></pre>"},{"location":"api/data_classes/#aeronet","title":"Aeronet","text":"<p>Not implemented yet.</p>"},{"location":"api/data_classes/#aprofiles.aeronet.AeronetData","title":"<code>AeronetData</code>","text":"<p>Base class representing profiles data returned by (aprofiles.io.reader.ReadAeronet):.</p> Source code in <code>aprofiles/aeronet.py</code> <pre><code>class AeronetData:\n    \"\"\"\n    Base class representing profiles data returned by (aprofiles.io.reader.ReadAeronet):.\"\"\"\n\n    def __init__(self, data):\n        self.data = data\n        raise NotImplementedError(\"AeronetData is not implemented yet\")\n</code></pre>"},{"location":"api/data_classes/#rayleigh","title":"Rayleigh","text":"<p>The <code>RayleighData</code> class is used for producing Rayleigh profiles in a standard atmosphere.</p>"},{"location":"api/data_classes/#aprofiles.rayleigh.RayleighData","title":"<code>RayleighData</code>","text":"<p>Class for computing rayleigh profile in a standard atmosphere. This class calls the :func:<code>get_optics_in_std_atmo()</code> method, which produces profiles of <code>backscatter</code> and <code>extinction</code> coefficients.</p> <p>Attributes:</p> Name Type Description <code>altitude</code> <code>array - like</code> <p>array of altitude ASL to be used to compute the rayleigh profile, in m.</p> <code>wavelength</code> <code>float</code> <p>Wavelength of the Rayleigh profile to be computed, in nm.</p> <code>T0</code> <code>float</code> <p>Temperature at ground level, in K.</p> <code>P0</code> <code>float</code> <p>Pressure at ground level, in hPa.</p> Example <pre><code># some imports\nimport aprofiles as apro\nimport numpy as np\n# creates altitude array\naltitude = np.arange(15,15000,15)\nwavelength = 1064.\n# produce rayleigh profile\nrayleigh = apro.rayleigh.RayleighData(altitude, wavelength, T0=298, P0=1013);\n# checkout the instance attributes\nrayleigh.__dict__.keys()\ndict_keys(['altitude', 'T0', 'P0', 'wavelength', 'cross_section', 'backscatter', 'extinction'])\n</code></pre> Source code in <code>aprofiles/rayleigh.py</code> <pre><code>class RayleighData:\n    \"\"\"\n    Class for computing *rayleigh profile* in a standard atmosphere.\n    This class calls the :func:`get_optics_in_std_atmo()` method, which produces profiles of `backscatter` and `extinction` coefficients.\n\n    Attributes:\n        altitude (array-like): array of altitude ASL to be used to compute the rayleigh profile, in m.\n        wavelength (float): Wavelength of the Rayleigh profile to be computed, in nm.\n        T0 (float): Temperature at ground level, in K.\n        P0 (float): Pressure at ground level, in hPa.\n\n    Example:\n        ```python\n        # some imports\n        import aprofiles as apro\n        import numpy as np\n        # creates altitude array\n        altitude = np.arange(15,15000,15)\n        wavelength = 1064.\n        # produce rayleigh profile\n        rayleigh = apro.rayleigh.RayleighData(altitude, wavelength, T0=298, P0=1013);\n        # checkout the instance attributes\n        rayleigh.__dict__.keys()\n        dict_keys(['altitude', 'T0', 'P0', 'wavelength', 'cross_section', 'backscatter', 'extinction'])\n        ```\n    \"\"\"\n\n    def __init__(self, altitude: list, wavelength: float, T0=298, P0=1013):\n        self.altitude = altitude\n        self.T0 = T0\n        self.P0 = P0\n        self.wavelength = wavelength\n\n        # calls functions\n        self.get_optics_in_std_atmo()\n\n    def get_optics_in_std_atmo(self):\n        \"\"\"\n        Function that returns *backscatter* and *extinction* profiles [#]_ for an instance of a (RayleighData): class.\n\n        .. [#] Bucholtz, A. (1995). Rayleigh-scattering calculations for the terrestrial atmosphere. Applied optics, 34(15), 2765-2773.\n\n        Returns:\n            (aprofiles.rayleigh.RayleighData): object with additional attributes:\n\n                - `extinction` (numpy.ndarray): extinction coefficient (m-1)\n                - `backscatter` (numpy.ndarray): backscatter coefficient (m-1.sr-1)\n                - `cross_section` (numpy.ndarray): cross section (cm-2)\n        \"\"\"\n\n        def _refi_air(wavelength):\n            \"\"\"\n            Function that calculates the refractive index of the air at a given wavelength in a standard atmosphere [#]_.\n\n            .. [#] Peck, E. R., &amp; Reeder, K. (1972). Dispersion of air. JOSA, 62(8), 958-962.\n\n            Args:\n                wavelength (float): wavelength, in \u00b5m.\n\n            Returns:\n                refractive index of the air.\n            \"\"\"\n            # wav (float): wavelength in \u00b5m\n            # returns refractive index of the air in standard atmosphere (Peck and Reeder)\n            var = (\n                8060.51\n                + 2480990 / (132.274 - wavelength ** -2)\n                + 17455.7 / (39.32957 - wavelength ** -2)\n            )\n            return var * 1e-8 + 1\n\n        # standard values at sea level\n        T0 = 298  # K\n        P0 = 1013 * 1e2  # Pa\n        p_He = 8\n\n        # standard gradients &amp; parameters\n        atmo = {\n            \"tropo\": {\"zmin\": 0, \"zmax\": 13, \"dTdz\": -6.5},\n            \"strato\": {\"zmin\": 13, \"zmax\": 55, \"dTdz\": 1.4},\n            \"meso\": {\"zmin\": 55, \"zmax\": 100, \"dTdz\": -2.4},\n        }\n\n        # convert altitude to km\n        z = self.altitude / 1000\n\n        # vertical resolution\n        dz = min(z[1:] - z[0:-1])\n\n        # temperature profile\n        Tz = [T0]\n        for layer in atmo.keys():\n            ibottom = int(np.floor(atmo[layer][\"zmin\"] / dz))\n            itop = int(np.floor(atmo[layer][\"zmax\"] / dz))\n            for i in range(ibottom, itop):\n                Tz.append(Tz[ibottom] + (i - ibottom) * atmo[layer][\"dTdz\"] * dz)\n\n        # vertical coordinates for temperature\n        z_Tz = np.arange(0, 100, dz)\n\n        # pressure profile\n        Pz = P0 * np.exp(-z_Tz / p_He)\n\n        # molecules density and cross section\n        Ns = (6.02214e23 / 22.4141) / 1000  # molecules.cm-3\n        # density (cm-3)\n        N_m = [Ns * (T0 / P0) * (Pz[i] / Tz[i]) for i in range(len(Pz))]\n\n        # cross section, in cm2 (adapted from Bodhaine et al., 1999)\n        king_factor = 1.05  # tomasi et al., 2005\n        num = 24 * (np.pi ** 3) * ((_refi_air(self.wavelength * 1e-3) ** 2 - 1) ** 2)\n        denum = (\n            ((self.wavelength * 1e-7) ** 4)\n            * (Ns ** 2)\n            * ((_refi_air(self.wavelength * 1e-3) ** 2 + 2) ** 2)\n        )\n        section_m = (num / denum) * king_factor\n\n        # extinction profile\n        amol = N_m * np.array(section_m)\n        # backscatter profile\n        lr_mol = 8 * np.pi / 3\n        bmol = amol / lr_mol\n\n        # colocate vertically to input altitude\n        imin = np.argmin(np.abs(np.array(z_Tz) - z[0]))\n        imax = imin + len(z)\n\n        # output\n        self.cross_section = section_m  # in cm2\n        self.backscatter = bmol[imin:imax] * 1e2  # from cm-1 to m-1\n        self.extinction = amol[imin:imax] * 1e2  # from cm-1 to m-1\n        self.tau = np.cumsum(self.extinction*(dz*1000))[-1]\n\n        return self\n\n    def plot(self, show_fig=True):\n        \"\"\"\n        Plot extinction profile of an instance of the (RayleighData): class.\n\n        Example:\n            ```python\n            # some imports\n            import aprofiles as apro\n            import numpy as np\n            # creates altitude array\n            altitude = np.arange(15,15000,15)\n            wavelength = 1064.\n            # produce rayleigh profile\n            rayleigh = apro.rayleigh.RayleighData(altitude, wavelength, T0=298, P0=1013);\n            # plot profile\n            rayleigh.plot()\n            ```\n\n            .. figure:: ../../docs/assets/images/rayleigh.png\n                :scale: 80 %\n                :alt: rayleigh profile\n\n                Rayleigh extinction profile for a standard atmosphere.\n        \"\"\"\n\n        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n        plt.plot(self.extinction, self.altitude)\n        plt.text(\n            0.97,\n            0.94,\n            f\"$\\sigma_m: {self.cross_section:.2e} cm2$\",\n            horizontalalignment=\"right\",\n            verticalalignment=\"center\",\n            transform=ax.transAxes,\n        )\n        plt.text(\n            0.97,\n            0.88,\n            f\"$\\u03C4_m: {self.tau:.2e}$\",\n            horizontalalignment=\"right\",\n            verticalalignment=\"center\",\n            transform=ax.transAxes,\n        )\n\n        plt.title(\n            f\"Rayleigh Profile in a Standard Atmosphere ({self.P0}hPa, {self.T0}K)\",\n            weight=\"bold\",\n        )\n        plt.xlabel(f\"Extinction coefficient @ {self.wavelength} nm (m-1)\")\n        plt.ylabel(\"Altitude ASL (m)\")\n        plt.tight_layout()\n        if show_fig:\n            plt.show()\n</code></pre>"},{"location":"api/data_classes/#aprofiles.rayleigh.RayleighData.get_optics_in_std_atmo","title":"<code>get_optics_in_std_atmo()</code>","text":"<p>Function that returns backscatter and extinction profiles [#]_ for an instance of a (RayleighData): class.</p> <p>.. [#] Bucholtz, A. (1995). Rayleigh-scattering calculations for the terrestrial atmosphere. Applied optics, 34(15), 2765-2773.</p> <p>Returns:</p> Type Description <code>RayleighData</code> <p>object with additional attributes:</p> <ul> <li><code>extinction</code> (numpy.ndarray): extinction coefficient (m-1)</li> <li><code>backscatter</code> (numpy.ndarray): backscatter coefficient (m-1.sr-1)</li> <li><code>cross_section</code> (numpy.ndarray): cross section (cm-2)</li> </ul> Source code in <code>aprofiles/rayleigh.py</code> <pre><code>def get_optics_in_std_atmo(self):\n    \"\"\"\n    Function that returns *backscatter* and *extinction* profiles [#]_ for an instance of a (RayleighData): class.\n\n    .. [#] Bucholtz, A. (1995). Rayleigh-scattering calculations for the terrestrial atmosphere. Applied optics, 34(15), 2765-2773.\n\n    Returns:\n        (aprofiles.rayleigh.RayleighData): object with additional attributes:\n\n            - `extinction` (numpy.ndarray): extinction coefficient (m-1)\n            - `backscatter` (numpy.ndarray): backscatter coefficient (m-1.sr-1)\n            - `cross_section` (numpy.ndarray): cross section (cm-2)\n    \"\"\"\n\n    def _refi_air(wavelength):\n        \"\"\"\n        Function that calculates the refractive index of the air at a given wavelength in a standard atmosphere [#]_.\n\n        .. [#] Peck, E. R., &amp; Reeder, K. (1972). Dispersion of air. JOSA, 62(8), 958-962.\n\n        Args:\n            wavelength (float): wavelength, in \u00b5m.\n\n        Returns:\n            refractive index of the air.\n        \"\"\"\n        # wav (float): wavelength in \u00b5m\n        # returns refractive index of the air in standard atmosphere (Peck and Reeder)\n        var = (\n            8060.51\n            + 2480990 / (132.274 - wavelength ** -2)\n            + 17455.7 / (39.32957 - wavelength ** -2)\n        )\n        return var * 1e-8 + 1\n\n    # standard values at sea level\n    T0 = 298  # K\n    P0 = 1013 * 1e2  # Pa\n    p_He = 8\n\n    # standard gradients &amp; parameters\n    atmo = {\n        \"tropo\": {\"zmin\": 0, \"zmax\": 13, \"dTdz\": -6.5},\n        \"strato\": {\"zmin\": 13, \"zmax\": 55, \"dTdz\": 1.4},\n        \"meso\": {\"zmin\": 55, \"zmax\": 100, \"dTdz\": -2.4},\n    }\n\n    # convert altitude to km\n    z = self.altitude / 1000\n\n    # vertical resolution\n    dz = min(z[1:] - z[0:-1])\n\n    # temperature profile\n    Tz = [T0]\n    for layer in atmo.keys():\n        ibottom = int(np.floor(atmo[layer][\"zmin\"] / dz))\n        itop = int(np.floor(atmo[layer][\"zmax\"] / dz))\n        for i in range(ibottom, itop):\n            Tz.append(Tz[ibottom] + (i - ibottom) * atmo[layer][\"dTdz\"] * dz)\n\n    # vertical coordinates for temperature\n    z_Tz = np.arange(0, 100, dz)\n\n    # pressure profile\n    Pz = P0 * np.exp(-z_Tz / p_He)\n\n    # molecules density and cross section\n    Ns = (6.02214e23 / 22.4141) / 1000  # molecules.cm-3\n    # density (cm-3)\n    N_m = [Ns * (T0 / P0) * (Pz[i] / Tz[i]) for i in range(len(Pz))]\n\n    # cross section, in cm2 (adapted from Bodhaine et al., 1999)\n    king_factor = 1.05  # tomasi et al., 2005\n    num = 24 * (np.pi ** 3) * ((_refi_air(self.wavelength * 1e-3) ** 2 - 1) ** 2)\n    denum = (\n        ((self.wavelength * 1e-7) ** 4)\n        * (Ns ** 2)\n        * ((_refi_air(self.wavelength * 1e-3) ** 2 + 2) ** 2)\n    )\n    section_m = (num / denum) * king_factor\n\n    # extinction profile\n    amol = N_m * np.array(section_m)\n    # backscatter profile\n    lr_mol = 8 * np.pi / 3\n    bmol = amol / lr_mol\n\n    # colocate vertically to input altitude\n    imin = np.argmin(np.abs(np.array(z_Tz) - z[0]))\n    imax = imin + len(z)\n\n    # output\n    self.cross_section = section_m  # in cm2\n    self.backscatter = bmol[imin:imax] * 1e2  # from cm-1 to m-1\n    self.extinction = amol[imin:imax] * 1e2  # from cm-1 to m-1\n    self.tau = np.cumsum(self.extinction*(dz*1000))[-1]\n\n    return self\n</code></pre>"},{"location":"api/data_classes/#aprofiles.rayleigh.RayleighData.plot","title":"<code>plot(show_fig=True)</code>","text":"<p>Plot extinction profile of an instance of the (RayleighData): class.</p> Example <pre><code># some imports\nimport aprofiles as apro\nimport numpy as np\n# creates altitude array\naltitude = np.arange(15,15000,15)\nwavelength = 1064.\n# produce rayleigh profile\nrayleigh = apro.rayleigh.RayleighData(altitude, wavelength, T0=298, P0=1013);\n# plot profile\nrayleigh.plot()\n</code></pre> <p>.. figure:: ../../docs/assets/images/rayleigh.png     :scale: 80 %     :alt: rayleigh profile</p> <pre><code>Rayleigh extinction profile for a standard atmosphere.\n</code></pre> Source code in <code>aprofiles/rayleigh.py</code> <pre><code>def plot(self, show_fig=True):\n    \"\"\"\n    Plot extinction profile of an instance of the (RayleighData): class.\n\n    Example:\n        ```python\n        # some imports\n        import aprofiles as apro\n        import numpy as np\n        # creates altitude array\n        altitude = np.arange(15,15000,15)\n        wavelength = 1064.\n        # produce rayleigh profile\n        rayleigh = apro.rayleigh.RayleighData(altitude, wavelength, T0=298, P0=1013);\n        # plot profile\n        rayleigh.plot()\n        ```\n\n        .. figure:: ../../docs/assets/images/rayleigh.png\n            :scale: 80 %\n            :alt: rayleigh profile\n\n            Rayleigh extinction profile for a standard atmosphere.\n    \"\"\"\n\n    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n    plt.plot(self.extinction, self.altitude)\n    plt.text(\n        0.97,\n        0.94,\n        f\"$\\sigma_m: {self.cross_section:.2e} cm2$\",\n        horizontalalignment=\"right\",\n        verticalalignment=\"center\",\n        transform=ax.transAxes,\n    )\n    plt.text(\n        0.97,\n        0.88,\n        f\"$\\u03C4_m: {self.tau:.2e}$\",\n        horizontalalignment=\"right\",\n        verticalalignment=\"center\",\n        transform=ax.transAxes,\n    )\n\n    plt.title(\n        f\"Rayleigh Profile in a Standard Atmosphere ({self.P0}hPa, {self.T0}K)\",\n        weight=\"bold\",\n    )\n    plt.xlabel(f\"Extinction coefficient @ {self.wavelength} nm (m-1)\")\n    plt.ylabel(\"Altitude ASL (m)\")\n    plt.tight_layout()\n    if show_fig:\n        plt.show()\n</code></pre>"},{"location":"api/data_classes/#size-distribution","title":"Size Distribution","text":"<p>The size distribution module is used to produce volume and number size distributions of a population of particles for a given type. The values describing the size distribution for different aerosol types are taken from the literature:</p> <ul> <li><code>dust</code>, <code>biomass_burning</code>, and <code>urban</code> aerosols<sup>1</sup></li> <li><code>volcanic_ash</code><sup>2</sup></li> </ul> <p>Aerosol properties are defined in <code>config/aer_properties.json</code></p>"},{"location":"api/data_classes/#aprofiles.size_distribution.SizeDistributionData","title":"<code>SizeDistributionData</code>","text":"<p>Class for computing size distributions for a given aerosol type. This class calls the <code>aprofiles.size_distribution.SizeDistributionData.get_sd</code>: method, which calculates VSD (Volume Size Distribution) and NSD (Number Size Distribution).</p> <p>Attributes:</p> Name Type Description <code>`aer_type`</code> <code>{dust, volcanic_ash, biomass_burning, urban}</code> <p>aerosol type.</p> <code>`aer_properties`</code> <code>dict</code> <p>dictionnary describing the optical and microphophysical properties of the prescribed aerosol (read from aer_properties.json)</p> Example <pre><code># some imports\nimport aprofiles as apro\nsd = apro.size_distribution.SizeDistributionData('urban')\n# checkout the instance attributes\napro.size_distribution.SizeDistributionData('dust').__dict__.keys()\ndict_keys(['aer_type', 'aer_properties', 'radius', 'vsd', 'nsd'])\n</code></pre> Source code in <code>aprofiles/size_distribution.py</code> <pre><code>class SizeDistributionData:\n    \"\"\"\n    Class for computing *size distributions* for a given aerosol type.\n    This class calls the `aprofiles.size_distribution.SizeDistributionData.get_sd`: method, which calculates VSD (Volume Size Distribution) and NSD (Number Size Distribution).\n\n    Attributes:\n        `aer_type` ({'dust', 'volcanic_ash', 'biomass_burning','urban'}): aerosol type.\n        `aer_properties` (dict): dictionnary describing the optical and microphophysical properties of the prescribed aerosol (read from *aer_properties.json*)\n\n    Example:\n        ```python\n        # some imports\n        import aprofiles as apro\n        sd = apro.size_distribution.SizeDistributionData('urban')\n        # checkout the instance attributes\n        apro.size_distribution.SizeDistributionData('dust').__dict__.keys()\n        dict_keys(['aer_type', 'aer_properties', 'radius', 'vsd', 'nsd'])\n        ```\n    \"\"\"\n\n    def __init__(self, aer_type):\n        self.aer_type = aer_type\n\n        # read aer_properties.json files\n        f = open(Path(Path(__file__).parent,'config','aer_properties.json'))\n        aer_properties = json.load(f)\n        f.close()\n        # check if the aer_type exist in the json file\n        if aer_type not in aer_properties.keys():\n            raise ValueError(\n                f\"{aer_type} not found in aer_properties.json. `aer_type` must be one of the follwowing: {list(aer_properties.keys())}\"\n            )\n        else:\n            self.aer_properties = aer_properties[self.aer_type]\n            self.get_sd()\n\n    def _vsd_to_nsd(self):\n        \"\"\"\n        Transforms Volume Size Distribution to Number Size Distribution\n        \"\"\"\n        self.nsd = [\n            self.vsd[i] * 3 / (4 * np.pi * self.radius[i] ** 4)\n            for i in range(len(self.radius))\n        ]\n        return self\n\n    def get_sd(self):\n        \"\"\"\n        Returns the Volume and Number Size Distributions arrays from an instance of the (SizeDistributionData): class .\n\n        Returns:\n            (SizeDistribData): object with additional attributes:\n\n                - `radius` (numpy.ndarray): radius (\u00b5m)\n                - `vsd` (numpy.ndarray): Volume Size Distribution (\u00b5m2.\u00b5m-3)\n                - `nsd` (numpy.ndarray): Number Size Distribution (\u00b5m-3.\u00b5m-1)\n        \"\"\"\n\n        aer_properties = self.aer_properties\n        radius = np.arange(1e-2, 2e1, 1e-3)  # radius in \u00b5m\n        vsd = np.zeros(len(radius))\n\n        # we loop though all the keys defining the different modes\n        for mode in aer_properties[\"vsd\"].keys():\n            vsd += utils.gaussian(\n                np.log(radius),\n                np.log(aer_properties[\"vsd\"][mode][\"reff\"]),\n                aer_properties[\"vsd\"][mode][\"rstd\"],\n                aer_properties[\"vsd\"][mode][\"conc\"],\n            )\n\n        self.radius = radius\n        self.vsd = vsd\n        self._vsd_to_nsd()\n\n        return self\n\n    def plot(self, show_fig=True):\n        \"\"\"\n        Plot Size Distributions of an instance of the (SizeDistributionData): class.\n\n        Example:\n            ```python\n            # import aprofiles\n            import aprofiles as apro\n            # get size distribution for urban particles\n            sd = apro.size_distribution.SizeDistribData('urban');\n            # plot profile\n            sd.plot()\n            ```\n\n            ![Size distributions for urban particles](../../assets/images/urban_sd.png)\n        \"\"\"\n        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n\n        # plot Volume Size Distribution in 1st axis\n        print(self.vsd)\n        ax.plot(self.radius, self.vsd, label=\"VSD\")\n        ax.set_ylabel(\"V(r) (\u00b5m2.\u00b5m-3)\")\n\n        # plot Number Size Distribution in 2nd axis\n        if \"nsd\" in self.__dict__:\n            # add secondary yaxis\n            ax2 = ax.twinx()\n            ax2.plot(self.radius, self.nsd, \"orange\", label=\"NSD\")\n            ax2.set_ylabel(\"N(r) (\u00b5m-3.\u00b5m-1)\")\n            # ax2.set_ylim([0,10])\n\n        ax.set_xlabel(\"Radius (\u00b5m)\")\n        ax.set_xscale(\"log\")\n        fig.legend(\n            loc=\"upper right\", bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes\n        )\n        plt.title(\n            f\"Size Distribution for {self.aer_type.capitalize().replace('_', ' ')} Particles\",\n            weight=\"bold\",\n        )\n        plt.tight_layout()\n        if show_fig:\n            plt.show()\n</code></pre>"},{"location":"api/data_classes/#aprofiles.size_distribution.SizeDistributionData.get_sd","title":"<code>get_sd()</code>","text":"<p>Returns the Volume and Number Size Distributions arrays from an instance of the (SizeDistributionData): class .</p> <p>Returns:</p> Type Description <code>SizeDistribData</code> <p>object with additional attributes:</p> <ul> <li><code>radius</code> (numpy.ndarray): radius (\u00b5m)</li> <li><code>vsd</code> (numpy.ndarray): Volume Size Distribution (\u00b5m2.\u00b5m-3)</li> <li><code>nsd</code> (numpy.ndarray): Number Size Distribution (\u00b5m-3.\u00b5m-1)</li> </ul> Source code in <code>aprofiles/size_distribution.py</code> <pre><code>def get_sd(self):\n    \"\"\"\n    Returns the Volume and Number Size Distributions arrays from an instance of the (SizeDistributionData): class .\n\n    Returns:\n        (SizeDistribData): object with additional attributes:\n\n            - `radius` (numpy.ndarray): radius (\u00b5m)\n            - `vsd` (numpy.ndarray): Volume Size Distribution (\u00b5m2.\u00b5m-3)\n            - `nsd` (numpy.ndarray): Number Size Distribution (\u00b5m-3.\u00b5m-1)\n    \"\"\"\n\n    aer_properties = self.aer_properties\n    radius = np.arange(1e-2, 2e1, 1e-3)  # radius in \u00b5m\n    vsd = np.zeros(len(radius))\n\n    # we loop though all the keys defining the different modes\n    for mode in aer_properties[\"vsd\"].keys():\n        vsd += utils.gaussian(\n            np.log(radius),\n            np.log(aer_properties[\"vsd\"][mode][\"reff\"]),\n            aer_properties[\"vsd\"][mode][\"rstd\"],\n            aer_properties[\"vsd\"][mode][\"conc\"],\n        )\n\n    self.radius = radius\n    self.vsd = vsd\n    self._vsd_to_nsd()\n\n    return self\n</code></pre>"},{"location":"api/data_classes/#aprofiles.size_distribution.SizeDistributionData.plot","title":"<code>plot(show_fig=True)</code>","text":"<p>Plot Size Distributions of an instance of the (SizeDistributionData): class.</p> Example <pre><code># import aprofiles\nimport aprofiles as apro\n# get size distribution for urban particles\nsd = apro.size_distribution.SizeDistribData('urban');\n# plot profile\nsd.plot()\n</code></pre> <p></p> Source code in <code>aprofiles/size_distribution.py</code> <pre><code>def plot(self, show_fig=True):\n    \"\"\"\n    Plot Size Distributions of an instance of the (SizeDistributionData): class.\n\n    Example:\n        ```python\n        # import aprofiles\n        import aprofiles as apro\n        # get size distribution for urban particles\n        sd = apro.size_distribution.SizeDistribData('urban');\n        # plot profile\n        sd.plot()\n        ```\n\n        ![Size distributions for urban particles](../../assets/images/urban_sd.png)\n    \"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n\n    # plot Volume Size Distribution in 1st axis\n    print(self.vsd)\n    ax.plot(self.radius, self.vsd, label=\"VSD\")\n    ax.set_ylabel(\"V(r) (\u00b5m2.\u00b5m-3)\")\n\n    # plot Number Size Distribution in 2nd axis\n    if \"nsd\" in self.__dict__:\n        # add secondary yaxis\n        ax2 = ax.twinx()\n        ax2.plot(self.radius, self.nsd, \"orange\", label=\"NSD\")\n        ax2.set_ylabel(\"N(r) (\u00b5m-3.\u00b5m-1)\")\n        # ax2.set_ylim([0,10])\n\n    ax.set_xlabel(\"Radius (\u00b5m)\")\n    ax.set_xscale(\"log\")\n    fig.legend(\n        loc=\"upper right\", bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes\n    )\n    plt.title(\n        f\"Size Distribution for {self.aer_type.capitalize().replace('_', ' ')} Particles\",\n        weight=\"bold\",\n    )\n    plt.tight_layout()\n    if show_fig:\n        plt.show()\n</code></pre>"},{"location":"api/data_classes/#mass-to-extinction-coefficient","title":"Mass to Extinction Coefficient","text":"<p>The <code>MECData</code> class is used for computing a Mass to Extinction Coefficient for a given aerosol type.</p> <ol> <li> <p>Dubovik, O., Holben, B., Eck, T. F., Smirnov, A., Kaufman, Y. J., King, M. D., ... &amp; Slutsker, I. (2002). Variability of absorption and optical properties of key aerosol types observed in worldwide locations. Journal of the Atmospheric Sciences, 59(3), 590-608.\u00a0\u21a9</p> </li> <li> <p>Mortier, A., Goloub, P., Podvin, T., Deroo, C., Chaikovsky, A., Ajtai, N., ... &amp; Derimian, Y. (2013). Detection and characterization of volcanic ash plumes over Lille during the Eyjafjallaj\u00f6kull eruption. Atmospheric Chemistry and Physics, 13(7), 3705-3720.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/data_classes/#aprofiles.mec.MECData","title":"<code>MECData</code>","text":"<p>Class for computing the Mass to Extinction Coefficient for a given aerosol type. This class calls the <code>get_mec()</code> method.</p> <p>Attributes:</p> Name Type Description <code>`aer_type`</code> <code>{dust, volcanic_ash, biomass_burning, urban}</code> <p>aerosol type.</p> <code>`wavelength`</code> <code>int or float</code> <p>wavelength, in mm.</p> <code>`method`</code> <code>{mortier_2013, literature}</code> <p>method to retrieve or compute <code>MEC</code>.</p> <code>`aer_properties`</code> <code>dict</code> <p>dictionary describing the optical and micro-physical properties of the prescribed aerosol (read from aer_properties.json)</p> Example <pre><code>#some imports\nimport aprofiles as apro\nmec_data = MECData('volcanic_ash', 532.)\nmec_data.__dict__.keys()\ndict_keys(['aer_type', 'wavelength', 'aer_properties', 'nsd', 'vsd', 'radius', 'qext', 'conv_factor', 'mec'])\nprint(f'{mec_data.conv_factor:.2e} m {mec_data.mec):.2e} m2.g-1')\n6.21e-07 m 0.62 m2.g-1\n</code></pre> Source code in <code>aprofiles/mec.py</code> <pre><code>class MECData:\n    \"\"\"\n    Class for computing the *Mass to Extinction Coefficient* for a given aerosol type.\n    This class calls the [`get_mec()`](#aprofiles.mec.MECData.get_mec) method.\n\n    Attributes:\n       `aer_type` ({'dust', 'volcanic_ash', 'biomass_burning', 'urban'}): aerosol type.\n       `wavelength` (int or float): wavelength, in mm.\n       `method` ({'mortier_2013', 'literature'}): method to retrieve or compute `MEC`.\n       `aer_properties` (dict): dictionary describing the optical and micro-physical properties of the prescribed aerosol (read from *aer_properties.json*)\n\n    Example:\n        ```python\n        #some imports\n        import aprofiles as apro\n        mec_data = MECData('volcanic_ash', 532.)\n        mec_data.__dict__.keys()\n        dict_keys(['aer_type', 'wavelength', 'aer_properties', 'nsd', 'vsd', 'radius', 'qext', 'conv_factor', 'mec'])\n        print(f'{mec_data.conv_factor:.2e} m {mec_data.mec):.2e} m2.g-1')\n        6.21e-07 m 0.62 m2.g-1\n        ```\n    \"\"\"\n\n    def __init__(self, aer_type: str, wavelength: float, method: str = \"mortier_2013\"):\n\n        # check parameters type\n        if not isinstance(aer_type, str):\n            raise TypeError(\n                \"`aer_type` is expected to be a string. Got {} instead.\".format(\n                    type(aer_type)\n                )\n            )\n        if not isinstance(wavelength, (int, float)):\n            raise TypeError(\n                \"`wavelength` is expected to be an int or a float. Got {} instead\".format(\n                    type(wavelength)\n                )\n            )\n        available_methods = [\"mortier_2013\", \"literature\"]\n        if method not in available_methods:\n            raise ValueError(\n                \"Invalid `method`. AAvailable methods are {}\".format(available_methods)\n            )\n\n        self.aer_type = aer_type\n        self.wavelength = wavelength\n        self.method = method\n\n        if self.method == \"mortier_2013\":\n            # read aer_properties.json files\n            f = open(Path(Path(__file__).parent,'config','aer_properties.json'))\n            aer_properties = json.load(f)\n            f.close()\n            # check if the aer_type exist in the json file\n            if aer_type not in aer_properties.keys():\n                raise ValueError(\n                    \"{} not found in aer_properties.json. `aer_type` must be one of the follwowing: {}\".format(\n                        aer_type, list(aer_properties.keys())\n                    )\n                )\n            else:\n                self.aer_properties = aer_properties[self.aer_type]\n                self.get_mec()\n        elif self.method == \"literature\":\n            self.mec = 3.33  # CHECK V-PROFILES VALUES. CHECK CODE IN LAPTOP?\n            self.conv_factor = -99\n\n    def get_mec(self):\n        \"\"\"\n        Calculates the Extinction to Mass Coefficient for a given type of particles, assuming a prescribed size distribution shape (with unknown amplitude), density, and using [Mie theory](https://miepython.readthedocs.io) to calculate the extinction efficiency.\n\n        Returns:\n            (MECData): with additional attributes:\n\n                - `nsd` (1D Array): Number Size Distribution\n                - `vsd` (1D Array): Volume Size Distribution\n                - `radius` (1D Array): Radius in \u00b5m\n                - `x` (1D Array): Size parameter (unitless)\n                - `conv_factor` (float): Conversion factor in m\n                - `mec` (float): Extinction to Mass Coefficient in m\u00b2.g\u207b\u00b9\n\n       !!! note\n            For a population of particles, the extinction coefficient $\\sigma_{ext}$ (m\u207b\u00b9) can be written as follows:\n\n            $$\n            \\sigma_{ext} = \\int_{r_{min}}^{r_{max}} N(r) Q_{ext}(m, r, \\lambda) \\pi r^2 dr\n            $$\n\n            where $Q_{ext}$ is the `extinction efficiency` and $N(r)$ is the `Number Size Distribution` (NSD).\n\n            $Q_{ext}$ varies with the refractive index, $m$, the wavelength, $\\lambda$, and can be calculated for spherical particles using Mie theory.\n\n            The total aerosol mass concentration $M_0$ (\u00b5g.m\u207b\u00b3) can be expressed as:\n\n            $$\n            M_0 = \\int_{r_{min}}^{r_{max}} M(r) dr\n            $$\n\n            where $M(r)$ is the mass size distribution (MSD).\n\n            This can be rewritten in terms of NSD and MSD as:\n\n            $$\n            M_0 = \\int_{r_{min}}^{r_{max}} \\\\frac{4\\pi r^3}{3} \\\\rho N(r) dr\n            $$\n\n            where $\\\\rho$ is the particle density (kg.m\u207b\u00b3).\n\n            By normalizing the NSD with respect to the fine mode ($N(r) = N_0 N_1(r)$), we arrive at:\n\n            $$\n            M_0 = \\sigma_{ext} \\\\rho \\\\frac{4}{3} \\\\frac{\\int_{r_{min}}^{r_{max}} N_1(r) r^3 dr}{\\int_{r_{min}}^{r_{max}} N_1(r) Q_{ext}(m, r, \\lambda) r^2 dr}\n            $$\n\n            We define the `conversion factor` (in m) as:\n\n            $$\n            c_v = \\\\frac{4}{3} \\\\frac{\\int_{r_{min}}^{r_{max}} N_1(r) r^3 dr}{\\int_{r_{min}}^{r_{max}} N_1(r) Q_{ext}(m, r, \\lambda) r^2 dr}\n            $$\n\n            Thus, the equation simplifies to:\n\n            $$\n            M_0 = \\sigma_{ext} \\\\rho c_v\n            $$\n\n            Finally, the `Extinction to Mass Coefficient` (MEC, also called `mass extinction cross section`, usually in m\u00b2.g\u207b\u00b9) is defined as:\n\n            $$\n            MEC = \\\\frac{\\sigma_{ext}}{M_0} = \\\\frac{1}{\\\\rho c_v}\n            $$\n\n            with $\\\\rho$ expressed in g.m\u207b\u00b3.\n\n\n            &lt;table&gt;\n                &lt;thead&gt;\n                    &lt;tr&gt;\n                        &lt;th&gt;Aerosol Type&lt;/th&gt;\n                        &lt;th colspan=2&gt;Conversion Factor (\u00b5m)&lt;/th&gt;\n                        &lt;th colspan=2&gt;MEC (m\u00b2.g\u207b\u00b9) &lt;/th&gt;\n                    &lt;/tr&gt;\n                    &lt;tr&gt;\n                        &lt;th&gt;&lt;/th&gt;\n                        &lt;th&gt;532 nm&lt;/th&gt;\n                        &lt;th&gt;1064 nm&lt;/th&gt;\n                        &lt;th&gt;532 nm&lt;/th&gt;\n                        &lt;th&gt;1064 nm&lt;/th&gt;\n                    &lt;/tr&gt;\n                &lt;/thead&gt;\n                &lt;tbody&gt;\n                    &lt;tr&gt;\n                        &lt;td&gt;Urban&lt;/td&gt;\n                        &lt;td&gt;0.31&lt;/td&gt;\n                        &lt;td&gt;1.92&lt;/td&gt;\n                        &lt;td&gt;1.86&lt;/td&gt;\n                        &lt;td&gt;0.31&lt;/td&gt;\n                    &lt;/tr&gt;\n                    &lt;tr&gt;\n                        &lt;td&gt;Desert dust&lt;/td&gt;\n                        &lt;td&gt;0.68&lt;/td&gt;\n                        &lt;td&gt;1.04&lt;/td&gt;\n                        &lt;td&gt;0.58&lt;/td&gt;\n                        &lt;td&gt;0.38&lt;/td&gt;\n                    &lt;/tr&gt;\n                    &lt;tr&gt;\n                        &lt;td&gt;Biomass burning&lt;/td&gt;\n                        &lt;td&gt;0.26&lt;/td&gt;\n                        &lt;td&gt;1.28&lt;/td&gt;\n                        &lt;td&gt;3.30&lt;/td&gt;\n                        &lt;td&gt;0.68&lt;/td&gt;\n                    &lt;/tr&gt;\n                    &lt;tr&gt;\n                        &lt;td&gt;Volcanic ash&lt;/td&gt;\n                        &lt;td&gt;0.62&lt;/td&gt;\n                        &lt;td&gt;0.56&lt;/td&gt;\n                        &lt;td&gt;0.62&lt;/td&gt;\n                        &lt;td&gt;0.68&lt;/td&gt;\n                    &lt;/tr&gt;\n                &lt;/tbody&gt;\n                &lt;caption&gt;Conversion Factors and MEC calculated for the main aerosol types&lt;/caption&gt;\n            &lt;/table&gt;\n\n        \"\"\"\n\n\n        def _compute_conv_factor(nsd, qext, radius):\n            \"\"\"Compute Conversion Factor for a given Size Distribution and Efficiency\n\n            Args:\n                nsd (1D Array): Number Size Distribution (\u00b5m-3.\u00b5m-1)\n                qext (1D Array): Extinction Efficiency (unitless)\n                radius (1D Array): Radius, in \u00b5m\n\n            Returns:\n                (float): Conversion factor (m)\n\n            \"\"\"\n            # radius resolution\n            dr = min(np.diff(radius))\n\n            # integrals\n            numerator = [nsd[i] * (radius[i] ** 3) for i in range(len(radius))]\n            denominator = [\n                nsd[i] * qext[i] * (radius[i] ** 2) for i in range(len(radius))\n            ]\n            int1 = np.nancumsum(np.asarray(numerator) * dr)[-1]\n            int2 = np.nancumsum(np.asarray(denominator) * dr)[-1]\n\n            conv_factor = (4 / 3) * (int1 / int2)\n\n            # conversion form \u00b5m to m\n            conv_factor = conv_factor * 1e-6\n            return conv_factor\n\n        # generate a size distribution for given aer_type\n        sd = size_distribution.SizeDistributionData(self.aer_type)\n\n        # calculate efficiency extinction qext\n        # size parameter\n        # as the radius is in \u00b5m and the wavelength is in nm, one must convert the wavelength to \u00b5m\n        x = [2 * np.pi * r / (self.wavelength * 1e-3) for r in sd.radius]\n        # refractive index\n        m = complex(\n            self.aer_properties[\"ref_index\"][\"real\"],\n            -abs(self.aer_properties[\"ref_index\"][\"imag\"]),\n        )\n        # mie calculation\n        qext, _qsca, _qback, _g = miepython.mie(m, x)\n\n        # output\n        self.nsd = sd.nsd\n        self.vsd = sd.vsd\n        self.radius = sd.radius\n        self.x = x\n        self.qext = qext\n        self.conv_factor = _compute_conv_factor(sd.nsd, qext, sd.radius)\n        self.mec = 1 / (\n            self.conv_factor * self.aer_properties[\"density\"] * 1e6\n        )  # convert density from g.cm-3 to g.m-3\n        return self\n\n    def plot(self, show_fig=True):\n        \"\"\"\n        Plot main information of an instance of the [`MECData`](#aprofiles.mec.MECData) class.\n\n        Example:\n            ```python\n            #import aprofiles\n            import aprofiles as apro\n            #compute mec for biomas burning particles at 532 nm\n            mec = apro.mec.MECData('volcanic_ash', 532.);\n            #plot information\n            mec.plot()\n            ```\n\n            ![Volcanic Ash particles properties used for MEC calculation](../../assets/images/volcanic_ash-mec.png)\n        \"\"\"\n        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n\n        # plot Volume Size Distribution in 1st axis\n        ax.plot(self.radius, self.vsd, label=\"VSD\")\n        ax.set_ylabel(\"V(r) (\u00b5m2.\u00b5m-3)\")\n\n        # plot Number Size Distribution in 2nd axis\n        if \"nsd\" in self.__dict__:\n            # add secondary yaxis\n            ax2 = ax.twinx()\n            ax2.plot(self.radius, self.qext, label=\"Qext\", color=\"gray\")\n            ax2.set_ylabel(\"Qext (unitless)\")\n            # ax2.set_ylim([0,10])\n\n        # add additional information\n        plt.text(\n            0.975,\n            0.85,\n            f\"$at\\ \\lambda={self.wavelength:.0f}\\ nm$\",\n            horizontalalignment=\"right\",\n            verticalalignment=\"center\",\n            transform=ax.transAxes,\n        )\n        plt.text(\n            0.975,\n            0.80,\n            f\"$c_v: {self.conv_factor * 1e6:.2f}\\ \\mu m$\",\n            horizontalalignment=\"right\",\n            verticalalignment=\"center\",\n            transform=ax.transAxes,\n        )\n        plt.text(\n            0.975,\n            0.75,\n            f\"$MEC: {self.mec:.2f}\\ m^2/g$\",\n            horizontalalignment=\"right\",\n            verticalalignment=\"center\",\n            transform=ax.transAxes,\n        )\n\n        ax.set_xlabel(\"Radius (\u00b5m)\")\n        ax.set_xscale(\"log\")\n        fig.legend(\n            loc=\"upper right\", bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes\n        )\n        plt.title(\n            f\"{self.aer_type.capitalize().replace('_', ' ')} particles properties for MEC calculation\",\n            weight=\"bold\",\n        )\n        plt.tight_layout()\n        if show_fig:\n            plt.show()\n</code></pre>"},{"location":"api/data_classes/#aprofiles.mec.MECData.get_mec","title":"<code>get_mec()</code>","text":"<p>Calculates the Extinction to Mass Coefficient for a given type of particles, assuming a prescribed size distribution shape (with unknown amplitude), density, and using Mie theory to calculate the extinction efficiency.</p> <p>Returns:      (MECData): with additional attributes:</p> <pre><code>     - `nsd` (1D Array): Number Size Distribution\n     - `vsd` (1D Array): Volume Size Distribution\n     - `radius` (1D Array): Radius in \u00b5m\n     - `x` (1D Array): Size parameter (unitless)\n     - `conv_factor` (float): Conversion factor in m\n     - `mec` (float): Extinction to Mass Coefficient in m\u00b2.g\u207b\u00b9\n</code></pre> <p>Note</p> <p>For a population of particles, the extinction coefficient \\(\\sigma_{ext}\\) (m\u207b\u00b9) can be written as follows:</p> <p>$$  \\sigma_{ext} = \\int_{r_{min}}^{r_{max}} N(r) Q_{ext}(m, r, \\lambda) \\pi r^2 dr  $$</p> <p>where \\(Q_{ext}\\) is the <code>extinction efficiency</code> and \\(N(r)\\) is the <code>Number Size Distribution</code> (NSD).</p> <p>\\(Q_{ext}\\) varies with the refractive index, \\(m\\), the wavelength, \\(\\lambda\\), and can be calculated for spherical particles using Mie theory.</p> <p>The total aerosol mass concentration \\(M_0\\) (\u00b5g.m\u207b\u00b3) can be expressed as:</p> <p>$$  M_0 = \\int_{r_{min}}^{r_{max}} M(r) dr  $$</p> <p>where \\(M(r)\\) is the mass size distribution (MSD).</p> <p>This can be rewritten in terms of NSD and MSD as:</p> <p>$$  M_0 = \\int_{r_{min}}^{r_{max}} \\frac{4\\pi r^3}{3} \\rho N(r) dr  $$</p> <p>where \\(\\rho\\) is the particle density (kg.m\u207b\u00b3).</p> <p>By normalizing the NSD with respect to the fine mode (\\(N(r) = N_0 N_1(r)\\)), we arrive at:</p> <p>$$  M_0 = \\sigma_{ext} \\rho \\frac{4}{3} \\frac{\\int_{r_{min}}^{r_{max}} N_1(r) r^3 dr}{\\int_{r_{min}}^{r_{max}} N_1(r) Q_{ext}(m, r, \\lambda) r^2 dr}  $$</p> <p>We define the <code>conversion factor</code> (in m) as:</p> <p>$$  c_v = \\frac{4}{3} \\frac{\\int_{r_{min}}^{r_{max}} N_1(r) r^3 dr}{\\int_{r_{min}}^{r_{max}} N_1(r) Q_{ext}(m, r, \\lambda) r^2 dr}  $$</p> <p>Thus, the equation simplifies to:</p> <p>$$  M_0 = \\sigma_{ext} \\rho c_v  $$</p> <p>Finally, the <code>Extinction to Mass Coefficient</code> (MEC, also called <code>mass extinction cross section</code>, usually in m\u00b2.g\u207b\u00b9) is defined as:</p> <p>$$  MEC = \\frac{\\sigma_{ext}}{M_0} = \\frac{1}{\\rho c_v}  $$</p> <p>with \\(\\rho\\) expressed in g.m\u207b\u00b3.</p> <p> Aerosol Type Conversion Factor (\u00b5m) MEC (m\u00b2.g\u207b\u00b9)  532 nm 1064 nm 532 nm 1064 nm Urban 0.31 1.92 1.86 0.31 Desert dust 0.68 1.04 0.58 0.38 Biomass burning 0.26 1.28 3.30 0.68 Volcanic ash 0.62 0.56 0.62 0.68 Conversion Factors and MEC calculated for the main aerosol types </p> Source code in <code>aprofiles/mec.py</code> <pre><code>def get_mec(self):\n    \"\"\"\n    Calculates the Extinction to Mass Coefficient for a given type of particles, assuming a prescribed size distribution shape (with unknown amplitude), density, and using [Mie theory](https://miepython.readthedocs.io) to calculate the extinction efficiency.\n\n    Returns:\n        (MECData): with additional attributes:\n\n            - `nsd` (1D Array): Number Size Distribution\n            - `vsd` (1D Array): Volume Size Distribution\n            - `radius` (1D Array): Radius in \u00b5m\n            - `x` (1D Array): Size parameter (unitless)\n            - `conv_factor` (float): Conversion factor in m\n            - `mec` (float): Extinction to Mass Coefficient in m\u00b2.g\u207b\u00b9\n\n   !!! note\n        For a population of particles, the extinction coefficient $\\sigma_{ext}$ (m\u207b\u00b9) can be written as follows:\n\n        $$\n        \\sigma_{ext} = \\int_{r_{min}}^{r_{max}} N(r) Q_{ext}(m, r, \\lambda) \\pi r^2 dr\n        $$\n\n        where $Q_{ext}$ is the `extinction efficiency` and $N(r)$ is the `Number Size Distribution` (NSD).\n\n        $Q_{ext}$ varies with the refractive index, $m$, the wavelength, $\\lambda$, and can be calculated for spherical particles using Mie theory.\n\n        The total aerosol mass concentration $M_0$ (\u00b5g.m\u207b\u00b3) can be expressed as:\n\n        $$\n        M_0 = \\int_{r_{min}}^{r_{max}} M(r) dr\n        $$\n\n        where $M(r)$ is the mass size distribution (MSD).\n\n        This can be rewritten in terms of NSD and MSD as:\n\n        $$\n        M_0 = \\int_{r_{min}}^{r_{max}} \\\\frac{4\\pi r^3}{3} \\\\rho N(r) dr\n        $$\n\n        where $\\\\rho$ is the particle density (kg.m\u207b\u00b3).\n\n        By normalizing the NSD with respect to the fine mode ($N(r) = N_0 N_1(r)$), we arrive at:\n\n        $$\n        M_0 = \\sigma_{ext} \\\\rho \\\\frac{4}{3} \\\\frac{\\int_{r_{min}}^{r_{max}} N_1(r) r^3 dr}{\\int_{r_{min}}^{r_{max}} N_1(r) Q_{ext}(m, r, \\lambda) r^2 dr}\n        $$\n\n        We define the `conversion factor` (in m) as:\n\n        $$\n        c_v = \\\\frac{4}{3} \\\\frac{\\int_{r_{min}}^{r_{max}} N_1(r) r^3 dr}{\\int_{r_{min}}^{r_{max}} N_1(r) Q_{ext}(m, r, \\lambda) r^2 dr}\n        $$\n\n        Thus, the equation simplifies to:\n\n        $$\n        M_0 = \\sigma_{ext} \\\\rho c_v\n        $$\n\n        Finally, the `Extinction to Mass Coefficient` (MEC, also called `mass extinction cross section`, usually in m\u00b2.g\u207b\u00b9) is defined as:\n\n        $$\n        MEC = \\\\frac{\\sigma_{ext}}{M_0} = \\\\frac{1}{\\\\rho c_v}\n        $$\n\n        with $\\\\rho$ expressed in g.m\u207b\u00b3.\n\n\n        &lt;table&gt;\n            &lt;thead&gt;\n                &lt;tr&gt;\n                    &lt;th&gt;Aerosol Type&lt;/th&gt;\n                    &lt;th colspan=2&gt;Conversion Factor (\u00b5m)&lt;/th&gt;\n                    &lt;th colspan=2&gt;MEC (m\u00b2.g\u207b\u00b9) &lt;/th&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;th&gt;&lt;/th&gt;\n                    &lt;th&gt;532 nm&lt;/th&gt;\n                    &lt;th&gt;1064 nm&lt;/th&gt;\n                    &lt;th&gt;532 nm&lt;/th&gt;\n                    &lt;th&gt;1064 nm&lt;/th&gt;\n                &lt;/tr&gt;\n            &lt;/thead&gt;\n            &lt;tbody&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;Urban&lt;/td&gt;\n                    &lt;td&gt;0.31&lt;/td&gt;\n                    &lt;td&gt;1.92&lt;/td&gt;\n                    &lt;td&gt;1.86&lt;/td&gt;\n                    &lt;td&gt;0.31&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;Desert dust&lt;/td&gt;\n                    &lt;td&gt;0.68&lt;/td&gt;\n                    &lt;td&gt;1.04&lt;/td&gt;\n                    &lt;td&gt;0.58&lt;/td&gt;\n                    &lt;td&gt;0.38&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;Biomass burning&lt;/td&gt;\n                    &lt;td&gt;0.26&lt;/td&gt;\n                    &lt;td&gt;1.28&lt;/td&gt;\n                    &lt;td&gt;3.30&lt;/td&gt;\n                    &lt;td&gt;0.68&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;Volcanic ash&lt;/td&gt;\n                    &lt;td&gt;0.62&lt;/td&gt;\n                    &lt;td&gt;0.56&lt;/td&gt;\n                    &lt;td&gt;0.62&lt;/td&gt;\n                    &lt;td&gt;0.68&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/tbody&gt;\n            &lt;caption&gt;Conversion Factors and MEC calculated for the main aerosol types&lt;/caption&gt;\n        &lt;/table&gt;\n\n    \"\"\"\n\n\n    def _compute_conv_factor(nsd, qext, radius):\n        \"\"\"Compute Conversion Factor for a given Size Distribution and Efficiency\n\n        Args:\n            nsd (1D Array): Number Size Distribution (\u00b5m-3.\u00b5m-1)\n            qext (1D Array): Extinction Efficiency (unitless)\n            radius (1D Array): Radius, in \u00b5m\n\n        Returns:\n            (float): Conversion factor (m)\n\n        \"\"\"\n        # radius resolution\n        dr = min(np.diff(radius))\n\n        # integrals\n        numerator = [nsd[i] * (radius[i] ** 3) for i in range(len(radius))]\n        denominator = [\n            nsd[i] * qext[i] * (radius[i] ** 2) for i in range(len(radius))\n        ]\n        int1 = np.nancumsum(np.asarray(numerator) * dr)[-1]\n        int2 = np.nancumsum(np.asarray(denominator) * dr)[-1]\n\n        conv_factor = (4 / 3) * (int1 / int2)\n\n        # conversion form \u00b5m to m\n        conv_factor = conv_factor * 1e-6\n        return conv_factor\n\n    # generate a size distribution for given aer_type\n    sd = size_distribution.SizeDistributionData(self.aer_type)\n\n    # calculate efficiency extinction qext\n    # size parameter\n    # as the radius is in \u00b5m and the wavelength is in nm, one must convert the wavelength to \u00b5m\n    x = [2 * np.pi * r / (self.wavelength * 1e-3) for r in sd.radius]\n    # refractive index\n    m = complex(\n        self.aer_properties[\"ref_index\"][\"real\"],\n        -abs(self.aer_properties[\"ref_index\"][\"imag\"]),\n    )\n    # mie calculation\n    qext, _qsca, _qback, _g = miepython.mie(m, x)\n\n    # output\n    self.nsd = sd.nsd\n    self.vsd = sd.vsd\n    self.radius = sd.radius\n    self.x = x\n    self.qext = qext\n    self.conv_factor = _compute_conv_factor(sd.nsd, qext, sd.radius)\n    self.mec = 1 / (\n        self.conv_factor * self.aer_properties[\"density\"] * 1e6\n    )  # convert density from g.cm-3 to g.m-3\n    return self\n</code></pre>"},{"location":"api/data_classes/#aprofiles.mec.MECData.plot","title":"<code>plot(show_fig=True)</code>","text":"<p>Plot main information of an instance of the <code>MECData</code> class.</p> Example <pre><code>#import aprofiles\nimport aprofiles as apro\n#compute mec for biomas burning particles at 532 nm\nmec = apro.mec.MECData('volcanic_ash', 532.);\n#plot information\nmec.plot()\n</code></pre> <p></p> Source code in <code>aprofiles/mec.py</code> <pre><code>def plot(self, show_fig=True):\n    \"\"\"\n    Plot main information of an instance of the [`MECData`](#aprofiles.mec.MECData) class.\n\n    Example:\n        ```python\n        #import aprofiles\n        import aprofiles as apro\n        #compute mec for biomas burning particles at 532 nm\n        mec = apro.mec.MECData('volcanic_ash', 532.);\n        #plot information\n        mec.plot()\n        ```\n\n        ![Volcanic Ash particles properties used for MEC calculation](../../assets/images/volcanic_ash-mec.png)\n    \"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n\n    # plot Volume Size Distribution in 1st axis\n    ax.plot(self.radius, self.vsd, label=\"VSD\")\n    ax.set_ylabel(\"V(r) (\u00b5m2.\u00b5m-3)\")\n\n    # plot Number Size Distribution in 2nd axis\n    if \"nsd\" in self.__dict__:\n        # add secondary yaxis\n        ax2 = ax.twinx()\n        ax2.plot(self.radius, self.qext, label=\"Qext\", color=\"gray\")\n        ax2.set_ylabel(\"Qext (unitless)\")\n        # ax2.set_ylim([0,10])\n\n    # add additional information\n    plt.text(\n        0.975,\n        0.85,\n        f\"$at\\ \\lambda={self.wavelength:.0f}\\ nm$\",\n        horizontalalignment=\"right\",\n        verticalalignment=\"center\",\n        transform=ax.transAxes,\n    )\n    plt.text(\n        0.975,\n        0.80,\n        f\"$c_v: {self.conv_factor * 1e6:.2f}\\ \\mu m$\",\n        horizontalalignment=\"right\",\n        verticalalignment=\"center\",\n        transform=ax.transAxes,\n    )\n    plt.text(\n        0.975,\n        0.75,\n        f\"$MEC: {self.mec:.2f}\\ m^2/g$\",\n        horizontalalignment=\"right\",\n        verticalalignment=\"center\",\n        transform=ax.transAxes,\n    )\n\n    ax.set_xlabel(\"Radius (\u00b5m)\")\n    ax.set_xscale(\"log\")\n    fig.legend(\n        loc=\"upper right\", bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes\n    )\n    plt.title(\n        f\"{self.aer_type.capitalize().replace('_', ' ')} particles properties for MEC calculation\",\n        weight=\"bold\",\n    )\n    plt.tight_layout()\n    if show_fig:\n        plt.show()\n</code></pre>"},{"location":"api/detection/","title":"Detection","text":"<p>The following functions are methods from the class <code>ProfilesData</code>.</p>"},{"location":"api/detection/#fog-or-condensation","title":"Fog or Condensation","text":"<p>This method allows for the detection of fog or condensation in single profiles.</p>"},{"location":"api/detection/#aprofiles.detection.foc.detect_foc","title":"<code>detect_foc(profiles, method='cloud_base', var='attenuated_backscatter_0', z_snr=2000.0, min_snr=2.0, zmin_cloud=200.0)</code>","text":"<p>Detects fog or condensation. Two methods are available: - cloud_base (default): uses the minimum cloud base height. - snr (fallback if no clouds are available): identifies areas under a certain altitude for which snr values lower than the prescribed threshold.</p> <p>Parameters:</p> Name Type Description Default <code>profiles</code> <code>ProfilesData</code> <p><code>ProfilesData</code> instance.</p> required <code>method</code> <code>{cloud_base, snr}</code> <p>Detection method.</p> <code>'cloud_base'</code> <code>var</code> <code>str</code> <p>Used for 'snr' method. Variable to calculate SNR from.</p> <code>'attenuated_backscatter_0'</code> <code>z_snr</code> <code>float</code> <p>Used for 'snr' method. Altitude AGL (in m) at which we calculate the SNR.</p> <code>2000.0</code> <code>min_snr</code> <code>float</code> <p>Used for 'snr' method. Minimum SNR under which the profile is considered as containing fog or condensation.</p> <code>2.0</code> <code>zmin_cloud</code> <code>float</code> <p>Used for 'cloud_base' method. Altitude AGL (in m) below which a cloud base height is considered a fog or condensation situation.</p> <code>200.0</code> <p>Returns:</p> Type Description <code>ProfilesData</code> <p>adds the following (xarray.DataArray) to existing (aprofiles.profiles.ProfilesData):</p> <ul> <li><code>'foc' (time)</code>: mask array corresponding to the presence of foc.</li> </ul> Example <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# foc detection\nprofiles.foc()\n# attenuated backscatter image with pbl up to 6km of altitude\nprofiles.plot(show_foc=True, zmax=6000., vmin=1e-2, vmax=1e1, log=True)\n</code></pre> <p></p> Source code in <code>aprofiles/detection/foc.py</code> <pre><code>def detect_foc(profiles, method: Literal[\"cloud_base\", \"snr\"]=\"cloud_base\", var=\"attenuated_backscatter_0\", z_snr=2000., min_snr=2., zmin_cloud=200.):\n    \"\"\"Detects fog or condensation. Two methods are available:\n    - cloud_base (default): uses the minimum cloud base height.\n    - snr (fallback if no clouds are available): identifies areas under a certain altitude for which snr values lower than the prescribed threshold.\n\n    Args:\n        profiles (aprofiles.profiles.ProfilesData): `ProfilesData` instance.\n        method ({'cloud_base', 'snr'}, optional): Detection method.\n        var (str, optional): Used for 'snr' method. Variable to calculate SNR from.\n        z_snr (float, optional): Used for 'snr' method. Altitude AGL (in m) at which we calculate the SNR.\n        min_snr (float, optional): Used for 'snr' method. Minimum SNR under which the profile is considered as containing fog or condensation.\n        zmin_cloud (float, optional): Used for 'cloud_base' method. Altitude AGL (in m) below which a cloud base height is considered a fog or condensation situation.\n\n    Returns:\n        (aprofiles.profiles.ProfilesData): \n            adds the following (xarray.DataArray) to existing (aprofiles.profiles.ProfilesData):\n\n            - `'foc' (time)`: mask array corresponding to the presence of foc.\n\n    Example:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # foc detection\n        profiles.foc()\n        # attenuated backscatter image with pbl up to 6km of altitude\n        profiles.plot(show_foc=True, zmax=6000., vmin=1e-2, vmax=1e1, log=True)\n        ```\n\n        ![Fog or condensation (foc) detection](../../assets/images/foc.png)\n    \"\"\"\n\n    if method == \"cloud_base\" and \"clouds\" in profiles.data:\n        foc = _detect_fog_from_cloud(profiles, zmin_cloud)\n    else:\n        foc = _detect_fog_from_snr(profiles, z_snr, var, min_snr)\n\n    # creates dataarray\n    profiles.data[\"foc\"] = (\"time\", foc)\n    profiles.data[\"foc\"] = profiles.data.foc.assign_attrs({'long_name': 'Fog or condensation mask'})\n\n    return profiles\n</code></pre>"},{"location":"api/detection/#clouds","title":"Clouds","text":"<p>This method allows for the detection of clouds in attenuated backscatter profiles.</p>"},{"location":"api/detection/#aprofiles.detection.clouds.detect_clouds","title":"<code>detect_clouds(profiles, method='dec', time_avg=1.0, zmin=0.0, thr_noise=5.0, thr_clouds=4.0, min_snr=0.0, verbose=False)</code>","text":"<p>Module for clouds detection. Two methods are available:  - \"dec\" (default): Deep Embedded Clustering (see AI-Profiles). - \"vg\": Vertical Gradient.</p> <p>Parameters:</p> Name Type Description Default <code>profiles</code> <code>ProfilesData</code> <p><code>ProfilesData</code> instance.</p> required <code>method</code> <code>Literal['dec', 'vg']</code> <p>cloud detection method used.</p> <code>'dec'</code> <code>time_avg</code> <code>float</code> <p>in minutes, the time during which we aggregates the profiles prior to the clouds detection.</p> <code>1.0</code> <code>zmin</code> <code>float</code> <p>altitude AGL, in m, above which we look for clouds. We recommend using the same value as used in the extrapolation_low_layers method (only for 'vg' method).</p> <code>0.0</code> <code>thr_noise</code> <code>float</code> <p>threshold used in the test to determine if a couple (base,peak) is significant: data[peak(z)] data[base(z)] &gt;= thr_noise * noise(z) (only for 'vg' method).</p> <code>5.0</code> <code>thr_clouds</code> <code>float</code> <p>threshold used to discriminate aerosol from clouds: data[peak(z)] / data[base(z)] &gt;= thr_clouds (only for 'vg' method).</p> <code>4.0</code> <code>min_snr</code> <code>float</code> <p>Minimum SNR required at the clouds peak value to consider the cloud as valid (only for 'vg' method).</p> <code>0.0</code> <code>verbose</code> <code>bool</code> <p>verbose mode. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>ProfilesData</code> <p>adds the following (xarray.DataArray) to existing (aprofiles.profiles.ProfilesData): - <code>'clouds' (time, altitude)</code>: Mask array corresponding to data flagged as a cloud.</p> Example 1 <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# clouds detection\nprofiles.clouds(method=\"dec\")\n# attenuated backscatter image with clouds\nprofiles.plot(show_clouds=True, vmin=1e-2, vmax=1e1, log=True)\n</code></pre> <p></p> Example 2 <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# clouds detection\nprofiles.clouds(method=\"vg\", zmin=300.)\n# attenuated backscatter image with clouds\nprofiles.plot(show_clouds=True, vmin=1e-2, vmax=1e1, log=True)\n</code></pre> <p></p> Source code in <code>aprofiles/detection/clouds.py</code> <pre><code>def detect_clouds(profiles: aprofiles.profiles.ProfilesData, method: Literal[\"dec\", \"vg\"]=\"dec\", time_avg: float=1., zmin: float=0., thr_noise: float=5., thr_clouds: float=4., min_snr: float=0., verbose: bool=False):\n    \"\"\"Module for *clouds detection*.\n    Two methods are available: \n    - \"dec\" (default): Deep Embedded Clustering (see [AI-Profiles](https://github.com/AugustinMortier/ai-profiles)).\n    - \"vg\": Vertical Gradient.\n\n    Args:\n        profiles (aprofiles.profiles.ProfilesData): `ProfilesData` instance.\n        method (Literal[\"dec\", \"vg\"]): cloud detection method used.\n        time_avg (float, optional): in minutes, the time during which we aggregates the profiles prior to the clouds detection.\n        zmin (float, optional): altitude AGL, in m, above which we look for clouds. We recommend using the same value as used in the extrapolation_low_layers method (only for 'vg' method).\n        thr_noise (float, optional): threshold used in the test to determine if a couple (base,peak) is significant: data[peak(z)] data[base(z)] &gt;= thr_noise * noise(z) (only for 'vg' method).\n        thr_clouds (float, optional): threshold used to discriminate aerosol from clouds: data[peak(z)] / data[base(z)] &gt;= thr_clouds (only for 'vg' method).\n        min_snr (float, optional): Minimum SNR required at the clouds peak value to consider the cloud as valid (only for 'vg' method).\n        verbose (bool, optional): verbose mode. Defaults to `False`.\n\n    Returns:\n        (aprofiles.profiles.ProfilesData): \n            adds the following (xarray.DataArray) to existing (aprofiles.profiles.ProfilesData):\n            - `'clouds' (time, altitude)`: Mask array corresponding to data flagged as a cloud.\n\n    Example 1:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # clouds detection\n        profiles.clouds(method=\"dec\")\n        # attenuated backscatter image with clouds\n        profiles.plot(show_clouds=True, vmin=1e-2, vmax=1e1, log=True)\n        ```\n\n        ![Clouds detection](../../assets/images/clouds_dec.png)\n\n    Example 2:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # clouds detection\n        profiles.clouds(method=\"vg\", zmin=300.)\n        # attenuated backscatter image with clouds\n        profiles.plot(show_clouds=True, vmin=1e-2, vmax=1e1, log=True)\n        ```\n\n        ![Clouds detection](../../assets/images/clouds_vg.png)\n    \"\"\"\n\n    def _vg_clouds(data, zmin, thr_noise, thr_clouds, min_snr):\n        # data: 1D range corrected signal (rcs)\n        # zmin: altitude AGL, in m, above which we detect clouds\n        # thr_noise: threshold used in the test to determine if a couple (base,peak) is significant: data[peak(z)] - data[base(z)] &gt;= thr_noise * noise(z)\n        # thr_clouds: threshold used to discriminate aerosol from clouds: data[peak(z)] / data[base(z)] &gt;= thr_clouds\n        # min_snr: minimum SNR required at the clouds peak value to consider the cloud as valid. Defaults to 2.\n\n        from scipy import signal\n        from scipy.ndimage.filters import uniform_filter1d\n\n        # some useful functions:\n        def _get_all_indexes(bases, peaks, tops=[]):\n            # get True indexes of bases, peaks and tops, based on masks\n            i_bases = utils.get_true_indexes(bases)\n            i_peaks = utils.get_true_indexes(peaks)\n            i_tops = utils.get_true_indexes(tops)\n            return i_bases, i_peaks, i_tops\n\n        def _make_all_masks(data, i_bases, i_peaks, i_tops=[]):\n            # return masks for bases, peaks and tops based on input indexes\n            bases = utils.make_mask(len(data), i_bases)\n            peaks = utils.make_mask(len(data), i_peaks)\n            tops = utils.make_mask(len(data), i_tops)\n            return bases, peaks, tops\n\n        def _merge_layers(data, i_bases, i_peaks, i_tops):\n            # merge layers depending on the altitude of the bases and the tops\n            remove_mode = True\n            while remove_mode:\n                remove_bases, remove_peaks, remove_tops = [], [], []\n                for i in range(len(i_bases) - 1):\n                    # filters based on the index\n                    if i_bases[i + 1] &lt;= i_tops[i]:\n                        remove_bases.append(i_bases[i + 1])\n                        # remove the weakest peak\n                        imin = np.argmin([data[i_peaks[i]], data[i_peaks[i + 1]]])\n                        remove_peaks.append(i_peaks[i + imin])\n                        # remove lowest top\n                        imin = np.argmin([i_tops[i], i_tops[i + 1]])\n                        remove_tops.append(i_tops[i + imin])\n                        # start again from the bottom\n                        break\n\n                i_bases = [i for i in i_bases if i not in remove_bases]\n                i_peaks = [i for i in i_peaks if i not in remove_peaks]\n                i_tops = [i for i in i_tops if i not in remove_tops]\n                if len(remove_bases) == 0:\n                    remove_mode = False\n\n            return i_bases, i_peaks, i_tops\n\n        def _find_tops(data, i_bases, i_peaks):\n            # function that finds the top of the layers by identifying the first value above thepeak for which the signal is lower than the base\n            # if no top is found, the layer is removed\n            # retruns lists of indexes of the bases, peaks and tops\n            tops = np.asarray([False for x in np.ones(len(data))])\n            # conditions: look for bases above i_peaks[i], and data[top[i]] &lt;= data[base[i]]\n\n            i_tops = []\n            for i in range(len(i_bases)):\n                mask_value = np.asarray(\n                    [\n                        True if data[j] &lt; data[i_bases[i]] else False\n                        for j in range(len(data))\n                    ]\n                )\n                mask_altitude = np.asarray(\n                    [True if j &gt; i_peaks[i] else False for j in range(len(data))]\n                )\n                # the top is the first value that corresponds to the intersection of the two masks\n                cross_mask = np.logical_and(mask_value, mask_altitude)\n                i_cross_mask = utils.get_true_indexes(cross_mask)\n                if len(i_cross_mask) &gt; 0:\n                    if tops[i_cross_mask[0]]:\n                        bases[i_bases[i]] = False\n                        peaks[i_peaks[i]] = False\n                    else:\n                        tops[i_cross_mask[0]] = True\n                        i_tops.append(i_cross_mask[0])\n                else:\n                    bases[i_bases[i]] = False\n                    peaks[i_peaks[i]] = False\n            # it is important to keep the tops in the same order, so not to use utils.get_true_indexes() function here\n            return utils.get_true_indexes(bases), utils.get_true_indexes(peaks), i_tops\n\n        def _mask_cloud(profile: aprofiles.profiles, bases: list[int], tops: list[int]) -&gt; np.ndarray:\n            \"\"\"Generate a boolean mask for cloud presence in a given profile.\n\n            Args:\n                profile (aprofiles.profiles): 1D array representing a single atmospheric profile.\n                bases (list[int]): List of base indices where clouds start.\n                tops (list[int]): List of top indices where clouds end.\n\n            Returns:\n                np.ndarray: Boolean mask of the same length as profile, where cloud regions are True.\n            \"\"\"\n            mask = np.zeros_like(profile, dtype=bool)\n\n            for base, top in zip(bases, tops):\n                mask[base:top] = True\n\n            return mask\n\n        #-1. check if any valid data\n        if np.isnan(data).all():\n            bases, peaks, tops = _make_all_masks(data, [], [], [])\n            return {\n                \"bases\": bases,\n                \"peaks\": peaks,\n                \"tops\": tops,\n            }\n\n        # 0. rolling average\n        avg_data = uniform_filter1d(data, size=10)\n\n        # 1. first derivative\n        gradient = np.gradient(avg_data)\n        #remove zero values since np.sign(0) = 0\n        gradient = [value if value != 0 else 1e-9 for value in gradient]\n\n        # 2. identifies peaks and base by checking the sign changes of the derivative\n        sign_changes = np.diff(np.sign(gradient), append=0)\n        all_bases = sign_changes == 2\n        all_peaks = sign_changes == -2\n        # limit to bases above zmin\n        imin = profiles._get_index_from_altitude_AGL(zmin)\n        all_bases[0:imin] = np.full(imin, False)\n        all_peaks[0:imin] = np.full(imin, False)\n        # get indexes\n        i_bases = utils.get_true_indexes(all_bases)\n        i_peaks = utils.get_true_indexes(all_peaks)\n\n        # 3. the signal should start with a base\n        if (len(i_bases)&gt;0): #this happens if the whole profile consists of nan\n            if i_bases[0] &gt; i_peaks[0] and i_peaks[0] &gt;= 1:\n                # set base as the minimum between peak and n gates under\n                gates = np.arange(i_peaks[0] - 5, i_peaks[0])\n                i_base = gates[np.argmin([data[gates[gates &gt;= 0]]])]\n                if i_base &gt;= imin:\n                    all_bases[i_base] = True\n                else:\n                    all_peaks[i_peaks[0]] = False\n            # update indexes\n            i_bases = utils.get_true_indexes(all_bases)\n            i_peaks = utils.get_true_indexes(all_peaks)\n\n        # 4. keeps significant couples (base,peak)\n        # a layer can be considered as a proper layer if the difference of signal between the peak and the base is significant (larger than the noise level)\n        # noise evaluation (using a high passing frequency filter)\n        b, a = signal.butter(1, 0.3, btype=\"high\")\n        noise = signal.filtfilt(b, a, data)\n        # rolling average of the noise\n        avg_abs_noise = uniform_filter1d(abs(noise), size=100)\n        # make sure we have as many peaks as bases\n        if len(i_peaks) != len(i_bases):\n            min_len = min([len(i_peaks), len(i_bases)])\n            i_peaks = i_peaks[0:min_len]\n            i_bases = i_bases[0:min_len]\n        bases, peaks = all_bases, all_peaks\n        for i in range(len(i_bases)):\n            data_around_peak = avg_data[i_peaks[i]]\n            data_around_base = avg_data[i_bases[i]]\n            if (\n                data_around_peak - data_around_base\n                &lt;= thr_noise * avg_abs_noise[i_bases[i]]\n            ):\n                bases[i_bases[i]] = False\n                peaks[i_peaks[i]] = False\n        # get indexes\n        i_bases = utils.get_true_indexes(bases)\n        i_peaks = utils.get_true_indexes(peaks)\n\n        # 5. make sure we finish by a peak: remove last base if necessary\n        if len(i_bases) &gt; len(i_peaks):\n            bases[i_bases[-1]] = False\n            i_bases.pop()\n\n        # 6. find tops of clouds layers\n        i_bases, i_peaks, i_tops = _find_tops(avg_data, i_bases, i_peaks)\n\n        # 7. merge layers: for a couple of base and peaks 1,2 if data(b2)&gt;data(p1), then merge layers 1 and 2 by removing p1 and b2\n        i_bases, i_peaks, i_tops = _merge_layers(avg_data, i_bases, i_peaks, i_tops)\n\n        # 8. find peaks as maximum between base and top    \n        i_peaks = [\n            i_bases[i] + np.argmax(data[i_bases[i]: i_tops[i]])\n            for i in range(len(i_bases))\n        ]\n        # reconstruct masks\n        bases, peaks, tops = _make_all_masks(data, i_bases, i_peaks, i_tops)\n\n        # 9. distinction between aerosol and clouds\n        for i in range(len(i_bases)):\n            data_around_peak = avg_data[i_peaks[i]]\n            data_around_base = avg_data[i_bases[i]]\n            if (\n                abs((data_around_peak - data_around_base) / data_around_base)\n                &lt;= thr_clouds\n            ):\n                bases[i_bases[i]] = False\n                peaks[i_peaks[i]] = False\n                tops[i_tops[i]] = False\n        # get indexes\n        i_bases, i_peaks, i_tops = _get_all_indexes(bases, peaks, tops)\n\n        \"\"\"\n        #10. set base a closest index\n        for i, _ in enumerate(i_peaks):\n            mask_value = np.asarray([True if gradient[j]&lt;0 else False for j in range(len(data))])\n            mask_altitude = np.asarray([True if j&lt;i_peaks[i] else False for j in range(len(data))])\n            #the top is the first value that corresponds to the intersection of the two masks\n            cross_mask = np.logical_and(mask_value, mask_altitude)\n            i_cross_mask = utils.get_true_indexes(cross_mask)\n            i_bases[i] = i_cross_mask[-1]\n        \"\"\"\n\n        # 11. check snr at peak levels\n        remove_bases, remove_peaks, remove_tops = [], [], []\n        for i in range(len(i_peaks)):\n            if utils.snr_at_iz(data, i_peaks[i], step=10) &lt; min_snr:\n                remove_bases.append(i_bases[i])\n                remove_peaks.append(i_peaks[i])\n                remove_tops.append(i_tops[i])\n        # remove indexes\n        i_bases = [i for i in i_bases if i not in remove_bases]\n        i_peaks = [i for i in i_peaks if i not in remove_peaks]\n        i_tops = [i for i in i_tops if i not in remove_tops]\n\n        # 11. build cloud mask from indexes\n        clouds = _mask_cloud(data, i_bases, i_tops)\n\n        \"\"\"\n        #some plotting\n        fig, axs = plt.subplots(1,2,figsize=(10,10))\n\n        ymin, ymax = 000, 15000\n        altitude_agl = profiles.data.altitude.data - profiles.data.station_altitude.data\n\n        #signal on the left\n        axs[0].plot(data, altitude_agl, 'b', label='rcs')\n        axs[0].plot(avg_data, altitude_agl, 'c', label='rcs')\n        axs[0].plot(avg_abs_noise,altitude_agl,':b', label='noise level')\n        axs[0].plot(avg_abs_noise*thr_noise,altitude_agl,':b', label=f'noise level * {thr_noise}')\n        axs[0].plot(data[bases], altitude_agl[bases], '&lt;g', label='bases')\n        axs[0].plot(data[peaks], altitude_agl[peaks], '&gt;r', label='peaks')\n        axs[0].plot(data[tops], altitude_agl[tops], '^k', label='tops')\n\n        #set axis\n        axs[0].set_ylim([ymin, ymax])\n        #axs[0].set_xlim([-20000,20000])\n        axs[0].legend()\n\n        #derivative on the right\n        axs[1].plot(ddata_dz, altitude_agl, 'b', label='first derivative')\n        axs[1].plot(ddata_dz[bases], altitude_agl[bases], '&lt;g', label='bases')\n        axs[1].plot(ddata_dz[peaks], altitude_agl[peaks], '&gt;r', label='peaks')\n\n        axs[1].set_ylim([ymin, ymax])\n        axs[1].legend()\n        #set title\n        fig.suptitle(t,weight='bold')\n        \"\"\"\n\n        return clouds\n\n\n    def _prepare_data(data, vmin, vmax, target_size):\n        # Log transform\n        #data = np.log(data)\n\n        # Clip data to the range [vmin, vmax] and then scale it\n        data_clipped = np.clip(data, vmin, vmax)\n\n        # Replace NaNs with minimum values\n        np.nan_to_num(data_clipped, copy=False, nan=vmin)\n\n        # Invert the normalized data to reflect the 'gray_r' colormap\n        data_normalized = (data_clipped - vmin) / (vmax - vmin)\n        data_inverted = 1 - data_normalized  # Invert the grayscale values\n\n        # Resize the inverted data to the target size\n        resized_data = resize(\n            data_inverted,\n            output_shape=target_size,\n            order=0,  # Nearest-neighbor interpolation to avoid smoothing\n            anti_aliasing=False\n        )\n        return resized_data\n\n\n    def _ml_clouds(prepared_data, encoder, cluster, target_size, output_shape):\n        # Add batch and channel dimensions for further processing\n        data_array = np.expand_dims(np.expand_dims(prepared_data, axis=0), axis=-1)\n\n        # Encode the image to get feature representation\n        encoded_img = encoder.predict(data_array)[0]  # Remove batch dimension\n\n        # Step 1: Aggregate Encoded Features\n        aggregated_encoded_img = np.mean(encoded_img, axis=-1)  # Aggregated to single-channel (16, 32)\n\n        # Optional: Normalize for better visualization\n        aggregated_encoded_img = (aggregated_encoded_img - aggregated_encoded_img.min()) / (aggregated_encoded_img.max() - aggregated_encoded_img.min())\n\n        # Step 2: Flatten Encoded Features and Cluster\n        encoded_img_flat = encoded_img.reshape(-1, encoded_img.shape[-1])  # Flatten spatial dimensions for clustering\n        pixel_labels = cluster.predict(encoded_img_flat)  # Get cluster labels for each pixel\n\n        # Step 3: Map clusters to categories\n        category_mapping = {\n            1: False,  # molecules\n            3: False,  # molecules\n            5: False,  # noise\n            4: False,  # aerosols\n            2: True,  # clouds\n            6: True,  # clouds\n            0: False,  # other\n            7: False   # other\n        }\n        pixel_labels = np.vectorize(category_mapping.get)(pixel_labels)\n\n        # Reshape the cluster labels back to the spatial dimensions\n        pixel_labels_image_shape = pixel_labels.reshape(encoded_img.shape[0], encoded_img.shape[1])\n\n        # Step 4: Upsample the cluster labels to match the original image size\n        upsampled_pixel_labels = resize(\n            pixel_labels_image_shape,\n            (target_size[0], target_size[1]),\n            order=0,  # Nearest-neighbor interpolation\n            preserve_range=True,\n            anti_aliasing=False\n        )\n        #upsampled_pixel_labels = upsampled_pixel_labels.astype(int)  # Ensure the labels are integers\n\n        # resize upsampled_pixel_labels to original size\n        resized_upsampled_pixel_labels = resize(\n                upsampled_pixel_labels,\n                output_shape=output_shape,\n                order=0,  # Nearest-neighbor interpolation to avoid smoothing\n                anti_aliasing=False\n            )\n\n        return resized_upsampled_pixel_labels\n\n    def _split_matrix(matrix, max_size):\n        return [matrix[i:i+max_size] for i in range(0, matrix.shape[0], max_size)]\n\n    def _combine_matrices(matrices):\n        return np.vstack(matrices)\n\n\n    # we work on profiles averaged in time to reduce the noise\n    rcs = profiles.time_avg(\n        time_avg, var=\"attenuated_backscatter_0\"\n    ).data.attenuated_backscatter_0\n\n    # imports and check options\n    if method == 'dec':\n        import os\n        import warnings\n        import absl.logging\n        from sklearn.exceptions import InconsistentVersionWarning\n\n        # Suppress TensorFlow CUDA messages\n        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n        os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir='  # Prevents unnecessary CUDA checks\n        os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"false\"  # Avoids some GPU-related logs\n\n        # Suppress Abseil warnings\n        absl.logging.set_verbosity(absl.logging.ERROR)\n\n        # Suppress scikit-learn version warnings\n        warnings.simplefilter(\"ignore\", InconsistentVersionWarning)\n\n        # Suppress TensorFlow progress bar\n        import tensorflow as tf\n        tf.keras.utils.disable_interactive_logging()\n\n        import numpy as np\n        from tensorflow.keras.models import load_model\n        from skimage.transform import resize\n        from pathlib import Path\n        import joblib\n\n        # ML parameters\n        ML = {\n            'paths': {\n                'encoder': Path(Path(__file__).parent,'ml_models','encoder.keras'),\n                'kmeans': Path(Path(__file__).parent,'ml_models','kmeans.pkl')    \n            },\n            'params': {\n                'vmin': -2,\n                'vmax': 2,\n                'target_size': (256, 512)    \n            }\n        }\n\n        # we split the rcs into subsets, so we artificially increase the time resolution of the cloud detection which is degraded by the DEC technique.\n        split_rcs_list = _split_matrix(rcs, 100)\n\n        # Load the encoder and kmeans model\n        encoder = load_model(ML['paths']['encoder'])\n        cluster = joblib.load(ML['paths']['kmeans'])\n\n        # prepare data\n        split_ml_clouds = []\n        for split_rcs in split_rcs_list:\n            prepared_data = _prepare_data(split_rcs, ML['params']['vmin'], ML['params']['vmax'], ML['params']['target_size'])\n            split_ml_clouds.append(_ml_clouds(prepared_data, encoder, cluster, ML['params']['target_size'], output_shape=np.shape(split_rcs)))\n\n        # aggregate split_ml_clouds\n        clouds = _combine_matrices(split_ml_clouds)\n\n        options = {\n            'encoder': ML['paths']['encoder'],\n            'kmeans': ML['paths']['kmeans']\n        }\n\n    elif method == 'vg':\n        import numpy as np\n        if None in (zmin, thr_noise, thr_clouds, min_snr):\n            raise ValueError(\"For method 'vg', zmin, thr_noise, thr_clouds, and min_snr must be provided.\")\n\n        clouds = []\n        for i in (track(range(len(profiles.data.time.data)), description=\"clouds\",disable=not verbose)):\n            i_clouds = _vg_clouds(\n                rcs.data[i, :], zmin, thr_noise, thr_clouds, min_snr\n            )\n\n            # store info in 2D array\n            clouds.append(i_clouds)\n\n        options = {\n            'zmin': zmin,\n            'thr_noise': thr_noise,\n            'thr_clouds': thr_clouds,\n            'min_snr': min_snr\n        }\n\n    # creates dataarrays\n    profiles.data[\"clouds\"] = ((\"time\", \"altitude\"), clouds)\n    profiles.data[\"clouds\"] = profiles.data.clouds.assign_attrs({\n        'long_name': 'Clouds mask',\n        'units': 'bool',\n        'time_avg': time_avg,\n        'method': method,\n        'options': str(options)\n    })\n    return profiles\n</code></pre>"},{"location":"api/detection/#planetary-boundary-layer","title":"Planetary Boundary Layer","text":"<p>This method allows for the tracking of the Planetary Boundary Layer (PBL) height in single profiles.</p>"},{"location":"api/detection/#aprofiles.detection.pbl.detect_pbl","title":"<code>detect_pbl(profiles, time_avg=1, zmin=100.0, zmax=3000.0, wav_width=200.0, under_clouds=True, min_snr=1.0, verbose=False)</code>","text":"<p>Module for Planetary Boundary Layer Height detection. Detects Planetary Boundary Layer Height between zmin and zmax by looking at the maximum vertical gradient in each individual profiles.</p> <p>Parameters:</p> Name Type Description Default <code>profiles</code> <code>ProfilesData</code> <p><code>ProfilesData</code> instance.</p> required <code>time_avg</code> <code>int</code> <p>in minutes, the time during which we aggregate the profiles before detecting the PBL.</p> <code>1</code> <code>zmin</code> <code>float</code> <p>maximum altitude AGL, in m, for retrieving the PBL.</p> <code>100.0</code> <code>zmin</code> <code>float</code> <p>minimum altitude AGL, in m, for retrieving the PBL.</p> <code>100.0</code> <code>wav_width</code> <code>float</code> <p>Width of the wavelet used in the convolution, in m.</p> <code>200.0</code> <code>under_clouds</code> <code>bool</code> <p>If True, and if clouds detection have been called before, force the PBL to be found below the first cloud detected in the profile.</p> <code>True</code> <code>min_snr</code> <code>float</code> <p>Minimum SNR at the retrieved PBL height required to return a valid value.</p> <code>1.0</code> <code>verbose</code> <code>bool</code> <p>verbose mode.</p> <code>False</code> <p>Returns:</p> Type Description <code>ProfilesData</code> <p>adds the following (xarray.DataArray) to existing (aprofiles.profiles.ProfilesData):</p> <ul> <li><code>'pbl' (time, altitude)</code>: mask array corresponding to the pbl height.</li> </ul> Example <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# pbl detection\nprofiles.pbl(zmin=100., zmax=3000.)\n# attenuated backscatter image with pbl up to 6km of altitude\nprofiles.plot(show_pbl=True, zmax=6000., vmin=1e-2, vmax=1e1, log=True)\n</code></pre> <p></p> Source code in <code>aprofiles/detection/pbl.py</code> <pre><code>def detect_pbl(\n    profiles,\n    time_avg=1,\n    zmin=100.0,\n    zmax=3000.0,\n    wav_width=200.0,\n    under_clouds=True,\n    min_snr=1.0,\n    verbose=False,\n):\n    \"\"\"Module for *Planetary Boundary Layer Height* detection.\n    Detects Planetary Boundary Layer Height between zmin and zmax by looking at the maximum vertical gradient in each individual profiles.\n\n    Args:\n        profiles (aprofiles.profiles.ProfilesData): `ProfilesData` instance.\n        time_avg (int, optional): in minutes, the time during which we aggregate the profiles before detecting the PBL.\n        zmin (float, optional): maximum altitude AGL, in m, for retrieving the PBL.\n        zmin (float, optional): minimum altitude AGL, in m, for retrieving the PBL.\n        wav_width (float, optional): Width of the wavelet used in the convolution, in m.\n        under_clouds (bool, optional): If True, and if clouds detection have been called before, force the PBL to be found below the first cloud detected in the profile.\n        min_snr (float, optional): Minimum SNR at the retrieved PBL height required to return a valid value.\n        verbose (bool, optional): verbose mode.\n\n    Returns:\n        (aprofiles.profiles.ProfilesData):\n            adds the following (xarray.DataArray) to existing (aprofiles.profiles.ProfilesData):\n\n            - `'pbl' (time, altitude)`: mask array corresponding to the pbl height.\n\n    Example:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # pbl detection\n        profiles.pbl(zmin=100., zmax=3000.)\n        # attenuated backscatter image with pbl up to 6km of altitude\n        profiles.plot(show_pbl=True, zmax=6000., vmin=1e-2, vmax=1e1, log=True)\n        ```\n\n        ![Planetary Boundary Layer Height detection](../../assets/images/pbl.png)\n    \"\"\"\n\n    from scipy.ndimage.filters import uniform_filter1d\n\n    def _detect_pbl(data, zmin, zmax, wav_width, min_snr):\n        # detect pbl from range corrected signal between zmin and zmax using convolution with a wavelet..\n        \"\"\"\n        from scipy import signal\n\n        #define wavelet with constant width\n        npoints = len(data)\n        width = wav_width #in meter\n        wav = signal.ricker(npoints, width/profiles._get_resolution('altitude'))\n\n        #simple convolution\n        convolution = signal.convolve(data, wav, mode='same')\n\n        #the PBL is the maximum of the convolution\n        #sets to nan outside of PBL search range\n        convolution[0:profiles._get_index_from_altitude_AGL(zmin):] = np.nan\n        convolution[profiles._get_index_from_altitude_AGL(zmax):] = np.nan\n        i_pbl = np.nanargmax(abs(convolution))\n        \"\"\"\n        # -1. check if any valid data\n        if np.isnan(data).all():\n            return np.nan\n\n        # 0. rolling average\n        avg_data = uniform_filter1d(data, size=10)\n\n        # simple gradient\n        gradient = np.gradient(avg_data)\n\n        # the PBL is the maximum of the convolution\n        # sets to nan outside of PBL search range\n        gradient[0 : profiles._get_index_from_altitude_AGL(zmin) :] = np.nan\n        gradient[profiles._get_index_from_altitude_AGL(zmax) :] = np.nan\n        if not np.isnan(gradient).all():\n            i_pbl = np.nanargmin(gradient)\n        else:\n            return np.nan\n\n        # calculates SNR\n        snr = utils.snr_at_iz(data, i_pbl, step=10)\n        if snr &gt; min_snr:\n            return profiles.data.altitude.data[i_pbl]\n        else:\n            return np.nan\n\n    # we work on profiles averaged in time to reduce the noise\n    rcs = profiles.time_avg(\n        time_avg, var=\"attenuated_backscatter_0\", inplace=False\n    ).data.attenuated_backscatter_0\n\n    # if under_clouds, check if clouds_bases is available\n    if under_clouds and \"clouds\" in list(profiles.data.data_vars):\n        lowest_clouds = profiles._get_lowest_clouds()\n    elif under_clouds and \"clouds\" not in list(profiles.data.data_vars):\n        import warnings\n\n        warnings.warn(\n            \"under_clouds parameter sets to True (defaults value) when the clouds detection has not been applied to ProfileData object.\"\n        )\n        lowest_clouds = [np.nan for _ in np.arange(len(profiles.data.time))]\n    else:\n        lowest_clouds = [np.nan for _ in np.arange(len(profiles.data.time))]\n\n    pbl = []\n    for i in track(\n        range(len(profiles.data.time.data)), description=\"pbl   \", disable=not verbose\n    ):\n        lowest_cloud_agl = lowest_clouds[i] - profiles.data.station_altitude.data[i]\n        _zmax = np.nanmin([zmax, lowest_cloud_agl])\n        pbl.append(\n            _detect_pbl(\n                rcs.data[i, :],\n                zmin,\n                _zmax,\n                wav_width,\n                min_snr,\n            )\n        )\n\n    # creates dataarrays\n    profiles.data[\"pbl\"] = (\"time\", pbl)\n    profiles.data[\"pbl\"] = profiles.data.pbl.assign_attrs(\n        {\n            \"long_name\": \"Planetary Boundary Layer Height, ASL\",\n            \"units\": \"m\",\n            \"time_avg\": time_avg,\n            \"zmin\": zmin,\n            \"zmax\": zmax,\n        }\n    )\n    return profiles\n</code></pre>"},{"location":"api/plotting/","title":"Plotting","text":""},{"location":"api/plotting/#image","title":"Image","text":"<p>This module is used to plot an image (time, altitude) for a given variable of an instance of the <code>ProfilesData</code> class.</p>"},{"location":"api/plotting/#aprofiles.plot.image.plot","title":"<code>plot(da, var='attenuated_backscatter_0', zref='agl', zmin=None, zmax=None, vmin=None, vmax=None, log=False, show_foc=False, show_pbl=False, show_clouds=False, cmap='coolwarm', show_fig=True, save_fig=None)</code>","text":"<p>Plot image of selected variable from :class:<code>aprofiles.profiles.ProfilesData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>da</code> <code>DataArray</code> <p>DataArray.</p> required <code>var</code> <code>str</code> <p>Variable of the DataArray to be plotted.</p> <code>'attenuated_backscatter_0'</code> <code>zref</code> <code>{agl}</code> <p>Base reference for altitude axis.</p> <code>'agl'</code> <code>zmin</code> <code>float</code> <p>Minimum altitude AGL (m).</p> <code>None</code> <code>zmax</code> <code>float</code> <p>Maximum altitude AGL (m).</p> <code>None</code> <code>vmin</code> <code>float</code> <p>Minimum value.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>Maximum value. If <code>None</code>, calculates max from data.</p> <code>None</code> <code>log</code> <code>bool</code> <p>Use logarithmic scale.</p> <code>False</code> <code>show_foc</code> <code>bool</code> <p>Add foc detection.</p> <code>False</code> <code>show_pbl</code> <code>bool</code> <p>Add PBL height.</p> <code>False</code> <code>show_clouds</code> <code>bool</code> <p>Add clouds detection.</p> <code>False</code> <code>cmap</code> <code>str</code> <p>Matplotlib colormap.</p> <code>'coolwarm'</code> <code>show_fig</code> <code>bool</code> <p>Show figure.</p> <code>True</code> <code>save_fig</code> <code>str</code> <p>Path of the saved figure.</p> <code>None</code> Example <p><pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# attenuated backscatter image\nprofiles.plot(vmin=1e-2, vmax=1e1, log=True)\n</code></pre> </p> Source code in <code>aprofiles/plot/image.py</code> <pre><code>def plot(\n    da,\n    var=\"attenuated_backscatter_0\",\n    zref=\"agl\",\n    zmin=None,\n    zmax=None,\n    vmin=None,\n    vmax=None,\n    log=False,\n    show_foc=False,\n    show_pbl=False,\n    show_clouds=False,\n    cmap=\"coolwarm\",\n    show_fig=True,\n    save_fig=None,\n):\n    \"\"\"Plot image of selected variable from :class:`aprofiles.profiles.ProfilesData` object.\n\n    Args:\n        da (xarray.DataArray): DataArray.\n        var (str, optional): Variable of the DataArray to be plotted.\n        zref ({'agl'}, optional): Base reference for altitude axis.\n        zmin (float, optional): Minimum altitude AGL (m).\n        zmax (float, optional): Maximum altitude AGL (m).\n        vmin (float, optional): Minimum value.\n        vmax (float, optional): Maximum value. If `None`, calculates max from data.\n        log (bool, optional): Use logarithmic scale.\n        show_foc (bool, optional): Add foc detection.\n        show_pbl (bool, optional): Add PBL height.\n        show_clouds (bool, optional): Add clouds detection.\n        cmap (str, optional): Matplotlib colormap.\n        show_fig (bool, optional): Show figure.\n        save_fig (str, optional): Path of the saved figure.\n\n    Example:\n        ``` python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # attenuated backscatter image\n        profiles.plot(vmin=1e-2, vmax=1e1, log=True)\n        ```\n        ![Image of attenuated backscatter profiles](../../assets/images/attenuated_backscatter.png)\n    \"\"\"\n\n    # calculates max value from data\n    if vmax is None and type(da[var].data[0][0]) != np.bool:\n        perc = np.percentile(da[var].data, 70)\n        pow10 = np.ceil(np.log10(perc))\n        vmax = 10 ** (pow10)\n\n    # time\n    time = da.time.data\n    # altitude\n    if zref.upper() == \"AGL\":\n        altitude = da.altitude.data\n    else:\n        raise ValueError(\"Unsupported altitude reference. Use 'AGL'.\")\n\n    fig, axs = plt.subplots(1, 1, figsize=(12, 4))\n\n    # 2D array\n    C = da[var].data.T\n\n    if log:\n        import matplotlib.colors as colors\n\n        pcm = plt.pcolormesh(\n            time,\n            altitude,\n            C,\n            norm=colors.LogNorm(vmin=np.max([0, vmin]), vmax=vmax),\n            cmap=cmap,\n            shading=\"nearest\",\n        )\n    else:\n        pcm = plt.pcolormesh(\n            time, altitude, C, vmin=vmin, vmax=vmax, cmap=cmap, shading=\"nearest\"\n        )\n    # store colorbar\n    cbar = fig.colorbar(pcm, ax=axs)\n\n    # add addition information\n    if show_foc:\n        _plot_foc(da, zref)\n    if show_clouds:\n        _plot_clouds(da, zref)\n    if show_pbl:\n        _plot_pbl(da, zref)\n\n    # limit to altitude range\n    plt.ylim([zmin, zmax])\n\n    # set title and axis labels\n    yyyy = pd.to_datetime(da.time.values[0]).year\n    mm = pd.to_datetime(da.time.values[0]).month\n    dd = pd.to_datetime(da.time.values[0]).day\n    latitude = da.station_latitude.data\n    longitude = da.station_longitude.data\n    altitude = da.station_altitude.data\n    station_id = da.attrs[\"site_location\"]\n    # title\n    str_latitude = (\n        f\"{latitude[0]:.2f}\"\n        if len(np.unique(latitude)) == 1\n        else f\"{np.min(latitude):.2f}-{np.max(latitude):.2f}\"\n    )\n    str_longitude = (\n        f\"{longitude[0]:.2f}\"\n        if len(np.unique(longitude)) == 1\n        else f\"{np.min(longitude):.2f}-{np.max(longitude):.2f}\"\n    )\n    str_altitude = (\n        f\"{altitude[0]:.2f}\"\n        if len(np.unique(altitude)) == 1\n        else f\"{np.min(altitude):.2f}-{np.max(altitude):.2f}\"\n    )\n\n    plt.title(\n        f\"{station_id} ({str_latitude};{str_longitude};{str_altitude}m) - {yyyy}/{mm:02}/{dd:02}\",\n        weight=\"bold\",\n    )\n    # labels\n    plt.xlabel(\"Time\")\n    plt.ylabel(f\"Altitude {zref.upper()} (m)\")\n\n    # add legend\n    if show_foc or show_clouds or show_pbl:\n        plt.legend(loc=\"upper right\")\n\n    # label\n    if \"units\" in list(da[var].attrs) and da[var].units is not None:\n        label = f\"{da[var].long_name} ({da[var].units})\"\n    else:\n        label = f\"{da[var].long_name}\"\n    cbar.set_label(label)\n\n    plt.tight_layout()\n    if save_fig:\n        plt.savefig(save_fig)\n    if show_fig:\n        plt.show()\n</code></pre>"},{"location":"api/plotting/#profile","title":"Profile","text":"<p>This module is used to plot a single profile for a given <code>numpy.datetime64</code>, of a given variable of an instance of the <code>ProfilesData</code> class.</p>"},{"location":"api/plotting/#aprofiles.plot.profile.plot","title":"<code>plot(da, datetime, var='attenuated_backscatter_0', zref='agl', zmin=None, zmax=None, vmin=None, vmax=None, log=False, show_foc=False, show_pbl=False, show_clouds=False, show_fig=True, save_fig=None)</code>","text":"<p>Plot single profile of selected variable from (aprofiles.profiles.ProfilesData): object.</p> <p>Parameters:</p> Name Type Description Default <code>da</code> <code>DataArray</code> <p>DataArray.</p> required <code>datetime</code> <code>datetime64</code> <p>Time for which the profile is plotted.</p> required <code>var</code> <code>str</code> <p>Variable of the DataArray to be plotted.</p> <code>'attenuated_backscatter_0'</code> <code>zref</code> <code>{agl, asl}</code> <p>Base reference for the altitude axis. Defaults to 'agl'.</p> <code>'agl'</code> <code>zmin</code> <code>float</code> <p>Minimum altitude AGL (m). Defaults to minimum available altitude.</p> <code>None</code> <code>zmax</code> <code>float</code> <p>Maximum altitude AGL (m). Defaults to maximum available altitude.</p> <code>None</code> <code>vmin</code> <code>float</code> <p>Minimum value.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>Maximum value. If None, calculates max from data.</p> <code>None</code> <code>log</code> <code>bool</code> <p>Use logarithmic scale.</p> <code>False</code> <code>show_foc</code> <code>bool</code> <p>Add foc detection.</p> <code>False</code> <code>show_pbl</code> <code>bool</code> <p>Add PBL height.</p> <code>False</code> <code>show_clouds</code> <code>bool</code> <p>Add clouds detection.</p> <code>False</code> <code>show_fig</code> <code>bool</code> <p>Show figure.</p> <code>True</code> <code>save_fig</code> <code>str</code> <p>Path of the saved figure.</p> <code>None</code> Example <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# some detection\nprofiles.clouds(inplace=True).pbl(inplace=True)\n# attenuated backscatter single profile\ndatetime = np.datetime64('2021-09-09T10:25:00')\nprofiles.plot(datetime=datetime, vmin=-1, vmax=10, zmax=12000, show_clouds=True, show_pbl=True)\n</code></pre> <p></p> Source code in <code>aprofiles/plot/profile.py</code> <pre><code>def plot(\n    da,\n    datetime,\n    var=\"attenuated_backscatter_0\",\n    zref=\"agl\",\n    zmin=None,\n    zmax=None,\n    vmin=None,\n    vmax=None,\n    log=False,\n    show_foc=False,\n    show_pbl=False,\n    show_clouds=False,\n    show_fig=True,\n    save_fig=None,\n):\n    \"\"\"\n    Plot single profile of selected variable from (aprofiles.profiles.ProfilesData): object.\n\n    Args:\n        da (xarray.DataArray): DataArray.\n        datetime (numpy.datetime64): Time for which the profile is plotted.\n        var (str, optional): Variable of the DataArray to be plotted.\n        zref ({'agl', 'asl'}, optional): Base reference for the altitude axis. Defaults to 'agl'.\n        zmin (float, optional): Minimum altitude AGL (m). Defaults to minimum available altitude.\n        zmax (float, optional): Maximum altitude AGL (m). Defaults to maximum available altitude.\n        vmin (float, optional): Minimum value.\n        vmax (float, optional): Maximum value. If None, calculates max from data.\n        log (bool, optional): Use logarithmic scale.\n        show_foc (bool, optional): Add foc detection.\n        show_pbl (bool, optional): Add PBL height.\n        show_clouds (bool, optional): Add clouds detection.\n        show_fig (bool, optional): Show figure.\n        save_fig (str, optional): Path of the saved figure.\n\n    Example:\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # some detection\n        profiles.clouds(inplace=True).pbl(inplace=True)\n        # attenuated backscatter single profile\n        datetime = np.datetime64('2021-09-09T10:25:00')\n        profiles.plot(datetime=datetime, vmin=-1, vmax=10, zmax=12000, show_clouds=True, show_pbl=True)\n        ```\n\n        ![Single profile of attenuated backscatter](../../assets/images/Profile-Oslo-20210909T212005.png){: style=\"width: 60%;\" }\n    \"\"\"\n\n    if datetime is None:\n        raise ValueError(\n            \"datetime needs to be a np.datetime object, e.g. time=np.datetime(2021-09-09T16:00:00)\"\n        )\n    # get index of closest profile\n    da_time = da.time.data\n    i_time = np.argmin(abs(da_time - datetime))\n\n    # altitude\n    if zref.upper() == \"AGL\":\n        altitude = da.altitude.data\n    elif zref.upper() == \"ASL\":\n        altitude = da.altitude.data + da.station_altitude.data[i_time]\n\n    fig, axs = plt.subplots(1, 1, figsize=(6, 6))\n    plt.plot(da[var].data[i_time], altitude)\n    # add zeros\n    plt.plot(np.zeros(len(altitude)), altitude, \":k\", alpha=0.2)\n\n    if log:\n        axs.set_xscale(\"log\")\n\n    # add addition information\n    if show_foc:\n        _plot_foc(da, da_time[i_time], zref)\n    if show_clouds:\n        _plot_clouds(da, da_time[i_time], var, zref)\n    if show_pbl:\n        _plot_pbl(da, da_time[i_time], var, zref)\n\n    # set scales\n    plt.ylim([zmin, zmax])\n    if vmin is not None or vmax is not None:\n        plt.xlim([vmin, vmax])\n\n    # set title and axis labels\n    latitude = da.station_latitude.data[i_time]\n    longitude = da.station_longitude.data[i_time]\n    altitude = da.station_altitude.data[i_time]\n    station_id = da.attrs[\"site_location\"]\n    # title\n    plt.title(\n        f\"{station_id} ({latitude:.2f};{longitude:.2f};{altitude:.1f}m) - {np.datetime_as_string(da_time[i_time]).split('.')[0]}\",\n        weight=\"bold\",\n        fontsize=12,\n    )\n    # labels\n    if \"units\" in list(da[var].attrs) and da[var].units is not None:\n        xlabel = f\"{da[var].long_name} ({da[var].units})\"\n    else:\n        xlabel = f\"{da[var].long_name}\"\n    plt.xlabel(xlabel)\n    plt.ylabel(f\"Altitude {zref.upper()} (m)\")\n\n    # add legend\n    if show_foc or show_clouds or show_pbl:\n        plt.legend(loc=\"upper right\")\n\n    plt.tight_layout()\n    if save_fig:\n        plt.savefig(save_fig)\n    if show_fig:\n        plt.show()\n</code></pre>"},{"location":"api/plotting/#time-series","title":"Time Series","text":"<p>This module is used to plot a time series of a given variable of an instance of the <code>ProfilesData</code> class.</p>"},{"location":"api/plotting/#aprofiles.plot.timeseries.plot","title":"<code>plot(da, var='aod', show_fig=True, save_fig=None, **kwargs)</code>","text":"<p>Plot time series of selected variable from (aprofiles.profiles.ProfilesData): object.</p> <p>Parameters:</p> Name Type Description Default <code>da</code> <code>DataArray</code> <p>DataArray</p> required <code>var</code> <code>str</code> <p>Variable of the DataArray to be plotted.</p> <code>'aod'</code> <code>show_fig</code> <code>bool</code> <p>Show Figure.</p> <code>True</code> <code>save_fig</code> <code>str</code> <p>Path of the saved figure.</p> <code>None</code> Example <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# retrieve pbl height\nprofiles.pbl(zmin=200, zmax=3000)\n# attenuated backscatter image\nprofiles.plot(var=\"pbl\" ymin=0., ymax=3000., min_snr=2.)\n</code></pre> <p></p> Source code in <code>aprofiles/plot/timeseries.py</code> <pre><code>def plot(da, var=\"aod\", show_fig=True, save_fig=None, **kwargs):\n    \"\"\"\n    Plot time series of selected variable from (aprofiles.profiles.ProfilesData): object.\n\n    Args:\n        da (xarray.DataArray): DataArray\n        var (str, optional): Variable of the DataArray to be plotted.\n        show_fig (bool, optional): Show Figure.\n        save_fig (str, optional): Path of the saved figure.\n\n    Example:\n        ``` python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # retrieve pbl height\n        profiles.pbl(zmin=200, zmax=3000)\n        # attenuated backscatter image\n        profiles.plot(var=\"pbl\" ymin=0., ymax=3000., min_snr=2.)\n        ```\n\n        ![Time series of Planetary Boundary Layer height](../../assets/images/time_series.png)\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    # get kwargs\n    ymin = kwargs.get(\"ymin\", None)\n    ymax = kwargs.get(\"ymax\", None)\n\n    # time\n    time = da.time.data\n\n    fig, axs = plt.subplots(1, 1, figsize=(12, 4))\n\n    # plot time series\n    plt.plot(time, da[var].data)\n\n    # limit to altitude range\n    if ymin is not None or ymax is not None:\n        plt.ylim([ymin, ymax])\n\n    # set title and axis labels\n    yyyy = pd.to_datetime(da.time.values[0]).year\n    mm = pd.to_datetime(da.time.values[0]).month\n    dd = pd.to_datetime(da.time.values[0]).day\n    latitude = da.station_latitude.data\n    longitude = da.station_longitude.data\n    altitude = da.station_altitude.data\n    station_id = da.attrs[\"site_location\"]\n    # title\n    str_latitude = (\n        f\"{latitude[0]:.2f}\"\n        if len(np.unique(latitude)) == 1\n        else f\"{np.min(latitude):.2f}-{np.max(latitude):.2f}\"\n    )\n    str_longitude = (\n        f\"{longitude[0]:.2f}\"\n        if len(np.unique(longitude)) == 1\n        else f\"{np.min(longitude):.2f}-{np.max(longitude):.2f}\"\n    )\n    str_altitude = (\n        f\"{altitude[0]:.2f}\"\n        if len(np.unique(altitude)) == 1\n        else f\"{np.min(altitude):.2f}-{np.max(altitude):.2f}\"\n    )\n    # title\n    plt.title(\n        f\"{station_id} ({str_latitude};{str_longitude};{str_altitude}m) - {yyyy}/{mm:02}/{dd:02}\",\n        weight=\"bold\",\n    )\n    # labels\n    plt.xlabel(\"Time\")\n\n    if \"units\" in list(da[var].attrs) and da[var].units is not None:\n        ylabel = f\"{da[var].long_name} ({da[var].units})\"\n    else:\n        ylabel = f\"{da[var].long_name}\"\n    plt.ylabel(ylabel)\n\n    plt.tight_layout()\n    if save_fig:\n        plt.savefig(save_fig)\n    if show_fig:\n        plt.show()\n</code></pre>"},{"location":"api/reading/","title":"Reading","text":"<p>The <code>Reader</code> module includes classes for reading profiles (NetCDF) and Aeronet (txt) data.</p>"},{"location":"api/reading/#aprofiles.reader.ReadAeronet","title":"<code>ReadAeronet</code>","text":"<p>Base class for reading Aeronet data.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>str</code> <p>path of the file to be read.</p> Source code in <code>aprofiles/reader.py</code> <pre><code>class ReadAeronet:\n    \"\"\"\n    Base class for reading Aeronet data.\n\n    Attributes:\n        path (str): path of the file to be read.\n    \"\"\"\n\n    def __init__(self, path):\n        self.path = path\n        raise NotImplementedError(\"ReadAeronet class is not implemented yet\")\n</code></pre>"},{"location":"api/reading/#aprofiles.reader.ReadProfiles","title":"<code>ReadProfiles</code>","text":"<p>Base class for reading profiles data.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>str</code> <p>path of the file to be read.</p> Source code in <code>aprofiles/reader.py</code> <pre><code>class ReadProfiles:\n    \"\"\"\n    Base class for reading profiles data.\n\n    Attributes:\n        path (str): path of the file to be read.\n    \"\"\"\n\n    def __init__(self, path):\n        self.path = path\n\n    def read(self):\n        \"\"\"\n        Method which calls the relevant reading class based on the file name.\n\n        Returns:\n            (aprofiles.profiles.ProfilesData):\n\n        Example:\n            ```python\n            # import library\n            import aprofiles as apro\n            path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n            # initialize reading class with file path\n            reader = apro.reader.ReadProfiles(path)\n            # calls the read method\n            profiles = reader.read()\n            # print ProfilesData object\n            print(profiles)\n            &lt;aprofiles.profiles.ProfilesData object at 0x7f011055fad0&gt;\n            # print the content of this ProfilesData object\n            profiles.__dict__\n            {'_data': &lt;xarray.Dataset&gt;\n            Dimensions:                          (altitude: 511, layer: 3, time: 273)\n            Coordinates:\n            * time                             (time) datetime64[ns] 2021-09-09T00:00:04 ... 2021-09-09T23:55:06\n            * altitude                         (altitude) float64 111.0 ... 1.541e+04\n            Dimensions without coordinates: layer\n            Data variables:\n                start_time                       (time) datetime64[ns] ...\n                latitude                         (time, altitude) float64 ...\n                longitude                        (time, altitude) float64 ...\n                attenuated_backscatter_0         (time, altitude) float64 ...\n                uncertainties_att_backscatter_0  (time, altitude) float64 ...\n                l0_wavelength                    float64 1.064e+03\n                station_longitude                float64 ...\n                station_latitude                 float64 ...\n                station_altitude                 float64 ...\n                quality_flag                     (time, altitude) int64 ...\n                vertical_visibility              (time) float64 ...\n                cloud_base_height                (time, layer) float64 ...\n                cbh_uncertainties                (time, layer) float64 ...\n                cloud_amount                     (time) float64 ...\n                calibration_constant_0           (time) float64 ...\n            Attributes:\n                instrument_id:                A\n                hermes_history:               hermes-raw2l1 2.0.1, hermes-eprofile-alc-sc...\n                instrument_type:              CHM15k\n                site_location:                OSLO,NORWAY\n                title:                        OSLO nimbus MET NORWAY\n                principal_investigator:       Remote Sensing Group\n                optical_module_id:            TUB110019\n                comment:                      \n                Conventions:                  CF-1.7, UKMO-1.0.2\n                wigos_station_id:             0-20000-0-01492\n                source:                       Ground Based Remote Sensing\n                references:                   E-PROFILE Data Format Description Document\n                wmo_id:                       01492\n                overlap_is_corrected:         true\n                instrument_firmware_version:  1.04\n                overlap_function:             true\n                institution:                  MET NORWAY Remote Sensing Group\n                instrument_serial_number:     TUB110019\n                history:                      Thu Sep  9 00:30:28 2021: ncpdq -O -a time,...\n                NCO:                          netCDF Operators version 4.9.1 (Homepage = ...}\n            ```\n        \"\"\"\n\n        # get the right reading class\n        data = read_eprofile.ReadEPROFILE(self.path).read()\n\n        # instantitate ProfilesData class with data\n        profiles = ProfilesData(data)\n\n        return profiles\n</code></pre>"},{"location":"api/reading/#aprofiles.reader.ReadProfiles.read","title":"<code>read()</code>","text":"<p>Method which calls the relevant reading class based on the file name.</p> <p>Returns:</p> Type Description <code>ProfilesData</code> Example <pre><code># import library\nimport aprofiles as apro\npath = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n# initialize reading class with file path\nreader = apro.reader.ReadProfiles(path)\n# calls the read method\nprofiles = reader.read()\n# print ProfilesData object\nprint(profiles)\n&lt;aprofiles.profiles.ProfilesData object at 0x7f011055fad0&gt;\n# print the content of this ProfilesData object\nprofiles.__dict__\n{'_data': &lt;xarray.Dataset&gt;\nDimensions:                          (altitude: 511, layer: 3, time: 273)\nCoordinates:\n* time                             (time) datetime64[ns] 2021-09-09T00:00:04 ... 2021-09-09T23:55:06\n* altitude                         (altitude) float64 111.0 ... 1.541e+04\nDimensions without coordinates: layer\nData variables:\n    start_time                       (time) datetime64[ns] ...\n    latitude                         (time, altitude) float64 ...\n    longitude                        (time, altitude) float64 ...\n    attenuated_backscatter_0         (time, altitude) float64 ...\n    uncertainties_att_backscatter_0  (time, altitude) float64 ...\n    l0_wavelength                    float64 1.064e+03\n    station_longitude                float64 ...\n    station_latitude                 float64 ...\n    station_altitude                 float64 ...\n    quality_flag                     (time, altitude) int64 ...\n    vertical_visibility              (time) float64 ...\n    cloud_base_height                (time, layer) float64 ...\n    cbh_uncertainties                (time, layer) float64 ...\n    cloud_amount                     (time) float64 ...\n    calibration_constant_0           (time) float64 ...\nAttributes:\n    instrument_id:                A\n    hermes_history:               hermes-raw2l1 2.0.1, hermes-eprofile-alc-sc...\n    instrument_type:              CHM15k\n    site_location:                OSLO,NORWAY\n    title:                        OSLO nimbus MET NORWAY\n    principal_investigator:       Remote Sensing Group\n    optical_module_id:            TUB110019\n    comment:                      \n    Conventions:                  CF-1.7, UKMO-1.0.2\n    wigos_station_id:             0-20000-0-01492\n    source:                       Ground Based Remote Sensing\n    references:                   E-PROFILE Data Format Description Document\n    wmo_id:                       01492\n    overlap_is_corrected:         true\n    instrument_firmware_version:  1.04\n    overlap_function:             true\n    institution:                  MET NORWAY Remote Sensing Group\n    instrument_serial_number:     TUB110019\n    history:                      Thu Sep  9 00:30:28 2021: ncpdq -O -a time,...\n    NCO:                          netCDF Operators version 4.9.1 (Homepage = ...}\n</code></pre> Source code in <code>aprofiles/reader.py</code> <pre><code>def read(self):\n    \"\"\"\n    Method which calls the relevant reading class based on the file name.\n\n    Returns:\n        (aprofiles.profiles.ProfilesData):\n\n    Example:\n        ```python\n        # import library\n        import aprofiles as apro\n        path = \"examples/data/E-PROFILE/L2_0-20000-001492_A20210909.nc\"\n        # initialize reading class with file path\n        reader = apro.reader.ReadProfiles(path)\n        # calls the read method\n        profiles = reader.read()\n        # print ProfilesData object\n        print(profiles)\n        &lt;aprofiles.profiles.ProfilesData object at 0x7f011055fad0&gt;\n        # print the content of this ProfilesData object\n        profiles.__dict__\n        {'_data': &lt;xarray.Dataset&gt;\n        Dimensions:                          (altitude: 511, layer: 3, time: 273)\n        Coordinates:\n        * time                             (time) datetime64[ns] 2021-09-09T00:00:04 ... 2021-09-09T23:55:06\n        * altitude                         (altitude) float64 111.0 ... 1.541e+04\n        Dimensions without coordinates: layer\n        Data variables:\n            start_time                       (time) datetime64[ns] ...\n            latitude                         (time, altitude) float64 ...\n            longitude                        (time, altitude) float64 ...\n            attenuated_backscatter_0         (time, altitude) float64 ...\n            uncertainties_att_backscatter_0  (time, altitude) float64 ...\n            l0_wavelength                    float64 1.064e+03\n            station_longitude                float64 ...\n            station_latitude                 float64 ...\n            station_altitude                 float64 ...\n            quality_flag                     (time, altitude) int64 ...\n            vertical_visibility              (time) float64 ...\n            cloud_base_height                (time, layer) float64 ...\n            cbh_uncertainties                (time, layer) float64 ...\n            cloud_amount                     (time) float64 ...\n            calibration_constant_0           (time) float64 ...\n        Attributes:\n            instrument_id:                A\n            hermes_history:               hermes-raw2l1 2.0.1, hermes-eprofile-alc-sc...\n            instrument_type:              CHM15k\n            site_location:                OSLO,NORWAY\n            title:                        OSLO nimbus MET NORWAY\n            principal_investigator:       Remote Sensing Group\n            optical_module_id:            TUB110019\n            comment:                      \n            Conventions:                  CF-1.7, UKMO-1.0.2\n            wigos_station_id:             0-20000-0-01492\n            source:                       Ground Based Remote Sensing\n            references:                   E-PROFILE Data Format Description Document\n            wmo_id:                       01492\n            overlap_is_corrected:         true\n            instrument_firmware_version:  1.04\n            overlap_function:             true\n            institution:                  MET NORWAY Remote Sensing Group\n            instrument_serial_number:     TUB110019\n            history:                      Thu Sep  9 00:30:28 2021: ncpdq -O -a time,...\n            NCO:                          netCDF Operators version 4.9.1 (Homepage = ...}\n        ```\n    \"\"\"\n\n    # get the right reading class\n    data = read_eprofile.ReadEPROFILE(self.path).read()\n\n    # instantitate ProfilesData class with data\n    profiles = ProfilesData(data)\n\n    return profiles\n</code></pre>"},{"location":"api/retrieval/","title":"Retrieval","text":"<p>The following functions are methods from the class <code>ProfilesData</code></p>"},{"location":"api/retrieval/#aerosol-extinction","title":"Aerosol Extinction","text":"<p>This module is used to calculate extinction profiles from single attenuated backscatter profiles using an a priori.</p>"},{"location":"api/retrieval/#aprofiles.retrieval.extinction.backward_inversion","title":"<code>backward_inversion(data, iref, apriori, rayleigh)</code>","text":"<p>Backward (Klett [Klett1985]_ ) inversion method.</p> <p>.. [Klett1985] Klett, J. D. (1985). Lidar inversion with variable backscatter/extinction ratios. Applied optics, 24(11), 1638-1643.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>1D array of a single profile of the attenuated backscatter coefficient.</p> required <code>iref</code> <code>float</code> <p>Index of the reference altitude returned by :func:<code>aprofiles.retrieval.ref_altitude.get_iref()</code>.</p> required <code>apriori</code> <code>dict</code> <p>A priori values used to constrain the inversion. Valid keys include: - lr (float): Lidar Ratio (in sr). - aod (float): AOD (unitless).</p> required <code>rayleigh</code> <p>class:<code>aprofiles.rayleigh.RayleighData</code>): Instance of the <code>RayleighData</code> class.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>AOD apriori is not implemented yet.</p> <p>Returns:</p> Type Description <code>array_like</code> <p>Extinction coefficient (in m\u207b\u00b9).</p> Source code in <code>aprofiles/retrieval/extinction.py</code> <pre><code>def backward_inversion(data, iref, apriori, rayleigh):\n    \"\"\"\n    Backward (Klett [Klett1985]_ ) inversion method.\n\n    .. [Klett1985] Klett, J. D. (1985). Lidar inversion with variable backscatter/extinction ratios. Applied optics, 24(11), 1638-1643.\n\n    Args:\n        data (array_like): 1D array of a single profile of the attenuated backscatter coefficient.\n        iref (float): Index of the reference altitude returned by :func:`aprofiles.retrieval.ref_altitude.get_iref()`.\n        apriori (dict): A priori values used to constrain the inversion. Valid keys include:\n            - **lr** (float): Lidar Ratio (in sr).\n            - **aod** (float): AOD (unitless).\n        rayleigh (:class:`aprofiles.rayleigh.RayleighData`): Instance of the `RayleighData` class.\n\n    Raises:\n        NotImplementedError: AOD apriori is not implemented yet.\n\n    Returns:\n        (array_like): Extinction coefficient (in m\u207b\u00b9).\n    \"\"\"\n\n    if \"aod\" in apriori:\n        # search by dichotomy the LR that matches the apriori aod\n        raise NotImplementedError(\"AOD apriori is not implemented yet\")\n        lr_aer = 50\n    else:\n        # if we assume the LR, no need to minimize for matching aod\n        lr_aer = apriori[\"lr\"]\n    lr_mol = 8.0 * np.pi / 3.0\n\n    # vertical resolution\n    dz = min(np.diff(rayleigh.altitude))\n\n    int1_a = np.cumsum((lr_aer - lr_mol) * rayleigh.backscatter[:iref] * dz)\n    int1_b = [2 * int1_a[-1] - 2 * int1_a[i] for i in range(iref)]\n    phi = [np.log(abs(data[i] / data[iref])) + int1_b[i] for i in range(iref)]\n\n    int2_a = 2 * np.nancumsum(lr_aer * np.exp(phi) * dz)\n    int2_b = [int2_a[-1] - int2_a[i] for i in range(iref)]\n\n    # initialize total backscatter\n    back_aer_iref = 0  # m-1\n    beta_tot_iref = rayleigh.backscatter[iref] + back_aer_iref\n\n    # total backscatter\n    beta_tot = [np.exp(phi[i]) / ((1 / beta_tot_iref) + int2_b[i]) for i in range(iref)]\n    # aerosol backsatter (m-1.sr-1)\n    beta_aer = beta_tot - rayleigh.backscatter[:iref]\n    # aerosol extinction (m-1)\n    sigma_aer = lr_aer * beta_aer\n    # returns extinction in m-1 when valid, and np.nan elsewhere\n    ext = [sigma_aer[i] if i &lt; len(sigma_aer) else np.nan for i in range(len(data))]\n    return ext\n</code></pre>"},{"location":"api/retrieval/#aprofiles.retrieval.extinction.forward_inversion","title":"<code>forward_inversion(data, iref, apriori, rayleigh)</code>","text":"<p>Forward iterative inversion method [#]_.</p> <p>.. [#] Li, D., Wu, Y., Gross, B., &amp; Moshary, F. (2021). Capabilities of an Automatic Lidar Ceilometer to Retrieve Aerosol Characteristics within the Planetary Boundary Layer. Remote Sensing, 13(18), 3626.</p> <p>Method principle:</p> <p>At z0, the aerosol transmission is assumed as being close to 1. We evaluate the aerosol extinction based on this assumption. This evaluation gives a refined aerosol extinction that is used to calculate a second time the aerosol transmission. The aerosol extinction retrieval will converge after a certain number iterations. After the convergence, the aerosol extinction is retrieved in the next upper layer.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>1D Array of single profile of attenuated backscatter coefficient, in m-1.sr-1.</p> required <code>iref</code> <code>float</code> <p>index of the reference altitude returned by :func:<code>aprofiles.retrieval.ref_altitude.get_iref()</code>.</p> required <code>apriori</code> <code>dict</code> <p>A priori value to be used to constrain the inversion. Valid keys: \u2018lr\u2019 (Lidar Ratio, in sr) and \u2018aod\u2019 (unitless).</p> required <code>rayleigh</code> <code>aprofiles.rayleigh.RayleighData). Instance of the </code> <p>class:<code>aprofiles.rayleigh.RayleighData</code> class.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>AOD apriori is not implemented yet.</p> <p>Returns:</p> Type Description <code>array_like</code> <p>Extinction coefficient (in m\u207b\u00b9).</p> Source code in <code>aprofiles/retrieval/extinction.py</code> <pre><code>def forward_inversion(data, iref, apriori, rayleigh):\n    \"\"\"Forward iterative inversion method [#]_.\n\n    .. [#] Li, D., Wu, Y., Gross, B., &amp; Moshary, F. (2021). Capabilities of an Automatic Lidar Ceilometer to Retrieve Aerosol Characteristics within the Planetary Boundary Layer. Remote Sensing, 13(18), 3626.\n\n    Method principle:\n\n    At z0, the aerosol transmission is assumed as being close to 1. We evaluate the aerosol extinction based on this assumption.\n    This evaluation gives a refined aerosol extinction that is used to calculate a second time the aerosol transmission.\n    The aerosol extinction retrieval will converge after a certain number iterations.\n    After the convergence, the aerosol extinction is retrieved in the next upper layer.\n\n    Args:\n        data (array_like): 1D Array of single profile of attenuated backscatter coefficient, in m-1.sr-1.\n        iref (float): index of the reference altitude returned by :func:`aprofiles.retrieval.ref_altitude.get_iref()`.\n        apriori (dict): A priori value to be used to constrain the inversion. Valid keys: \u2018lr\u2019 (Lidar Ratio, in sr) and \u2018aod\u2019 (unitless).\n        rayleigh (aprofiles.rayleigh.RayleighData). Instance of the :class:`aprofiles.rayleigh.RayleighData` class.\n\n    Raises:\n        NotImplementedError: AOD apriori is not implemented yet.\n\n    Returns:\n        (array_like): Extinction coefficient (in m\u207b\u00b9).\n    \"\"\"\n\n    if \"aod\" in apriori:\n        # search by dichotomy the LR that matches the apriori aod\n        raise NotImplementedError(\"AOD apriori is not implemented yet\")\n        lr_aer = 50\n    elif \"lr\" in apriori:\n        # if we assume the LR, no need to minimize for matching aod\n        lr_aer = apriori[\"lr\"]\n    lr_mol = 8.0 * np.pi / 3.0\n\n    def _get_aer_at_i(data, i, Tm, Bm, Ta, Ba, Ea, dz, nloop_max=30, diff_ext=0.01):\n        # suppress warnings\n        warnings.filterwarnings(\"ignore\")\n\n        for _ in range(nloop_max):\n            if np.isnan(Ea[i]):\n                Ta[i] = 1\n            else:\n                Ta[i] = np.exp(-np.nancumsum(Ea * dz))[i]\n            if (Tm[i] ** 2 * Ta[i] ** 2) != 0:\n                Ba[i] = data[i] / (Tm[i] ** 2 * Ta[i] ** 2) - Bm[i]\n            else:\n                Ba[i] = np.nan\n            # test extinction\n            if 1 - (lr_aer * Ba[i] / Ea[i]) &lt; diff_ext:\n                Ea[i] = lr_aer * Ba[i]\n                break\n            Ea[i] = lr_aer * Ba[i]\n\n        return Ba[i], Ea[i], Ta[i]\n\n    # vertical resolution\n    dz = min(np.diff(rayleigh.altitude))\n\n    Bm = rayleigh.backscatter\n    Em = rayleigh.extinction\n    Tm = np.exp(-np.cumsum(Em * dz))\n\n    # Initialize aer profiles\n    Ta = np.asarray([np.nan for _ in range(len(data))])\n    Ba = np.asarray([np.nan for _ in range(len(data))])\n    Ea = np.asarray([np.nan for _ in range(len(data))])\n\n    for i in range(iref):\n        Ba[i], Ea[i], Ta[i] = _get_aer_at_i(data, i, Tm, Bm, Ta, Ba, Ea, dz)\n        if np.isnan(Ba[i]):\n            continue\n    # returns extinction in m-1\n    ext = Ea\n    return ext\n</code></pre>"},{"location":"api/retrieval/#aprofiles.retrieval.extinction.inversion","title":"<code>inversion(profiles, time_avg=1, zmin=4000.0, zmax=6000.0, min_snr=0.0, under_clouds=False, method='forward', apriori={'lr': 50.0}, remove_outliers=False, verbose=False)</code>","text":"<p>Aerosol inversion of the attenuated backscatter profiles using an apriori.</p> <p>Parameters:</p> Name Type Description Default <code>profiles</code> <code>ProfilesData</code> <p><code>ProfilesData</code> instance.</p> required <code>time_avg</code> <code>int</code> <p>in minutes, the time during which we aggregate the profiles before inverting the profiles.</p> <code>1</code> <code>zmin</code> <code>float</code> <p>minimum altitude AGL, in m, for looking for the initialization altitude.</p> <code>4000.0</code> <code>zmax</code> <code>float</code> <p>maximum altitude AGL, in m, for looking for the initialization altitude.</p> <code>6000.0</code> <code>min_snr</code> <code>float</code> <p>Minimum SNR required at the reference altitude to be valid.</p> <code>0.0</code> <code>under_clouds</code> <code>bool</code> <p>If True, and if the <code>ProfilesData</code> has a <code>cloud_base</code> variable (returned by the <code>clouds</code> method), forces the initialization altitude to be found below the first cloud detected in the profile.</p> <code>False</code> <code>method</code> <code>str</code> <p>must be in [\u2018backward\u2019, \u2018forward\u2019].</p> <code>'forward'</code> <code>apriori</code> <code>dict</code> <p>A priori value to be used to constrain the inversion. Valid keys: \u2018lr\u2019 (Lidar Ratio, in sr), \u2018aod\u2019 (unitless), 'cfg' (path of config file).</p> <code>{'lr': 50.0}</code> <code>remove_outliers</code> <code>bool</code> <p>Remove profiles considered as outliers based on aod calculation (AOD&lt;0, or AOD&gt;2).</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>verbose mode.</p> <code>False</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>AOD apriori is not implemented yet.</p> <p>Returns:</p> Type Description <code>ProfilesData</code> <p>object with additional (xarray.DataArray):</p> <ul> <li><code>'extinction' (time, altitude)</code>: 2D array corresponding to the aerosol extinction, in km-1.</li> <li><code>'aod' (time)</code>: 1D array corresponding to the aerosol optical depth associated to the extinction profiles.</li> <li><code>'lidar_ratio' (time)</code>: 1D array corresponding to the lidar ratio associated to the extinction profiles.</li> </ul> Example <p>Profiles preparation <pre><code>import aprofiles as apro\n#read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n#extrapolate lowest layers\nprofiles.extrapolate_below(z=150, inplace=True)\n</code></pre></p> <p>Backward inversion <pre><code>#aerosol inversion\nprofiles.inversion(zmin=4000, zmax=6000, remove_outliers=False, method='backward')\n#plot extinction profiles\nprofiles.plot(var='extinction', zmax=6000, vmin=0, vmax=5e-2)\n</code></pre></p> <p></p> <p>Forward inversion <pre><code>#aerosol inversion\nprofiles.inversion(zmin=4000, zmax=6000, remove_outliers=False, method='forward')\n#plot extinction profiles\nprofiles.plot(var='extinction', zmax=6000, vmin=0, vmax=5e-2)\n</code></pre></p> <p></p> Source code in <code>aprofiles/retrieval/extinction.py</code> <pre><code>def inversion(\n    profiles,\n    time_avg=1,\n    zmin=4000.0,\n    zmax=6000.0,\n    min_snr=0.0,\n    under_clouds=False,\n    method=\"forward\",\n    apriori={\"lr\": 50.0},\n    remove_outliers=False,\n    verbose=False,\n):\n    \"\"\"Aerosol inversion of the attenuated backscatter profiles using an apriori.\n\n    Args:\n        profiles (aprofiles.profiles.ProfilesData): `ProfilesData` instance.\n        time_avg (int, optional): in minutes, the time during which we aggregate the profiles before inverting the profiles.\n        zmin (float, optional): minimum altitude AGL, in m, for looking for the initialization altitude.\n        zmax (float, optional): maximum altitude AGL, in m, for looking for the initialization altitude.\n        min_snr (float, optional): Minimum SNR required at the reference altitude to be valid.\n        under_clouds (bool, optional): If True, and if the `ProfilesData` has a `cloud_base` variable (returned by the `clouds` method), forces the initialization altitude to be found below the first cloud detected in the profile.\n        method (str, optional): must be in [\u2018backward\u2019, \u2018forward\u2019].\n        apriori (dict, optional): A priori value to be used to constrain the inversion. Valid keys: \u2018lr\u2019 (Lidar Ratio, in sr), \u2018aod\u2019 (unitless), 'cfg' (path of config file).\n        remove_outliers (bool, optional): Remove profiles considered as outliers based on aod calculation (AOD&lt;0, or AOD&gt;2).\n        verbose (bool, optional): verbose mode.\n\n    Raises:\n        NotImplementedError: AOD apriori is not implemented yet.\n\n    Returns:\n        (aprofiles.profiles.ProfilesData):\n            object with additional (xarray.DataArray):\n\n            - `'extinction' (time, altitude)`: 2D array corresponding to the aerosol extinction, in km-1.\n            - `'aod' (time)`: 1D array corresponding to the aerosol optical depth associated to the extinction profiles.\n            - `'lidar_ratio' (time)`: 1D array corresponding to the lidar ratio associated to the extinction profiles.\n\n    Example:\n        Profiles preparation\n        ```python\n        import aprofiles as apro\n        #read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        #extrapolate lowest layers\n        profiles.extrapolate_below(z=150, inplace=True)\n        ```\n\n        Backward inversion\n        ```python\n        #aerosol inversion\n        profiles.inversion(zmin=4000, zmax=6000, remove_outliers=False, method='backward')\n        #plot extinction profiles\n        profiles.plot(var='extinction', zmax=6000, vmin=0, vmax=5e-2)\n        ```\n\n        ![Extinction profiles retrieved with the backward method](../../assets/images/backward.png)\n\n        Forward inversion\n        ```python\n        #aerosol inversion\n        profiles.inversion(zmin=4000, zmax=6000, remove_outliers=False, method='forward')\n        #plot extinction profiles\n        profiles.plot(var='extinction', zmax=6000, vmin=0, vmax=5e-2)\n        ```\n\n        ![Extinction profiles retrieved with the forward method](../../assets/images/forward.png)\n    \"\"\"\n\n    # we work on profiles averaged in time to reduce the noise\n    rcs = profiles.time_avg(\n        time_avg, var=\"attenuated_backscatter_0\", inplace=False\n    ).data.attenuated_backscatter_0\n\n    \"\"\"\n    #if clouds detected, set to nan profiles where cloud is found below 4000m\n    lowest_clouds = profiles._get_lowest_clouds()\n    for i in range(len(profiles.data.time.data)):\n        if lowest_clouds[i]&lt;=4000:\n            rcs.data[i,:] = [np.nan for _ in rcs.data[i,:]]\n    \"\"\"\n\n    # if under_clouds, check if clouds_bases is available\n    if under_clouds and \"clouds\" in list(profiles.data.data_vars):\n        lowest_clouds = profiles._get_lowest_clouds()\n    elif under_clouds and \"clouds\" not in list(profiles.data.data_vars):\n        warnings.warn(\n            \"under_clouds parameter sets to True (defaults value) when the clouds detection has not been applied to ProfileData object.\"\n        )\n        lowest_clouds = [np.nan for i in np.arange(len(profiles.data.time))]\n    else:\n        lowest_clouds = [np.nan for i in np.arange(len(profiles.data.time))]\n\n    # aerosol inversion\n    ext, lr, aod, z_ref = [], [], [], []\n    aod_min, aod_max = 0, 2\n    vertical_resolution = profiles._get_resolution(\"altitude\")\n    for i in track(\n        range(len(profiles.data.time.data)), description=\"klett \", disable=not verbose\n    ):\n        altitude_agl = profiles.data.altitude.data\n        altitude_asl = (\n            profiles.data.altitude.data + profiles.data.station_altitude.data[i]\n        )\n\n        # aerosol retrieval requires a molecular profile: use station_altitude in addition\n        wavelength = float(profiles.data.l0_wavelength.data)\n        rayleigh = apro.rayleigh.RayleighData(\n            altitude_asl, T0=298, P0=1013, wavelength=wavelength\n        )\n\n        # for this inversion, it is important to use the right units\n        if \"Mm\" in profiles.data.attenuated_backscatter_0.units:\n            calibrated_data = (\n                rcs.data[i, :] * 1e-6\n            )  # conversion from Mm-1.sr-1 to m-1.sr-1\n        else:\n            calibrated_data = rcs.data[i, :]\n\n        # reference altitude\n        imin = profiles._get_index_from_altitude_AGL(zmin)\n        imax = profiles._get_index_from_altitude_AGL(\n            np.nanmin([zmax, lowest_clouds[i]])\n        )\n        if method == \"backward\":\n            iref = get_iref(rcs.data[i, :], imin, imax, min_snr)\n        elif method == \"forward\":\n            iref = imax\n        z_ref.append(altitude_agl[iref])\n\n        if iref is not None:\n            # aerosol inversion\n            if method == \"backward\":\n                _ext = backward_inversion(calibrated_data, iref, apriori, rayleigh)\n            elif method == \"forward\":\n                _ext = forward_inversion(calibrated_data, iref, apriori, rayleigh)\n        else:\n            _ext = [np.nan for _ in range(len(calibrated_data))]\n\n        # add aod and lr\n        if \"aod\" in apriori:\n            # search by dichotomy the LR that matches the apriori aod\n            raise NotImplementedError(\"AOD apriori is not implemented yet\")\n        else:\n            # if we assume the LR, no need to minimize for matching aod\n            _lr = apriori[\"lr\"]\n            _aod = np.nancumsum(np.asarray(_ext) * vertical_resolution)[-1]\n            if remove_outliers and _aod &lt; aod_min or remove_outliers and _aod &gt; aod_max:\n                lr.append(np.nan)\n                aod.append(np.nan)\n                ext.append([np.nan for x in _ext])\n            else:\n                lr.append(_lr)\n                aod.append(_aod)\n                ext.append(_ext)\n\n    # creates dataarrays\n    profiles.data[\"extinction\"] = ((\"time\", \"altitude\"), np.asarray(ext) * 1e3)\n    profiles.data[\"extinction\"] = profiles.data.extinction.assign_attrs(\n        {\n            \"long_name\": f\"Extinction Coefficient @ {int(wavelength)} nm\",\n            \"method\": f\"{method.capitalize()} Klett\",\n            \"units\": \"km-1\",\n            \"time_avg\": time_avg,\n            \"zmin\": zmin,\n            \"zmax\": zmax,\n            \"apriori_variable\": list(apriori.keys())[0],\n            \"apriori_value\": apriori[list(apriori.keys())[0]],\n        }\n    )\n\n    profiles.data[\"aod\"] = (\"time\", aod)\n    profiles.data[\"aod\"] = profiles.data.aod.assign_attrs(\n        {\"long_name\": f\"Aerosol Optical Depth @ {int(wavelength)} nm\", \"unit\": \"\"}\n    )\n\n    profiles.data[\"lidar_ratio\"] = (\"time\", lr)\n    profiles.data[\"lidar_ratio\"] = profiles.data.lidar_ratio.assign_attrs(\n        {\n            \"long_name\": f\"Lidar Ratio @\u00a0{int(wavelength)} nm\",\n            \"units\": \"sr\",\n            \"use_cfg\": str(apriori[\"use_cfg\"]),\n        }\n    )\n    if \"cfg\" in apriori:\n        profiles.data[\"lidar_ratio\"] = profiles.data.lidar_ratio.assign_attrs(\n            {\"cfg\": str(apriori[\"cfg\"])}\n        )\n\n    profiles.data[\"z_ref\"] = (\"time\", z_ref)\n    profiles.data[\"z_ref\"] = profiles.data.z_ref.assign_attrs(\n        {\"long_name\": f\"Reference altitude ASL\", \"units\": \"m\"}\n    )\n\n    return profiles\n</code></pre>"},{"location":"api/retrieval/#mass-concentration","title":"Mass Concentration","text":"<p>This module is used to calculate mass concentration profiles from extinction profiles for given aerosol types.</p>"},{"location":"api/retrieval/#aprofiles.retrieval.mass_conc.concentration_profiles","title":"<code>concentration_profiles(profiles, method, apriori)</code>","text":"<p>Calculates Mass concentration profiles for different aerosol types</p> <p>Parameters:</p> Name Type Description Default <code>profiles</code> <code>ProfilesData</code> <p><code>ProfilesData</code> instance.</p> required <code>method</code> <code>str</code> <p>Method for calculating MEC. Must be one of {\"mortier_2013\", \"literature\"}.</p> required <code>apriori</code> <code>dict</code> <p>Apriori mec value (m2.g-1).</p> required <p>Returns:</p> Type Description <code>ProfilesData</code> <p>object with additional (xarray.Dataset):</p> <ul> <li><code>'mass_concentration:&lt;aer_type&gt;'</code></li> </ul> Example <p>Profiles preparation <pre><code>import aprofiles as apro\n# read example file\npath = \"examples/data/L2_0-20000-001492_A20210909.nc\"\nreader = apro.reader.ReadProfiles(path)\nprofiles = reader.read()\n# extrapolate lowest layers\nprofiles.extrapolate_below(z=150, inplace=True)\n</code></pre></p> <p>Forward inversion <pre><code># aerosol inversion\nprofiles.inversion(\n    zmin=4000, zmax=6000, remove_outliers=False, method='forward', \n    method_mass_conc='mortier_2013'\n)\n# plot mass concentration profiles for urban particles\nprofiles.plot(var='mass_concentration:urban', zmax=6000, vmin=0, vmax=100)\n</code></pre></p> <p></p> Source code in <code>aprofiles/retrieval/mass_conc.py</code> <pre><code>def concentration_profiles(profiles, method, apriori):\n    \"\"\"Calculates Mass concentration profiles for different aerosol types\n\n    Args:\n        profiles (aprofiles.profiles.ProfilesData): `ProfilesData` instance.\n        method (str): Method for calculating MEC. Must be one of {\"mortier_2013\", \"literature\"}.\n        apriori (dict): Apriori mec value (m2.g-1).\n\n    Returns:\n        (aprofiles.profiles.ProfilesData):\n            object with additional (xarray.Dataset):\n\n            - `'mass_concentration:&lt;aer_type&gt;'`\n\n    Example:\n        Profiles preparation\n        ```python\n        import aprofiles as apro\n        # read example file\n        path = \"examples/data/L2_0-20000-001492_A20210909.nc\"\n        reader = apro.reader.ReadProfiles(path)\n        profiles = reader.read()\n        # extrapolate lowest layers\n        profiles.extrapolate_below(z=150, inplace=True)\n        ```\n\n        Forward inversion\n        ```python\n        # aerosol inversion\n        profiles.inversion(\n            zmin=4000, zmax=6000, remove_outliers=False, method='forward', \n            method_mass_conc='mortier_2013'\n        )\n        # plot mass concentration profiles for urban particles\n        profiles.plot(var='mass_concentration:urban', zmax=6000, vmin=0, vmax=100)\n        ```\n\n        ![Mass concentration profiles in the case of urban particles](../../assets/images/mass_conc-urban.png)\n    \"\"\"\n\n    # read aer_properties.json files\n    f = open(Path(Path(__file__).parent,'..','config','aer_properties.json'))\n    aer_properties = json.load(f)\n    f.close()\n    # check if the aer_type exist in the json file\n    aer_types = aer_properties.keys()\n\n    # get wavelength\n    wavelength = float(profiles.data.l0_wavelength.data)\n    if profiles.data.l0_wavelength.units != \"nm\":\n        raise ValueError(\"wavelength units is not `nm`.\")\n\n    for aer_type in aer_types:\n        # calculates mec\n        mec = apro.mec.MECData(aer_type, wavelength, method)\n\n        # compute mass_concentration profile. Use extinction as base.\n        mass_concentration = profiles.data.extinction * 1e-3 #conversion from km-1 to m-1\n        # mass_concentration = copy.deepcopy(profiles.data.extinction)\n        mass_concentration.data = np.divide(mass_concentration, mec.mec)\n        # # conversion from g.m-3 to \u00b5g.m-3\n        mass_concentration.data = mass_concentration.data * 1e6\n\n        # creates dataset with a dataarray for each aer_type\n        profiles.data[f\"mass_concentration:{aer_type}\"] = (('time', 'altitude'), mass_concentration.data)\n        profiles.data[f\"mass_concentration:{aer_type}\"] = profiles.data[f\"mass_concentration:{aer_type}\"].assign_attrs({\n            'long_name': f\"Mass concentration [{aer_type.replace('_', ' ')} particles]\",\n            'units': '\u00b5g.m-3',\n            'mec': mec.mec,\n        })\n\n    # add ifs mec\n    if apriori.get(\"mec\"):\n        aer_type = \"ifs\"\n        # compute mass_concentration profile. Use extinction as base.\n        mass_concentration = profiles.data.extinction * 1e-3 #conversion from km-1 to m-1\n        # mass_concentration = copy.deepcopy(profiles.data.extinction)\n        mass_concentration.data = np.divide(mass_concentration, apriori[\"mec\"])\n        # # conversion from g.m-3 to \u00b5g.m-3\n        mass_concentration.data = mass_concentration.data * 1e6\n\n        # creates dataset with a dataarray for each aer_type\n        profiles.data[f\"mass_concentration:{aer_type}\"] = (('time', 'altitude'), mass_concentration.data)\n        profiles.data[f\"mass_concentration:{aer_type}\"] = profiles.data[f\"mass_concentration:{aer_type}\"].assign_attrs({\n            'long_name': f\"Mass concentration [{aer_type.replace('_', ' ')}]\",\n            'units': '\u00b5g.m-3',\n            'mec': apriori[\"mec\"],\n        })\n\n    return profiles\n</code></pre>"},{"location":"api/simulation/","title":"Simulation","text":"<p>This module is used to calculate attenuated backscatter profiles from extinction profiles given a predefined atmospheric model.</p>"},{"location":"api/simulation/#aprofiles.simulation.ext2back.ExtinctionToAttenuatedBackscatter","title":"<code>ExtinctionToAttenuatedBackscatter</code>","text":"<p>Class for simulating measurements (attenuated backscatter profiles) for different models.</p> <p>Attributes:</p> Name Type Description <code>`model`</code> <code>{null, step}</code> <p>atmospheric model to be simulated.</p> <code>`wavelength`</code> <code>float</code> <p>Wavelength of the Rayleigh profile to be computed, in nm.</p> <code>`lidar_ratio`</code> <code>float</code> <p>Lidar Ratio, in sr.</p> <code>`noise`</code> <code>float</code> <p>Noise level. The noise is normalized to the maximum extinction value in the profile.</p> Example <pre><code># some imports\nimport aprofiles as apro\n# simulate rayleigh profiles with a random noise\nsimulator = apro.simulator.ExtinctionToAttenuatedBackscatter(\n    model = 'step', wavelength = 1064., lidar_ratio = 50., noise = 0.5\n);\n# calls the to_profiles_data method\nsim_profiles = simulator.to_profiles_data()\n# plot modelled extinction\nsim_profiles.plot('extinction_model')\n</code></pre> <p></p> Source code in <code>aprofiles/simulation/ext2back.py</code> <pre><code>class ExtinctionToAttenuatedBackscatter:\n    \"\"\"Class for simulating measurements (attenuated backscatter profiles) for different models.\n\n    Attributes:\n        `model` ({'null', 'step'}): atmospheric model to be simulated.\n        `wavelength` (float): Wavelength of the Rayleigh profile to be computed, in nm.\n        `lidar_ratio` (float): Lidar Ratio, in sr.\n        `noise` (float): Noise level. The noise is normalized to the maximum extinction value in the profile.\n\n    Example:\n        ```python\n        # some imports\n        import aprofiles as apro\n        # simulate rayleigh profiles with a random noise\n        simulator = apro.simulator.ExtinctionToAttenuatedBackscatter(\n            model = 'step', wavelength = 1064., lidar_ratio = 50., noise = 0.5\n        );\n        # calls the to_profiles_data method\n        sim_profiles = simulator.to_profiles_data()\n        # plot modelled extinction\n        sim_profiles.plot('extinction_model')\n        ```\n\n        ![Simulation of aerosol extinction using a step model](../../assets/images/simulation_step-model.png)\n    \"\"\"    \n    # get the right reading class\n    def __init__(self, model, wavelength, lidar_ratio, noise):\n        self.model = model\n        self.wavelength = wavelength\n        self.lidar_ratio = lidar_ratio\n        self.noise = noise\n\n        # workflow\n        ds = self._model_extinction()\n        ds = self._simulate_attenuated_backscatter(ds)\n        self.data = ds\n\n    def to_profiles_data(self: xr.DataArray):\n        \"\"\"\n        Method which returns an instance of the (aprofiles.profiles.ProfilesData) class.\n\n        Returns:\n            (aprofiles.profiles.ProfilesData):\n        \"\"\"  \n        return ProfilesData(self.data)\n\n    def _model_extinction(self):\n        \"\"\"Calculates the extinction coefficient profiles for a given aerosol model (vertical distribution, lidar ratio) at a given wavelength and with a random noise.\n\n        Returns:\n            (xr.Dataset):\n        \"\"\"        \n        _time = pd.date_range(\n            start=datetime.combine(date.today(), time(0, 0, 0)),\n            end=datetime.combine(date.today(), time(23, 59, 59)),\n            periods=24 * 60 / 5,\n        ).tolist()\n        altitude = np.arange(15, 15000, 15)\n\n        # extinction models\n        extinction_model = []\n        # model clear: twice the molecular\n        if self.model == \"null\":\n            extinction_profile = np.asarray([0 for z in altitude])\n        if self.model == \"step\":\n            extinction_profile = np.asarray([0.1 if z&lt;3000 else 0 for z in altitude])\n        if self.model == \"aloft\":\n            #TODO: gaussian in altitude (3 km)\n            pass\n\n        # use profile over the whole day\n        for t in _time:\n            norm_noise = self.noise*np.nanmax(extinction_profile) / altitude[-1]**2\n            noise_profile = [norm_noise * random.uniform(-1,1) * z**2 for z in altitude]\n            extinction_model.append(np.asarray(extinction_profile + noise_profile))\n\n        ds = xr.Dataset(\n            data_vars=dict(\n                extinction_model=([\"time\", \"altitude\"], extinction_model),\n                station_altitude=(0.0),\n                station_latitude=(0.0),\n                station_longitude=(0.0),\n                l0_wavelength=(self.wavelength)\n            ),\n            coords=dict(time=_time, altitude=altitude),\n            attrs=dict(site_location=f\"Simulation - [{self.model}]\"),\n        )\n        ds.extinction_model.attrs = {\n            \"long_name\": f\"Extinction Coefficient (model) @ {self.wavelength} nm\",\n            \"units\": \"km-1\",\n        }\n        ds.l0_wavelength.attrs = {\n            \"units\": \"nm\"\n        }\n        return ds\n\n    def _simulate_attenuated_backscatter(self, ds: xr.Dataset):\n        \"\"\"Calculates the attenuated backscatter measurements for given extinction profiles\n\n        Args:\n            ds (xr.Dataset): Dataset which contains extinction profiles (`time`, `altitude`)\n\n        Returns:\n            (xr.Dataset):\n        \"\"\"\n        # frequently used variables\n        altitude = ds.altitude.data\n        time = ds.time.data\n        extinction_model = ds.extinction_model.data * 1e-3 #conversion from km-1 to m-1\n        vertical_resolution = min(np.diff(altitude))\n\n        # open molecular profile\n        rayleigh = RayleighData(altitude, self.wavelength, T0=298, P0=1013)\n\n        # attenuated_backscatter calculation\n        attenuated_backscatter = []\n        for i, t in enumerate(time):\n            total_backscatter = rayleigh.backscatter + np.divide(extinction_model[i,:], self.lidar_ratio)\n            total_extinction = rayleigh.extinction + extinction_model[i]\n            optical_depth = np.cumsum(total_extinction * vertical_resolution)\n            transmission = np.exp(-optical_depth)\n            attenuated_backscatter.append(np.asarray([total_backscatter[j] * (transmission[j]**2) for j, z in enumerate(altitude)]))\n        # convert list to np array\n        attenuated_backscatter = np.asarray(attenuated_backscatter)\n\n        # add attenuated_backscatter as new dataarray\n        ds[\"attenuated_backscatter_0\"] = xr.DataArray(\n            data=attenuated_backscatter * 1e6, #conversion from m-1.sr-1 to Mm-1.sr-1\n            dims=[\"time\", \"altitude\"],\n            attrs=dict(long_name=f\"Attenuated Backscatter @ {self.wavelength}nm\", units='Mm-1.sr-1'),\n        )\n        return ds\n</code></pre>"},{"location":"api/simulation/#aprofiles.simulation.ext2back.ExtinctionToAttenuatedBackscatter.to_profiles_data","title":"<code>to_profiles_data()</code>","text":"<p>Method which returns an instance of the (aprofiles.profiles.ProfilesData) class.</p> <p>Returns:</p> Type Description <code>ProfilesData</code> Source code in <code>aprofiles/simulation/ext2back.py</code> <pre><code>def to_profiles_data(self: xr.DataArray):\n    \"\"\"\n    Method which returns an instance of the (aprofiles.profiles.ProfilesData) class.\n\n    Returns:\n        (aprofiles.profiles.ProfilesData):\n    \"\"\"  \n    return ProfilesData(self.data)\n</code></pre>"},{"location":"api/writing/","title":"Writing","text":"<p>This module is used to write data from an instance of the <code>ProfilesData</code> class as a NetCDF file.</p>"},{"location":"api/writing/#aprofiles.io.write_profiles.write","title":"<code>write(profiles, base_dir, verbose)</code>","text":"<p>Writing method for an instance of a (aprofiles.profiles.ProfilesData): class.</p> <p>Parameters:</p> Name Type Description Default <code>profiles</code> <code>ProfilesData</code> <p>Object to be written.</p> required <code>base_dir</code> <code>str</code> <p>Base path of the file should be written.</p> required <code>verbose</code> <code>bool</code> <p>Verbose mode.</p> required Source code in <code>aprofiles/io/write_profiles.py</code> <pre><code>def write(profiles, base_dir, verbose):\n    \"\"\"\n    Writing method for an instance of a (aprofiles.profiles.ProfilesData): class.\n\n    Args:\n        profiles (aprofiles.profiles.ProfilesData): Object to be written.\n        base_dir (str): Base path of the file should be written.\n        verbose (bool): Verbose mode.\n    \"\"\"\n\n    def _classify_scene(ds):\n        lowest_clouds = profiles._get_lowest_clouds()\n        scene = []\n        # got clouds classification here: https://www.metoffice.gov.uk/weather/learn-about/weather/types-of-weather/clouds\n        for i, lowest_cloud in enumerate(lowest_clouds):\n            if lowest_cloud &lt;= 1981:\n                scene.append(3)\n            elif lowest_cloud &gt; 1981 and lowest_cloud &lt;= 6096:\n                scene.append(2)\n            elif lowest_cloud &gt; 6096:\n                scene.append(1)\n            else:\n                scene.append(0)\n            # overwrite result based on foc\n            if ds.foc.data[i]:\n                scene[i] = 4\n        return scene\n\n    def _classify_retrieval_scene(ds):\n        lowest_clouds = profiles._get_lowest_clouds()\n        z_ref = profiles.data.z_ref.data\n        scene = []\n        for i, _ in enumerate(lowest_clouds):\n            if lowest_clouds[i] &gt; z_ref[i]:\n                scene.append(1)\n            elif lowest_clouds[i] &lt; z_ref[i]:\n                scene.append(3)\n            else:\n                scene.append(0)\n            # overwrite result based on foc\n            if ds.foc.data[i]:\n                scene[i] = 4\n        return scene\n\n    # get dataset from profilesdata\n    ds = profiles.data\n\n    # get date as string yyyy-mm-dd from first value of the time data\n    str_date = str(ds.time.values[0])[:10]\n    yyyy = str_date[:4]\n    mm = str_date[5:7]\n    dd = str_date[8:10]\n    filename = f\"AP_{ds.wigos_station_id}-{ds.instrument_id}-{str_date}.nc\"\n    path = os.path.join(base_dir, yyyy, mm, dd, filename)\n\n    if utils.file_exists(path) and verbose:\n        warnings.warn(f\"{path} already exists and will be overwritten.\")\n    else:\n        from pathlib import Path\n\n        Path(base_dir, yyyy, mm, dd).mkdir(parents=True, exist_ok=True)\n\n    # creates a copy od original dataset -&gt; writes only necessary data\n    ds_towrite = copy.deepcopy(ds)\n\n    # for the mass concentration, we just need the mec.\n    mec = {}\n    for data_var in list(ds_towrite.data_vars):\n        if \"mass_concentration:\" in data_var:\n            mec[data_var.split(\":\")[1]] = ds[data_var].mec\n            ds_towrite = ds_towrite.drop(data_var)\n\n    # add mec as new dataarray\n    ds_towrite[\"mec\"] = xr.DataArray(\n        data=list(mec.values()),\n        dims=[\"aer_type\"],\n        coords=dict(\n            aer_type=list(mec.keys()),\n        ),\n        attrs=dict(\n            long_name=\"Mass to Extinction Coefficient\",\n            units=\"m2.g-1\",\n            wavelength=ds.l0_wavelength.data,\n        ),\n    )\n    # add attributes to aer_type\n    ds_towrite[\"aer_type\"] = ds_towrite[\"aer_type\"].assign_attrs(\n        {\"long_name\": \"Aerosol type\"}\n    )\n\n    # determines the scene classification for each profile\n    scene = _classify_scene(ds_towrite)\n    # add scene as new dataarray\n    ds_towrite[\"scene\"] = (\"time\", scene)\n    ds_towrite[\"scene\"] = ds_towrite[\"scene\"].assign_attrs(\n        {\n            \"long_name\": \"Scene classification\",\n            \"definition\": \"0: aer (aerosols only) / 1: high_cloud (base cloud above 6096 m) / 2: mid_cloud (base cloud between 1981 m and 6096 m) / 3: low-cloud (base cloud below 1981 m) - 4: foc (fog or condensation)\",\n        }\n    )\n\n    # add scene for extinction profile: cloud_above, cloud_below\n    retrieval_scene = _classify_retrieval_scene(ds_towrite)\n    # add scene as new dataarray\n    ds_towrite[\"retrieval_scene\"] = (\"time\", retrieval_scene)\n    ds_towrite[\"retrieval_scene\"] = ds_towrite[\"retrieval_scene\"].assign_attrs(\n        {\n            \"long_name\": \"Retrieval scene classification\",\n            \"definition\": \"0: aer (aerosols only) / 1: cloud_above (cloud above reference altitude) / 3: cloud_below (cloud below reference point) / 4: foc (fog or condensation)\",\n        }\n    )\n\n    # drop other variables\n    drop_variables = [\n        \"start_time\",\n        \"vertical_visibility\",\n        \"cbh_uncertainties\",\n        \"uncertainties_att_backscatter_0\",\n    ]\n    for drop_var in drop_variables:\n        ds_towrite = ds_towrite.drop(drop_var)\n\n    # some variables have no dimension. Set it as attribute and drop the variable.\n    nodim_variables = [\"l0_wavelength\"]\n    for nodim_var in nodim_variables:\n        ds_towrite.attrs[nodim_var] = ds_towrite[nodim_var].data\n        ds_towrite = ds_towrite.drop(nodim_var)\n\n    # for convenience, add initial coordinates of station\n    coordinates_vars = [\"station_altitude\", \"station_latitude\", \"station_longitude\"]\n    for coordinate_var in coordinates_vars:\n        ds_towrite.attrs[f\"{coordinate_var}_t0\"] = ds_towrite[coordinate_var].data[0]\n\n    # add altitude direction\n    ds_towrite[\"altitude\"] = ds_towrite[\"altitude\"].assign_attrs({\"positive\": \"up\"})\n\n    # encoding with compression\n    encoding = {}\n    for varname, var in ds_towrite.variables.items():\n        if varname == \"time\":\n            continue\n        if var.dtype == np.int64:\n            encoding[varname] = {\n                \"dtype\": np.int32,\n                \"zlib\": True,\n                \"chunksizes\": var.shape,\n            }\n        if varname in [\"extinction\", \"clouds\"]:\n            encoding[varname] = {\"zlib\": True, \"chunksizes\": var.shape}\n\n    # convert also the quality_flag's variable flag_values attribute also to NC_INT instead of NC_INT64\n    ds_towrite[\"quality_flag\"] = ds_towrite.quality_flag.assign_attrs(\n        {\"flag_values\": np.array([0, 1, 2], dtype=np.int32)}\n    )\n\n    # add some metadata\n    ds_towrite.attrs[\"aprofiles\"] = version(\"aprofiles\")\n\n    # sort to ensure monotonicity\n    ds_towrite = ds_towrite.sortby(\"time\")\n    ds_towrite = ds_towrite.sortby(\"aer_type\")\n\n    # writes to netcdf\n    # ds_towrite.to_netcdf(path, mode=\"w\", encoding=encoding)\n    ds_towrite.to_netcdf(path, mode=\"w\")\n</code></pre>"}]}